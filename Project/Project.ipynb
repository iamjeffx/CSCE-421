{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 421 Final Project\n",
    "\n",
    "Jeffrey Xu  \n",
    "Prof. Mortazavi  \n",
    "CSCE 421  \n",
    "11/11/2020  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "Image classification has been an interesting field within AI and machine learning for many years now. There are many different machine learning models that can perform the task of image classification. Finding the best model however can be quite tricky as different models have different strengths and weaknesses. We explore the effectiveness of some unique machine learning models that can perform image classification and analyze the performance of each model on the MNIST digit dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by making sure the versions of our imports are correct. We can do this by using pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision==0.2.1 in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from torchvision==0.2.1) (1.16.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from torchvision==0.2.1) (6.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from torchvision==0.2.1) (1.12.0)\n",
      "Requirement already satisfied: torch in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from torchvision==0.2.1) (0.4.1)\n",
      "Requirement already satisfied: scikit-learn==0.23.2 in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from scikit-learn==0.23.2) (1.16.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from scikit-learn==0.23.2) (0.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from scikit-learn==0.23.2) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\jeffr\\anaconda3\\lib\\site-packages (from scikit-learn==0.23.2) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.2.1\n",
    "!pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import all the required libraries for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set some initial hyperparameters. These values can change depending on how we want to implement our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20f8e2412b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Imbalanced MNIST Example')\n",
    "parser.add_argument(\"-f\")\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='--random-seed (default: 42)')\n",
    "parser.add_argument('--nrow', type=int, default=5,\n",
    "                    help='rows of example')\n",
    "parser.add_argument('--ncol', type=int, default=10,\n",
    "                    help='columns of example')\n",
    "parser.add_argument('--n-epochs', type=int, default=25,\n",
    "                   help='number of epochs')\n",
    "parser.add_argument('--learning-rate', type=float, default=0.01,\n",
    "                   help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, \n",
    "                   help='momentum')\n",
    "parser.add_argument('--log-interval', type=int, default=10,\n",
    "                   help='log interval')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load in the training datasets that we are going to use for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_linear_train_dataset = torch.load('imbalanced_linear_train_dataset.pt')\n",
    "imbalanced_linear_train_loader = torch.utils.data.DataLoader(imbalanced_linear_train_dataset,\n",
    "                                                             batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "imbalanced_step_train_dataset = torch.load('imbalanced_step_train_dataset.pt')\n",
    "imbalanced_step_train_loader = torch.utils.data.DataLoader(imbalanced_step_train_dataset, batch_size=args.batch_size,\n",
    "                                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_linear_loader = torch.utils.data.DataLoader(imbalanced_linear_train_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                                                     sampler=ImbalancedDatasetSampler(imbalanced_linear_train_dataset, num_samples=50000))\n",
    "balanced_step_loader = torch.utils.data.DataLoader(imbalanced_step_train_dataset, batch_size=args.batch_size, shuffle=False,\n",
    "                                                   sampler=ImbalancedDatasetSampler(imbalanced_step_train_dataset, num_samples=50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_linear = []\n",
    "y_linear = []\n",
    "\n",
    "for data in imbalanced_linear_train_dataset:\n",
    "    X_linear.append(np.array(data[0]).flatten())\n",
    "    y_linear.append(int(data[1]))\n",
    "    \n",
    "X_linear = np.array(X_linear)\n",
    "y_linear = np.array(y_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_linear_res, y_linear_res = rus.fit_resample(X_linear, y_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_step = []\n",
    "y_step = []\n",
    "\n",
    "for data in imbalanced_step_train_dataset:\n",
    "    X_step.append(np.array(data[0]).flatten())\n",
    "    y_step.append(int(data[1]))\n",
    "    \n",
    "X_step = np.array(X_step)\n",
    "y_step = np.array(y_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_step_res, y_step_res = rus.fit_resample(X_step, y_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load in the testing datasets for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.load('test_dataset.pt')\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for data in test_dataset:\n",
    "    X_test.append(np.array(data[0]).flatten())\n",
    "    y_test.append(int(data[1]))\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that shows the distribution of the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mnist(arr, nrow=args.nrow, ncol=args.ncol, figsize=None):\n",
    "    if figsize is None:\n",
    "        figsize = (ncol, nrow)\n",
    "\n",
    "    f, a = plt.subplots(nrow, ncol, figsize=figsize)\n",
    "\n",
    "    def _do_show(the_figure, the_array):\n",
    "        the_figure.imshow(the_array)\n",
    "        the_figure.axis('off')\n",
    "\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            _do_show(a[i][j], np.reshape(arr[i * ncol + j], (28, 28)))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.draw()\n",
    "    plt.savefig('examples.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we display the distribution of our MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of classes in linear imbalanced dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribution of classes in linear imbalanced dataset:')\n",
    "fig, ax = plt.subplots()\n",
    "_, counts = np.unique(imbalanced_linear_train_loader.dataset.train_labels, return_counts=True)\n",
    "num_classes = 10\n",
    "classe_labels = range(num_classes)\n",
    "ax.bar(classe_labels, counts)\n",
    "ax.set_xticks(classe_labels)\n",
    "plt.savefig('dist linear.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of classes in step imbalanced dataset:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribution of classes in step imbalanced dataset:')\n",
    "fig, ax = plt.subplots()\n",
    "_, counts = np.unique(imbalanced_step_train_loader.dataset.train_labels, return_counts=True)\n",
    "num_classes = 10\n",
    "classe_labels = range(num_classes)\n",
    "ax.bar(classe_labels, counts)\n",
    "ax.set_xticks(classe_labels)\n",
    "plt.savefig('dist step.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show the numbers used in each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data, _ in imbalanced_linear_train_loader:\n",
    "    show_mnist(data)\n",
    "    break\n",
    "\n",
    "for data, _ in imbalanced_step_train_loader:\n",
    "    show_mnist(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Our first model to test on this MNIST dataset is logistic regression. We start by importing the model in from *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also perform Cross Validation on the training data to determine the best hyperparameters to use for our logistical model here. We also need to implement a multiclass roc score function to accurately test how well our model is doing despite the imbalance of the given dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_score_multiclass(actual_class, pred_class, average=\"macro\"):\n",
    "    # Creating a set of all the unique classes using the actual class list\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        # Creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        # Marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        # Using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "    # Computing the average roc auc score\n",
    "    total = 0\n",
    "    for item in roc_auc_dict.values():\n",
    "        total += item\n",
    "        \n",
    "    return total/len(roc_auc_dict.values())\n",
    "\n",
    "def max_val(d):\n",
    "    max = 0\n",
    "    max_element = 0\n",
    "    for item in d.keys():\n",
    "        if d[item] > max:\n",
    "            max = d[item]\n",
    "            max_element = item\n",
    "    return max_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed\n",
      "Fold 2 completed\n",
      "Fold 3 completed\n",
      "Fold 4 completed\n",
      "Fold 5 completed\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "c_vals = [100, 10, 1.0, 0.1, 0.01]\n",
    "auc_dict_linear = {100:0, 10:0, 1.0:0, 0.1:0, 0.01:0}\n",
    "count = 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "for train_index, test_index in skf.split(X_linear, y_linear):\n",
    "    x_train, x_test = pd.DataFrame(X_linear).iloc[train_index], pd.DataFrame(X_linear).iloc[test_index]\n",
    "    Y_train, Y_test = pd.DataFrame(y_linear).iloc[train_index], pd.DataFrame(y_linear).iloc[test_index]\n",
    "    \n",
    "    for c in c_vals:\n",
    "        log_regressor_linear = LogisticRegression(solver=\"lbfgs\", C=c)\n",
    "        log_regressor_linear.fit(x_train, Y_train)\n",
    "        \n",
    "        pred = log_regressor_linear.predict(x_test)\n",
    "        \n",
    "        auc_dict_linear[c] += roc_auc_score_multiclass(np.array(Y_test).T[0], pred) / num_folds\n",
    "    print(\"Fold \" + str(count) + \" completed\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value for linear: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Best C value for linear: \" + str(max_val(auc_dict_linear)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.log(list(auc_dict_linear.keys())), list(auc_dict_linear.values()))\n",
    "plt.title('Log of C values vs. ROC AUC Score')\n",
    "plt.xlabel('Log of C Values')\n",
    "plt.ylabel('AUC ROC Multiclass Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit our Logistic Regression model to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_linear = LogisticRegression(solver=\"lbfgs\", C=max_val(auc_dict_linear)).fit(X_linear, y_linear)\n",
    "log_model_linear_res = LogisticRegression(solver='lbfgs', C=max_val(auc_dict_linear)).fit(X_linear_res, y_linear_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = log_model_linear.predict(X_test)\n",
    "pred_res = log_model_linear_res.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC multiclass score for linear dataset: 0.9472371967739848\n",
      "AUC ROC multiclass score for linear resampled dataset: 0.9484009823171616\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC ROC multiclass score for linear dataset: \" + str(roc_auc_score_multiclass(y_test, pred)))\n",
    "print(\"AUC ROC multiclass score for linear resampled dataset: \" + str(roc_auc_score_multiclass(y_test, pred_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to fit another separate model to the step dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed\n",
      "Fold 2 completed\n",
      "Fold 3 completed\n",
      "Fold 4 completed\n",
      "Fold 5 completed\n"
     ]
    }
   ],
   "source": [
    "auc_dict_step = {100:0, 10:0, 1.0:0, 0.1:0, 0.01:0}\n",
    "count = 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "for train_index, test_index in skf.split(X_step, y_step):\n",
    "    x_train, x_test = pd.DataFrame(X_step).iloc[train_index], pd.DataFrame(X_step).iloc[test_index]\n",
    "    Y_train, Y_test = pd.DataFrame(y_step).iloc[train_index], pd.DataFrame(y_step).iloc[test_index]\n",
    "    \n",
    "    for c in c_vals:\n",
    "        log_regressor_step = LogisticRegression(solver=\"lbfgs\", C=c)\n",
    "        log_regressor_step.fit(x_train, Y_train)\n",
    "        \n",
    "        pred = log_regressor_step.predict(x_test)\n",
    "        \n",
    "        auc_dict_step[c] += roc_auc_score_multiclass(np.array(Y_test).T[0], pred) / num_folds\n",
    "    print(\"Fold \" + str(count) + \" completed\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value for step: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Best C value for step: \" + str(max_val(auc_dict_step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.log(list(auc_dict_step.keys())), list(auc_dict_step.values()))\n",
    "plt.title('Log of C values vs. ROC AUC Score')\n",
    "plt.xlabel('Log of C Values')\n",
    "plt.ylabel('AUC ROC Multiclass Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model_step = LogisticRegression(solver=\"lbfgs\", C=max_val(auc_dict_step)).fit(X_step, y_step)\n",
    "log_model_step_res = LogisticRegression(solver='lbfgs', C=max_val(auc_dict_step)).fit(X_step_res, y_step_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_step = log_model_step.predict(X_test)\n",
    "pred_step_res = log_model_step_res.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC multiclass score for step dataset: 0.9521365236922357\n",
      "AUC ROC multiclass score for step resampled dataset: 0.9523040187456987\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC ROC multiclass score for step dataset: \" + str(roc_auc_score_multiclass(y_test, pred_step)))\n",
    "print(\"AUC ROC multiclass score for step resampled dataset: \" + str(roc_auc_score_multiclass(y_test, pred_step_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to fit another model to classify the MNIST digits dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to perform Cross validation on our dataset to determine the best hyperparameters for our Random Forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_Validate_Models_RF(max_trees, X_train, y_train):\n",
    "    # Create splitter object\n",
    "    n_folds = 5\n",
    "    splitter = StratifiedKFold(n_splits=n_folds, shuffle=True).split(X_train, y_train)\n",
    "    \n",
    "    # Performance\n",
    "    gini_perf = []\n",
    "    entropy_perf = []\n",
    "    gini_train = []\n",
    "    entropy_train = []\n",
    "    for i in max_trees:\n",
    "        gini_perf.append([])\n",
    "        entropy_perf.append([])\n",
    "        gini_train.append([])\n",
    "        entropy_train.append([])\n",
    "    \n",
    "    fold = 1\n",
    "    \n",
    "    # Cross Validation\n",
    "    for train_index, test_index in splitter:\n",
    "        # Split training data for CV\n",
    "        X_train_CV, X_test_CV = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_CV, y_test_CV = y_train.iloc[train_index].values.ravel(), y_train.iloc[test_index].values.ravel()\n",
    "        \n",
    "        index = 0\n",
    "        \n",
    "        # Iterate through all different depths\n",
    "        for d in max_trees:\n",
    "            model_gini = RandomForestClassifier(criterion='gini', n_estimators=d, \n",
    "                                                min_impurity_decrease=0.0, min_samples_split=2)\n",
    "            model_entropy = RandomForestClassifier(criterion='entropy', n_estimators=d, \n",
    "                                                   min_impurity_decrease=0.0, min_samples_split=2)\n",
    "            model_gini.fit(X_train_CV, y_train_CV)\n",
    "            model_entropy.fit(X_train_CV, y_train_CV)\n",
    "\n",
    "            pred_gini = model_gini.predict(X_test_CV)\n",
    "            pred_entropy = model_entropy.predict(X_test_CV)\n",
    "            \n",
    "            train_gini_pred = model_gini.predict(X_train_CV)\n",
    "            train_entropy_pred = model_entropy.predict(X_train_CV)\n",
    "\n",
    "            gini_perf[index].append(roc_auc_score_multiclass(y_test_CV, pred_gini))\n",
    "            entropy_perf[index].append(roc_auc_score_multiclass(y_test_CV, pred_entropy))\n",
    "            \n",
    "            gini_train[index].append(roc_auc_score_multiclass(y_train_CV, train_gini_pred))\n",
    "            entropy_train[index].append(roc_auc_score_multiclass(y_train_CV, train_entropy_pred))\n",
    "            \n",
    "            index += 1\n",
    "        print('Fold ' + str(fold) + ' completed')\n",
    "        fold += 1\n",
    "    return gini_perf, entropy_perf, gini_train, entropy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed\n",
      "Fold 2 completed\n",
      "Fold 3 completed\n",
      "Fold 4 completed\n",
      "Fold 5 completed\n"
     ]
    }
   ],
   "source": [
    "d = [100, 200, 300, 400, 500]\n",
    "gini_perf_RF, entropy_perf_RF, gini_train_RF, entropy_train_RF = Cross_Validate_Models_RF(d, \n",
    "                                                                                          pd.DataFrame(X_linear), \n",
    "                                                                                          pd.DataFrame(y_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d, np.mean(gini_perf_RF, axis=1), label='Gini test performance')\n",
    "plt.plot(d, np.mean(entropy_perf_RF, axis=1), label='Entropy test performance')\n",
    "plt.title('Max Depth vs ROC AUC')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max-depth for the gini model: 500, ROC AUC score: 0.9656686702698816\n",
      "Best max-depth for the entropy model: 400, ROC AUC score: 0.9662628898847269\n"
     ]
    }
   ],
   "source": [
    "# Determine the best depth for each model\n",
    "max_trees_gini_RF = d[np.argmax(np.mean(gini_perf_RF, axis=1))]\n",
    "max_trees_entropy_RF = d[np.argmax(np.mean(entropy_perf_RF, axis=1))]\n",
    "auc_roc_score_gini = np.max(np.mean(gini_perf_RF, axis=1))\n",
    "auc_roc_score_entropy = np.max(np.mean(entropy_perf_RF, axis=1))\n",
    "\n",
    "print('Best max-depth for the gini model: ' + str(max_trees_gini_RF) + \n",
    "      \", ROC AUC score: \" + str(auc_roc_score_gini))\n",
    "print('Best max-depth for the entropy model: ' + str(max_trees_entropy_RF)  + \n",
    "      \", ROC AUC score: \" + str(auc_roc_score_entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've performed Cross Validation, we generate our model using the best hyperparameters determined from the Cross Validation run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=400)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = ''\n",
    "num_trees = 0\n",
    "if auc_roc_score_gini > auc_roc_score_entropy:\n",
    "    model_type = 'gini'\n",
    "    num_trees = max_trees_gini_RF\n",
    "else:\n",
    "    model_type = 'entropy'\n",
    "    num_trees = max_trees_entropy_RF\n",
    "    \n",
    "RF_model = RandomForestClassifier(criterion=model_type, n_estimators=num_trees, \n",
    "                                   min_impurity_decrease=0.0, min_samples_split=2)\n",
    "RF_model_res = RandomForestClassifier(criterion=model_type, n_estimators=num_trees,\n",
    "                                     min_impurity_decrease=0.0, min_samples_split=2)\n",
    "RF_model.fit(X_linear, y_linear)\n",
    "RF_model_res.fit(X_linear_res, y_linear_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score for RF: 0.9729426184862197\n",
      "ROC Score for RF Resampled: 0.9714230184495986\n"
     ]
    }
   ],
   "source": [
    "RF_pred = RF_model.predict(X_test)\n",
    "RF_pred_res = RF_model_res.predict(X_test)\n",
    "print('ROC Score for RF: ' + str(roc_auc_score_multiclass(y_test, RF_pred)))\n",
    "print('ROC Score for RF Resampled: ' + str(roc_auc_score_multiclass(y_test, RF_pred_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a significant increase in the accuracy once we started to use the Random Forest classifier compared to the Logistic Regression classifier. Now we fit a model for the step dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed\n",
      "Fold 2 completed\n",
      "Fold 3 completed\n",
      "Fold 4 completed\n",
      "Fold 5 completed\n"
     ]
    }
   ],
   "source": [
    "gini_perf_RF_step, entropy_perf_RF_step, gini_train_RF_step, entropy_train_RF_step = Cross_Validate_Models_RF(d, \n",
    "                                                                                          pd.DataFrame(X_step), \n",
    "                                                                                          pd.DataFrame(y_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d, np.mean(gini_perf_RF_step, axis=1), label='Gini test performance')\n",
    "plt.plot(d, np.mean(entropy_perf_RF_step, axis=1), label='Entropy test performance')\n",
    "plt.title('Max Depth vs ROC AUC')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max-depth for the gini model: 400, ROC AUC score: 0.9733429079488154\n",
      "Best max-depth for the entropy model: 500, ROC AUC score: 0.9733090399536415\n"
     ]
    }
   ],
   "source": [
    "# Determine the best depth for each model\n",
    "max_trees_gini_RF_step = d[np.argmax(np.mean(gini_perf_RF_step, axis=1))]\n",
    "max_trees_entropy_RF_step = d[np.argmax(np.mean(entropy_perf_RF_step, axis=1))]\n",
    "auc_roc_score_gini_step = np.max(np.mean(gini_perf_RF_step, axis=1))\n",
    "auc_roc_score_entropy_step = np.max(np.mean(entropy_perf_RF_step, axis=1))\n",
    "\n",
    "print('Best max-depth for the gini model: ' + str(max_trees_gini_RF_step) + \n",
    "      \", ROC AUC score: \" + str(auc_roc_score_gini_step))\n",
    "print('Best max-depth for the entropy model: ' + str(max_trees_entropy_RF_step)  + \n",
    "      \", ROC AUC score: \" + str(auc_roc_score_entropy_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=400)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type_step = ''\n",
    "num_trees_step = 0\n",
    "if auc_roc_score_gini_step > auc_roc_score_entropy_step:\n",
    "    model_type_step = 'gini'\n",
    "    num_trees_step = max_trees_gini_RF_step\n",
    "else:\n",
    "    model_type_step = 'entropy'\n",
    "    num_trees_step = max_trees_entropy_RF_step\n",
    "    \n",
    "RF_model_step = RandomForestClassifier(criterion=model_type_step, n_estimators=num_trees_step, \n",
    "                                   min_impurity_decrease=0.0, min_samples_split=2)\n",
    "RF_model_step_res = RandomForestClassifier(criterion=model_type_step, n_estimators=num_trees_step,\n",
    "                                          min_impurity_decrease=0.0, min_samples_split=2)\n",
    "RF_model_step.fit(X_step, y_step)\n",
    "RF_model_step_res.fit(X_step_res, y_step_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score for RF step: 0.9792071487813313\n",
      "ROC Score for RF step resampled: 0.9795475836426748\n"
     ]
    }
   ],
   "source": [
    "RF_pred_step = RF_model_step.predict(X_test)\n",
    "RF_pred_step_res = RF_model_step_res.predict(X_test)\n",
    "print('ROC Score for RF step: ' + str(roc_auc_score_multiclass(y_test, RF_pred_step)))\n",
    "print('ROC Score for RF step resampled: ' + str(roc_auc_score_multiclass(y_test, RF_pred_step_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use a Convolutional Neural Network as our model to predict digits. We will be using the PyTorch library to help generate the CNN model. We need to start by generating our CNN class object. This code was based on the template provided from https://nextjournal.com/gkoehler/pytorch-mnist. All credit for the model structure goes to the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CNN()\n",
    "optimizer = optim.SGD(network.parameters(), lr=args.learning_rate, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i * len(imbalanced_linear_train_loader) for i in range(args.n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader, network, optimizer):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), \n",
    "                                                                           len(train_loader.dataset), \n",
    "                                                                           100. * batch_idx / len(train_loader), \n",
    "                                                                           loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, \n",
    "                                                                              correct, \n",
    "                                                                              len(test_loader.dataset),\n",
    "                                                                              100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3165, Accuracy: 608/10000 (6%)\n",
      "\n",
      "Train Epoch: 1 [0/37879 (0%)]\tLoss: 2.345601\n",
      "Train Epoch: 1 [640/37879 (2%)]\tLoss: 2.295111\n",
      "Train Epoch: 1 [1280/37879 (3%)]\tLoss: 2.252045\n",
      "Train Epoch: 1 [1920/37879 (5%)]\tLoss: 2.230008\n",
      "Train Epoch: 1 [2560/37879 (7%)]\tLoss: 2.136305\n",
      "Train Epoch: 1 [3200/37879 (8%)]\tLoss: 2.130889\n",
      "Train Epoch: 1 [3840/37879 (10%)]\tLoss: 2.083104\n",
      "Train Epoch: 1 [4480/37879 (12%)]\tLoss: 1.981201\n",
      "Train Epoch: 1 [5120/37879 (14%)]\tLoss: 2.073714\n",
      "Train Epoch: 1 [5760/37879 (15%)]\tLoss: 1.699332\n",
      "Train Epoch: 1 [6400/37879 (17%)]\tLoss: 1.687877\n",
      "Train Epoch: 1 [7040/37879 (19%)]\tLoss: 1.756233\n",
      "Train Epoch: 1 [7680/37879 (20%)]\tLoss: 1.448253\n",
      "Train Epoch: 1 [8320/37879 (22%)]\tLoss: 1.553697\n",
      "Train Epoch: 1 [8960/37879 (24%)]\tLoss: 1.233509\n",
      "Train Epoch: 1 [9600/37879 (25%)]\tLoss: 1.456660\n",
      "Train Epoch: 1 [10240/37879 (27%)]\tLoss: 1.409914\n",
      "Train Epoch: 1 [10880/37879 (29%)]\tLoss: 1.222752\n",
      "Train Epoch: 1 [11520/37879 (30%)]\tLoss: 1.160323\n",
      "Train Epoch: 1 [12160/37879 (32%)]\tLoss: 0.883134\n",
      "Train Epoch: 1 [12800/37879 (34%)]\tLoss: 1.295021\n",
      "Train Epoch: 1 [13440/37879 (35%)]\tLoss: 0.822724\n",
      "Train Epoch: 1 [14080/37879 (37%)]\tLoss: 1.023066\n",
      "Train Epoch: 1 [14720/37879 (39%)]\tLoss: 1.105677\n",
      "Train Epoch: 1 [15360/37879 (41%)]\tLoss: 0.939222\n",
      "Train Epoch: 1 [16000/37879 (42%)]\tLoss: 0.850350\n",
      "Train Epoch: 1 [16640/37879 (44%)]\tLoss: 0.895338\n",
      "Train Epoch: 1 [17280/37879 (46%)]\tLoss: 0.692148\n",
      "Train Epoch: 1 [17920/37879 (47%)]\tLoss: 0.931326\n",
      "Train Epoch: 1 [18560/37879 (49%)]\tLoss: 0.787067\n",
      "Train Epoch: 1 [19200/37879 (51%)]\tLoss: 0.842653\n",
      "Train Epoch: 1 [19840/37879 (52%)]\tLoss: 0.765694\n",
      "Train Epoch: 1 [20480/37879 (54%)]\tLoss: 1.025641\n",
      "Train Epoch: 1 [21120/37879 (56%)]\tLoss: 0.648867\n",
      "Train Epoch: 1 [21760/37879 (57%)]\tLoss: 1.035832\n",
      "Train Epoch: 1 [22400/37879 (59%)]\tLoss: 0.780137\n",
      "Train Epoch: 1 [23040/37879 (61%)]\tLoss: 0.790747\n",
      "Train Epoch: 1 [23680/37879 (62%)]\tLoss: 0.750955\n",
      "Train Epoch: 1 [24320/37879 (64%)]\tLoss: 0.746007\n",
      "Train Epoch: 1 [24960/37879 (66%)]\tLoss: 0.984515\n",
      "Train Epoch: 1 [25600/37879 (68%)]\tLoss: 0.645287\n",
      "Train Epoch: 1 [26240/37879 (69%)]\tLoss: 0.640882\n",
      "Train Epoch: 1 [26880/37879 (71%)]\tLoss: 0.575324\n",
      "Train Epoch: 1 [27520/37879 (73%)]\tLoss: 0.634474\n",
      "Train Epoch: 1 [28160/37879 (74%)]\tLoss: 0.778395\n",
      "Train Epoch: 1 [28800/37879 (76%)]\tLoss: 1.022625\n",
      "Train Epoch: 1 [29440/37879 (78%)]\tLoss: 0.632869\n",
      "Train Epoch: 1 [30080/37879 (79%)]\tLoss: 0.692199\n",
      "Train Epoch: 1 [30720/37879 (81%)]\tLoss: 0.688708\n",
      "Train Epoch: 1 [31360/37879 (83%)]\tLoss: 0.621101\n",
      "Train Epoch: 1 [32000/37879 (84%)]\tLoss: 0.514037\n",
      "Train Epoch: 1 [32640/37879 (86%)]\tLoss: 0.632423\n",
      "Train Epoch: 1 [33280/37879 (88%)]\tLoss: 0.527697\n",
      "Train Epoch: 1 [33920/37879 (90%)]\tLoss: 0.623956\n",
      "Train Epoch: 1 [34560/37879 (91%)]\tLoss: 0.647928\n",
      "Train Epoch: 1 [35200/37879 (93%)]\tLoss: 0.693320\n",
      "Train Epoch: 1 [35840/37879 (95%)]\tLoss: 0.592821\n",
      "Train Epoch: 1 [36480/37879 (96%)]\tLoss: 0.529772\n",
      "Train Epoch: 1 [37120/37879 (98%)]\tLoss: 0.504266\n",
      "Train Epoch: 1 [37760/37879 (100%)]\tLoss: 0.319232\n",
      "\n",
      "Test set: Avg. loss: 0.3694, Accuracy: 8693/10000 (86%)\n",
      "\n",
      "Train Epoch: 2 [0/37879 (0%)]\tLoss: 0.564602\n",
      "Train Epoch: 2 [640/37879 (2%)]\tLoss: 0.530469\n",
      "Train Epoch: 2 [1280/37879 (3%)]\tLoss: 0.784541\n",
      "Train Epoch: 2 [1920/37879 (5%)]\tLoss: 0.409319\n",
      "Train Epoch: 2 [2560/37879 (7%)]\tLoss: 0.555835\n",
      "Train Epoch: 2 [3200/37879 (8%)]\tLoss: 0.369915\n",
      "Train Epoch: 2 [3840/37879 (10%)]\tLoss: 0.396039\n",
      "Train Epoch: 2 [4480/37879 (12%)]\tLoss: 0.341803\n",
      "Train Epoch: 2 [5120/37879 (14%)]\tLoss: 0.771756\n",
      "Train Epoch: 2 [5760/37879 (15%)]\tLoss: 0.625661\n",
      "Train Epoch: 2 [6400/37879 (17%)]\tLoss: 0.552396\n",
      "Train Epoch: 2 [7040/37879 (19%)]\tLoss: 0.640999\n",
      "Train Epoch: 2 [7680/37879 (20%)]\tLoss: 0.532902\n",
      "Train Epoch: 2 [8320/37879 (22%)]\tLoss: 0.288957\n",
      "Train Epoch: 2 [8960/37879 (24%)]\tLoss: 0.509177\n",
      "Train Epoch: 2 [9600/37879 (25%)]\tLoss: 0.479177\n",
      "Train Epoch: 2 [10240/37879 (27%)]\tLoss: 0.442193\n",
      "Train Epoch: 2 [10880/37879 (29%)]\tLoss: 0.439357\n",
      "Train Epoch: 2 [11520/37879 (30%)]\tLoss: 0.506216\n",
      "Train Epoch: 2 [12160/37879 (32%)]\tLoss: 0.373269\n",
      "Train Epoch: 2 [12800/37879 (34%)]\tLoss: 0.575321\n",
      "Train Epoch: 2 [13440/37879 (35%)]\tLoss: 0.408687\n",
      "Train Epoch: 2 [14080/37879 (37%)]\tLoss: 0.386689\n",
      "Train Epoch: 2 [14720/37879 (39%)]\tLoss: 0.487777\n",
      "Train Epoch: 2 [15360/37879 (41%)]\tLoss: 0.412588\n",
      "Train Epoch: 2 [16000/37879 (42%)]\tLoss: 0.552962\n",
      "Train Epoch: 2 [16640/37879 (44%)]\tLoss: 0.511310\n",
      "Train Epoch: 2 [17280/37879 (46%)]\tLoss: 0.366623\n",
      "Train Epoch: 2 [17920/37879 (47%)]\tLoss: 0.403761\n",
      "Train Epoch: 2 [18560/37879 (49%)]\tLoss: 0.491610\n",
      "Train Epoch: 2 [19200/37879 (51%)]\tLoss: 0.394374\n",
      "Train Epoch: 2 [19840/37879 (52%)]\tLoss: 0.383529\n",
      "Train Epoch: 2 [20480/37879 (54%)]\tLoss: 0.706718\n",
      "Train Epoch: 2 [21120/37879 (56%)]\tLoss: 0.390356\n",
      "Train Epoch: 2 [21760/37879 (57%)]\tLoss: 0.287329\n",
      "Train Epoch: 2 [22400/37879 (59%)]\tLoss: 0.786878\n",
      "Train Epoch: 2 [23040/37879 (61%)]\tLoss: 0.390305\n",
      "Train Epoch: 2 [23680/37879 (62%)]\tLoss: 0.481159\n",
      "Train Epoch: 2 [24320/37879 (64%)]\tLoss: 0.419160\n",
      "Train Epoch: 2 [24960/37879 (66%)]\tLoss: 0.399486\n",
      "Train Epoch: 2 [25600/37879 (68%)]\tLoss: 0.442824\n",
      "Train Epoch: 2 [26240/37879 (69%)]\tLoss: 0.377108\n",
      "Train Epoch: 2 [26880/37879 (71%)]\tLoss: 0.610981\n",
      "Train Epoch: 2 [27520/37879 (73%)]\tLoss: 0.420406\n",
      "Train Epoch: 2 [28160/37879 (74%)]\tLoss: 0.391940\n",
      "Train Epoch: 2 [28800/37879 (76%)]\tLoss: 0.290409\n",
      "Train Epoch: 2 [29440/37879 (78%)]\tLoss: 0.295250\n",
      "Train Epoch: 2 [30080/37879 (79%)]\tLoss: 0.545701\n",
      "Train Epoch: 2 [30720/37879 (81%)]\tLoss: 0.382176\n",
      "Train Epoch: 2 [31360/37879 (83%)]\tLoss: 0.435755\n",
      "Train Epoch: 2 [32000/37879 (84%)]\tLoss: 0.430288\n",
      "Train Epoch: 2 [32640/37879 (86%)]\tLoss: 0.282566\n",
      "Train Epoch: 2 [33280/37879 (88%)]\tLoss: 0.636971\n",
      "Train Epoch: 2 [33920/37879 (90%)]\tLoss: 0.334715\n",
      "Train Epoch: 2 [34560/37879 (91%)]\tLoss: 0.386327\n",
      "Train Epoch: 2 [35200/37879 (93%)]\tLoss: 0.341850\n",
      "Train Epoch: 2 [35840/37879 (95%)]\tLoss: 0.353684\n",
      "Train Epoch: 2 [36480/37879 (96%)]\tLoss: 0.164275\n",
      "Train Epoch: 2 [37120/37879 (98%)]\tLoss: 0.414685\n",
      "Train Epoch: 2 [37760/37879 (100%)]\tLoss: 0.401946\n",
      "\n",
      "Test set: Avg. loss: 0.2312, Accuracy: 9270/10000 (92%)\n",
      "\n",
      "Train Epoch: 3 [0/37879 (0%)]\tLoss: 0.453574\n",
      "Train Epoch: 3 [640/37879 (2%)]\tLoss: 0.437813\n",
      "Train Epoch: 3 [1280/37879 (3%)]\tLoss: 0.386955\n",
      "Train Epoch: 3 [1920/37879 (5%)]\tLoss: 0.333631\n",
      "Train Epoch: 3 [2560/37879 (7%)]\tLoss: 0.321180\n",
      "Train Epoch: 3 [3200/37879 (8%)]\tLoss: 0.324144\n",
      "Train Epoch: 3 [3840/37879 (10%)]\tLoss: 0.423079\n",
      "Train Epoch: 3 [4480/37879 (12%)]\tLoss: 0.401442\n",
      "Train Epoch: 3 [5120/37879 (14%)]\tLoss: 0.487038\n",
      "Train Epoch: 3 [5760/37879 (15%)]\tLoss: 0.379452\n",
      "Train Epoch: 3 [6400/37879 (17%)]\tLoss: 0.392988\n",
      "Train Epoch: 3 [7040/37879 (19%)]\tLoss: 0.528743\n",
      "Train Epoch: 3 [7680/37879 (20%)]\tLoss: 0.450453\n",
      "Train Epoch: 3 [8320/37879 (22%)]\tLoss: 0.441390\n",
      "Train Epoch: 3 [8960/37879 (24%)]\tLoss: 0.294163\n",
      "Train Epoch: 3 [9600/37879 (25%)]\tLoss: 0.315070\n",
      "Train Epoch: 3 [10240/37879 (27%)]\tLoss: 0.438601\n",
      "Train Epoch: 3 [10880/37879 (29%)]\tLoss: 0.438140\n",
      "Train Epoch: 3 [11520/37879 (30%)]\tLoss: 0.368312\n",
      "Train Epoch: 3 [12160/37879 (32%)]\tLoss: 0.399812\n",
      "Train Epoch: 3 [12800/37879 (34%)]\tLoss: 0.504188\n",
      "Train Epoch: 3 [13440/37879 (35%)]\tLoss: 0.382013\n",
      "Train Epoch: 3 [14080/37879 (37%)]\tLoss: 0.281539\n",
      "Train Epoch: 3 [14720/37879 (39%)]\tLoss: 0.583639\n",
      "Train Epoch: 3 [15360/37879 (41%)]\tLoss: 0.456600\n",
      "Train Epoch: 3 [16000/37879 (42%)]\tLoss: 0.372935\n",
      "Train Epoch: 3 [16640/37879 (44%)]\tLoss: 0.342533\n",
      "Train Epoch: 3 [17280/37879 (46%)]\tLoss: 0.288454\n",
      "Train Epoch: 3 [17920/37879 (47%)]\tLoss: 0.373592\n",
      "Train Epoch: 3 [18560/37879 (49%)]\tLoss: 0.416839\n",
      "Train Epoch: 3 [19200/37879 (51%)]\tLoss: 0.323327\n",
      "Train Epoch: 3 [19840/37879 (52%)]\tLoss: 0.348557\n",
      "Train Epoch: 3 [20480/37879 (54%)]\tLoss: 0.195255\n",
      "Train Epoch: 3 [21120/37879 (56%)]\tLoss: 0.249015\n",
      "Train Epoch: 3 [21760/37879 (57%)]\tLoss: 0.287167\n",
      "Train Epoch: 3 [22400/37879 (59%)]\tLoss: 0.467706\n",
      "Train Epoch: 3 [23040/37879 (61%)]\tLoss: 0.218379\n",
      "Train Epoch: 3 [23680/37879 (62%)]\tLoss: 0.303971\n",
      "Train Epoch: 3 [24320/37879 (64%)]\tLoss: 0.587138\n",
      "Train Epoch: 3 [24960/37879 (66%)]\tLoss: 0.393809\n",
      "Train Epoch: 3 [25600/37879 (68%)]\tLoss: 0.511942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [26240/37879 (69%)]\tLoss: 0.363911\n",
      "Train Epoch: 3 [26880/37879 (71%)]\tLoss: 0.253221\n",
      "Train Epoch: 3 [27520/37879 (73%)]\tLoss: 0.301979\n",
      "Train Epoch: 3 [28160/37879 (74%)]\tLoss: 0.247773\n",
      "Train Epoch: 3 [28800/37879 (76%)]\tLoss: 0.186360\n",
      "Train Epoch: 3 [29440/37879 (78%)]\tLoss: 0.356955\n",
      "Train Epoch: 3 [30080/37879 (79%)]\tLoss: 0.459314\n",
      "Train Epoch: 3 [30720/37879 (81%)]\tLoss: 0.446502\n",
      "Train Epoch: 3 [31360/37879 (83%)]\tLoss: 0.304301\n",
      "Train Epoch: 3 [32000/37879 (84%)]\tLoss: 0.236717\n",
      "Train Epoch: 3 [32640/37879 (86%)]\tLoss: 0.407321\n",
      "Train Epoch: 3 [33280/37879 (88%)]\tLoss: 0.298918\n",
      "Train Epoch: 3 [33920/37879 (90%)]\tLoss: 0.432759\n",
      "Train Epoch: 3 [34560/37879 (91%)]\tLoss: 0.499624\n",
      "Train Epoch: 3 [35200/37879 (93%)]\tLoss: 0.409138\n",
      "Train Epoch: 3 [35840/37879 (95%)]\tLoss: 0.289726\n",
      "Train Epoch: 3 [36480/37879 (96%)]\tLoss: 0.190751\n",
      "Train Epoch: 3 [37120/37879 (98%)]\tLoss: 0.165487\n",
      "Train Epoch: 3 [37760/37879 (100%)]\tLoss: 0.251263\n",
      "\n",
      "Test set: Avg. loss: 0.1620, Accuracy: 9525/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/37879 (0%)]\tLoss: 0.382505\n",
      "Train Epoch: 4 [640/37879 (2%)]\tLoss: 0.384730\n",
      "Train Epoch: 4 [1280/37879 (3%)]\tLoss: 0.380249\n",
      "Train Epoch: 4 [1920/37879 (5%)]\tLoss: 0.376155\n",
      "Train Epoch: 4 [2560/37879 (7%)]\tLoss: 0.418900\n",
      "Train Epoch: 4 [3200/37879 (8%)]\tLoss: 0.294559\n",
      "Train Epoch: 4 [3840/37879 (10%)]\tLoss: 0.365692\n",
      "Train Epoch: 4 [4480/37879 (12%)]\tLoss: 0.374817\n",
      "Train Epoch: 4 [5120/37879 (14%)]\tLoss: 0.417436\n",
      "Train Epoch: 4 [5760/37879 (15%)]\tLoss: 0.274168\n",
      "Train Epoch: 4 [6400/37879 (17%)]\tLoss: 0.331709\n",
      "Train Epoch: 4 [7040/37879 (19%)]\tLoss: 0.363976\n",
      "Train Epoch: 4 [7680/37879 (20%)]\tLoss: 0.223750\n",
      "Train Epoch: 4 [8320/37879 (22%)]\tLoss: 0.275503\n",
      "Train Epoch: 4 [8960/37879 (24%)]\tLoss: 0.374863\n",
      "Train Epoch: 4 [9600/37879 (25%)]\tLoss: 0.220533\n",
      "Train Epoch: 4 [10240/37879 (27%)]\tLoss: 0.204582\n",
      "Train Epoch: 4 [10880/37879 (29%)]\tLoss: 0.139473\n",
      "Train Epoch: 4 [11520/37879 (30%)]\tLoss: 0.296048\n",
      "Train Epoch: 4 [12160/37879 (32%)]\tLoss: 0.428597\n",
      "Train Epoch: 4 [12800/37879 (34%)]\tLoss: 0.246912\n",
      "Train Epoch: 4 [13440/37879 (35%)]\tLoss: 0.161596\n",
      "Train Epoch: 4 [14080/37879 (37%)]\tLoss: 0.307396\n",
      "Train Epoch: 4 [14720/37879 (39%)]\tLoss: 0.540764\n",
      "Train Epoch: 4 [15360/37879 (41%)]\tLoss: 0.414478\n",
      "Train Epoch: 4 [16000/37879 (42%)]\tLoss: 0.213330\n",
      "Train Epoch: 4 [16640/37879 (44%)]\tLoss: 0.226177\n",
      "Train Epoch: 4 [17280/37879 (46%)]\tLoss: 0.267190\n",
      "Train Epoch: 4 [17920/37879 (47%)]\tLoss: 0.222970\n",
      "Train Epoch: 4 [18560/37879 (49%)]\tLoss: 0.467035\n",
      "Train Epoch: 4 [19200/37879 (51%)]\tLoss: 0.269876\n",
      "Train Epoch: 4 [19840/37879 (52%)]\tLoss: 0.284997\n",
      "Train Epoch: 4 [20480/37879 (54%)]\tLoss: 0.440394\n",
      "Train Epoch: 4 [21120/37879 (56%)]\tLoss: 0.211711\n",
      "Train Epoch: 4 [21760/37879 (57%)]\tLoss: 0.376799\n",
      "Train Epoch: 4 [22400/37879 (59%)]\tLoss: 0.190909\n",
      "Train Epoch: 4 [23040/37879 (61%)]\tLoss: 0.463402\n",
      "Train Epoch: 4 [23680/37879 (62%)]\tLoss: 0.414739\n",
      "Train Epoch: 4 [24320/37879 (64%)]\tLoss: 0.453971\n",
      "Train Epoch: 4 [24960/37879 (66%)]\tLoss: 0.223439\n",
      "Train Epoch: 4 [25600/37879 (68%)]\tLoss: 0.178548\n",
      "Train Epoch: 4 [26240/37879 (69%)]\tLoss: 0.306677\n",
      "Train Epoch: 4 [26880/37879 (71%)]\tLoss: 0.429018\n",
      "Train Epoch: 4 [27520/37879 (73%)]\tLoss: 0.391042\n",
      "Train Epoch: 4 [28160/37879 (74%)]\tLoss: 0.208241\n",
      "Train Epoch: 4 [28800/37879 (76%)]\tLoss: 0.434504\n",
      "Train Epoch: 4 [29440/37879 (78%)]\tLoss: 0.266753\n",
      "Train Epoch: 4 [30080/37879 (79%)]\tLoss: 0.335908\n",
      "Train Epoch: 4 [30720/37879 (81%)]\tLoss: 0.283942\n",
      "Train Epoch: 4 [31360/37879 (83%)]\tLoss: 0.369818\n",
      "Train Epoch: 4 [32000/37879 (84%)]\tLoss: 0.258562\n",
      "Train Epoch: 4 [32640/37879 (86%)]\tLoss: 0.326202\n",
      "Train Epoch: 4 [33280/37879 (88%)]\tLoss: 0.189920\n",
      "Train Epoch: 4 [33920/37879 (90%)]\tLoss: 0.271768\n",
      "Train Epoch: 4 [34560/37879 (91%)]\tLoss: 0.205749\n",
      "Train Epoch: 4 [35200/37879 (93%)]\tLoss: 0.166349\n",
      "Train Epoch: 4 [35840/37879 (95%)]\tLoss: 0.313572\n",
      "Train Epoch: 4 [36480/37879 (96%)]\tLoss: 0.213908\n",
      "Train Epoch: 4 [37120/37879 (98%)]\tLoss: 0.320821\n",
      "Train Epoch: 4 [37760/37879 (100%)]\tLoss: 0.296236\n",
      "\n",
      "Test set: Avg. loss: 0.1529, Accuracy: 9546/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/37879 (0%)]\tLoss: 0.453819\n",
      "Train Epoch: 5 [640/37879 (2%)]\tLoss: 0.270255\n",
      "Train Epoch: 5 [1280/37879 (3%)]\tLoss: 0.187827\n",
      "Train Epoch: 5 [1920/37879 (5%)]\tLoss: 0.224130\n",
      "Train Epoch: 5 [2560/37879 (7%)]\tLoss: 0.175608\n",
      "Train Epoch: 5 [3200/37879 (8%)]\tLoss: 0.223235\n",
      "Train Epoch: 5 [3840/37879 (10%)]\tLoss: 0.435004\n",
      "Train Epoch: 5 [4480/37879 (12%)]\tLoss: 0.271922\n",
      "Train Epoch: 5 [5120/37879 (14%)]\tLoss: 0.323162\n",
      "Train Epoch: 5 [5760/37879 (15%)]\tLoss: 0.389417\n",
      "Train Epoch: 5 [6400/37879 (17%)]\tLoss: 0.230564\n",
      "Train Epoch: 5 [7040/37879 (19%)]\tLoss: 0.123798\n",
      "Train Epoch: 5 [7680/37879 (20%)]\tLoss: 0.321405\n",
      "Train Epoch: 5 [8320/37879 (22%)]\tLoss: 0.276131\n",
      "Train Epoch: 5 [8960/37879 (24%)]\tLoss: 0.338157\n",
      "Train Epoch: 5 [9600/37879 (25%)]\tLoss: 0.329572\n",
      "Train Epoch: 5 [10240/37879 (27%)]\tLoss: 0.172616\n",
      "Train Epoch: 5 [10880/37879 (29%)]\tLoss: 0.236655\n",
      "Train Epoch: 5 [11520/37879 (30%)]\tLoss: 0.214090\n",
      "Train Epoch: 5 [12160/37879 (32%)]\tLoss: 0.196060\n",
      "Train Epoch: 5 [12800/37879 (34%)]\tLoss: 0.267631\n",
      "Train Epoch: 5 [13440/37879 (35%)]\tLoss: 0.410826\n",
      "Train Epoch: 5 [14080/37879 (37%)]\tLoss: 0.194279\n",
      "Train Epoch: 5 [14720/37879 (39%)]\tLoss: 0.125944\n",
      "Train Epoch: 5 [15360/37879 (41%)]\tLoss: 0.244863\n",
      "Train Epoch: 5 [16000/37879 (42%)]\tLoss: 0.142836\n",
      "Train Epoch: 5 [16640/37879 (44%)]\tLoss: 0.260883\n",
      "Train Epoch: 5 [17280/37879 (46%)]\tLoss: 0.187687\n",
      "Train Epoch: 5 [17920/37879 (47%)]\tLoss: 0.160175\n",
      "Train Epoch: 5 [18560/37879 (49%)]\tLoss: 0.318638\n",
      "Train Epoch: 5 [19200/37879 (51%)]\tLoss: 0.314866\n",
      "Train Epoch: 5 [19840/37879 (52%)]\tLoss: 0.437446\n",
      "Train Epoch: 5 [20480/37879 (54%)]\tLoss: 0.230881\n",
      "Train Epoch: 5 [21120/37879 (56%)]\tLoss: 0.310605\n",
      "Train Epoch: 5 [21760/37879 (57%)]\tLoss: 0.499280\n",
      "Train Epoch: 5 [22400/37879 (59%)]\tLoss: 0.210915\n",
      "Train Epoch: 5 [23040/37879 (61%)]\tLoss: 0.145911\n",
      "Train Epoch: 5 [23680/37879 (62%)]\tLoss: 0.494461\n",
      "Train Epoch: 5 [24320/37879 (64%)]\tLoss: 0.507287\n",
      "Train Epoch: 5 [24960/37879 (66%)]\tLoss: 0.452740\n",
      "Train Epoch: 5 [25600/37879 (68%)]\tLoss: 0.150555\n",
      "Train Epoch: 5 [26240/37879 (69%)]\tLoss: 0.253613\n",
      "Train Epoch: 5 [26880/37879 (71%)]\tLoss: 0.337422\n",
      "Train Epoch: 5 [27520/37879 (73%)]\tLoss: 0.370682\n",
      "Train Epoch: 5 [28160/37879 (74%)]\tLoss: 0.291052\n",
      "Train Epoch: 5 [28800/37879 (76%)]\tLoss: 0.427693\n",
      "Train Epoch: 5 [29440/37879 (78%)]\tLoss: 0.188791\n",
      "Train Epoch: 5 [30080/37879 (79%)]\tLoss: 0.385305\n",
      "Train Epoch: 5 [30720/37879 (81%)]\tLoss: 0.355107\n",
      "Train Epoch: 5 [31360/37879 (83%)]\tLoss: 0.266301\n",
      "Train Epoch: 5 [32000/37879 (84%)]\tLoss: 0.146283\n",
      "Train Epoch: 5 [32640/37879 (86%)]\tLoss: 0.263948\n",
      "Train Epoch: 5 [33280/37879 (88%)]\tLoss: 0.265025\n",
      "Train Epoch: 5 [33920/37879 (90%)]\tLoss: 0.316513\n",
      "Train Epoch: 5 [34560/37879 (91%)]\tLoss: 0.265608\n",
      "Train Epoch: 5 [35200/37879 (93%)]\tLoss: 0.278289\n",
      "Train Epoch: 5 [35840/37879 (95%)]\tLoss: 0.326568\n",
      "Train Epoch: 5 [36480/37879 (96%)]\tLoss: 0.311249\n",
      "Train Epoch: 5 [37120/37879 (98%)]\tLoss: 0.460988\n",
      "Train Epoch: 5 [37760/37879 (100%)]\tLoss: 0.409479\n",
      "\n",
      "Test set: Avg. loss: 0.1235, Accuracy: 9621/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/37879 (0%)]\tLoss: 0.271733\n",
      "Train Epoch: 6 [640/37879 (2%)]\tLoss: 0.241798\n",
      "Train Epoch: 6 [1280/37879 (3%)]\tLoss: 0.178485\n",
      "Train Epoch: 6 [1920/37879 (5%)]\tLoss: 0.260426\n",
      "Train Epoch: 6 [2560/37879 (7%)]\tLoss: 0.316544\n",
      "Train Epoch: 6 [3200/37879 (8%)]\tLoss: 0.246303\n",
      "Train Epoch: 6 [3840/37879 (10%)]\tLoss: 0.170475\n",
      "Train Epoch: 6 [4480/37879 (12%)]\tLoss: 0.341852\n",
      "Train Epoch: 6 [5120/37879 (14%)]\tLoss: 0.356144\n",
      "Train Epoch: 6 [5760/37879 (15%)]\tLoss: 0.529272\n",
      "Train Epoch: 6 [6400/37879 (17%)]\tLoss: 0.322108\n",
      "Train Epoch: 6 [7040/37879 (19%)]\tLoss: 0.277856\n",
      "Train Epoch: 6 [7680/37879 (20%)]\tLoss: 0.129779\n",
      "Train Epoch: 6 [8320/37879 (22%)]\tLoss: 0.302173\n",
      "Train Epoch: 6 [8960/37879 (24%)]\tLoss: 0.300277\n",
      "Train Epoch: 6 [9600/37879 (25%)]\tLoss: 0.203282\n",
      "Train Epoch: 6 [10240/37879 (27%)]\tLoss: 0.128759\n",
      "Train Epoch: 6 [10880/37879 (29%)]\tLoss: 0.369134\n",
      "Train Epoch: 6 [11520/37879 (30%)]\tLoss: 0.219523\n",
      "Train Epoch: 6 [12160/37879 (32%)]\tLoss: 0.220381\n",
      "Train Epoch: 6 [12800/37879 (34%)]\tLoss: 0.272926\n",
      "Train Epoch: 6 [13440/37879 (35%)]\tLoss: 0.359047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [14080/37879 (37%)]\tLoss: 0.216439\n",
      "Train Epoch: 6 [14720/37879 (39%)]\tLoss: 0.343038\n",
      "Train Epoch: 6 [15360/37879 (41%)]\tLoss: 0.233961\n",
      "Train Epoch: 6 [16000/37879 (42%)]\tLoss: 0.304751\n",
      "Train Epoch: 6 [16640/37879 (44%)]\tLoss: 0.274366\n",
      "Train Epoch: 6 [17280/37879 (46%)]\tLoss: 0.182324\n",
      "Train Epoch: 6 [17920/37879 (47%)]\tLoss: 0.246447\n",
      "Train Epoch: 6 [18560/37879 (49%)]\tLoss: 0.282509\n",
      "Train Epoch: 6 [19200/37879 (51%)]\tLoss: 0.371742\n",
      "Train Epoch: 6 [19840/37879 (52%)]\tLoss: 0.224015\n",
      "Train Epoch: 6 [20480/37879 (54%)]\tLoss: 0.176263\n",
      "Train Epoch: 6 [21120/37879 (56%)]\tLoss: 0.159558\n",
      "Train Epoch: 6 [21760/37879 (57%)]\tLoss: 0.316154\n",
      "Train Epoch: 6 [22400/37879 (59%)]\tLoss: 0.202394\n",
      "Train Epoch: 6 [23040/37879 (61%)]\tLoss: 0.358025\n",
      "Train Epoch: 6 [23680/37879 (62%)]\tLoss: 0.370010\n",
      "Train Epoch: 6 [24320/37879 (64%)]\tLoss: 0.318487\n",
      "Train Epoch: 6 [24960/37879 (66%)]\tLoss: 0.268421\n",
      "Train Epoch: 6 [25600/37879 (68%)]\tLoss: 0.256029\n",
      "Train Epoch: 6 [26240/37879 (69%)]\tLoss: 0.406107\n",
      "Train Epoch: 6 [26880/37879 (71%)]\tLoss: 0.189256\n",
      "Train Epoch: 6 [27520/37879 (73%)]\tLoss: 0.322588\n",
      "Train Epoch: 6 [28160/37879 (74%)]\tLoss: 0.444766\n",
      "Train Epoch: 6 [28800/37879 (76%)]\tLoss: 0.307873\n",
      "Train Epoch: 6 [29440/37879 (78%)]\tLoss: 0.109528\n",
      "Train Epoch: 6 [30080/37879 (79%)]\tLoss: 0.096386\n",
      "Train Epoch: 6 [30720/37879 (81%)]\tLoss: 0.272124\n",
      "Train Epoch: 6 [31360/37879 (83%)]\tLoss: 0.210481\n",
      "Train Epoch: 6 [32000/37879 (84%)]\tLoss: 0.159309\n",
      "Train Epoch: 6 [32640/37879 (86%)]\tLoss: 0.268661\n",
      "Train Epoch: 6 [33280/37879 (88%)]\tLoss: 0.269479\n",
      "Train Epoch: 6 [33920/37879 (90%)]\tLoss: 0.142240\n",
      "Train Epoch: 6 [34560/37879 (91%)]\tLoss: 0.494082\n",
      "Train Epoch: 6 [35200/37879 (93%)]\tLoss: 0.268157\n",
      "Train Epoch: 6 [35840/37879 (95%)]\tLoss: 0.372447\n",
      "Train Epoch: 6 [36480/37879 (96%)]\tLoss: 0.258854\n",
      "Train Epoch: 6 [37120/37879 (98%)]\tLoss: 0.158427\n",
      "Train Epoch: 6 [37760/37879 (100%)]\tLoss: 0.151732\n",
      "\n",
      "Test set: Avg. loss: 0.1134, Accuracy: 9659/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/37879 (0%)]\tLoss: 0.273739\n",
      "Train Epoch: 7 [640/37879 (2%)]\tLoss: 0.354858\n",
      "Train Epoch: 7 [1280/37879 (3%)]\tLoss: 0.159904\n",
      "Train Epoch: 7 [1920/37879 (5%)]\tLoss: 0.395658\n",
      "Train Epoch: 7 [2560/37879 (7%)]\tLoss: 0.158186\n",
      "Train Epoch: 7 [3200/37879 (8%)]\tLoss: 0.279872\n",
      "Train Epoch: 7 [3840/37879 (10%)]\tLoss: 0.122528\n",
      "Train Epoch: 7 [4480/37879 (12%)]\tLoss: 0.327240\n",
      "Train Epoch: 7 [5120/37879 (14%)]\tLoss: 0.183930\n",
      "Train Epoch: 7 [5760/37879 (15%)]\tLoss: 0.352261\n",
      "Train Epoch: 7 [6400/37879 (17%)]\tLoss: 0.223018\n",
      "Train Epoch: 7 [7040/37879 (19%)]\tLoss: 0.178033\n",
      "Train Epoch: 7 [7680/37879 (20%)]\tLoss: 0.232415\n",
      "Train Epoch: 7 [8320/37879 (22%)]\tLoss: 0.392144\n",
      "Train Epoch: 7 [8960/37879 (24%)]\tLoss: 0.227545\n",
      "Train Epoch: 7 [9600/37879 (25%)]\tLoss: 0.158358\n",
      "Train Epoch: 7 [10240/37879 (27%)]\tLoss: 0.388420\n",
      "Train Epoch: 7 [10880/37879 (29%)]\tLoss: 0.207494\n",
      "Train Epoch: 7 [11520/37879 (30%)]\tLoss: 0.199768\n",
      "Train Epoch: 7 [12160/37879 (32%)]\tLoss: 0.133799\n",
      "Train Epoch: 7 [12800/37879 (34%)]\tLoss: 0.159971\n",
      "Train Epoch: 7 [13440/37879 (35%)]\tLoss: 0.303270\n",
      "Train Epoch: 7 [14080/37879 (37%)]\tLoss: 0.143647\n",
      "Train Epoch: 7 [14720/37879 (39%)]\tLoss: 0.235946\n",
      "Train Epoch: 7 [15360/37879 (41%)]\tLoss: 0.199211\n",
      "Train Epoch: 7 [16000/37879 (42%)]\tLoss: 0.124419\n",
      "Train Epoch: 7 [16640/37879 (44%)]\tLoss: 0.183577\n",
      "Train Epoch: 7 [17280/37879 (46%)]\tLoss: 0.174362\n",
      "Train Epoch: 7 [17920/37879 (47%)]\tLoss: 0.353686\n",
      "Train Epoch: 7 [18560/37879 (49%)]\tLoss: 0.327909\n",
      "Train Epoch: 7 [19200/37879 (51%)]\tLoss: 0.227747\n",
      "Train Epoch: 7 [19840/37879 (52%)]\tLoss: 0.092490\n",
      "Train Epoch: 7 [20480/37879 (54%)]\tLoss: 0.156234\n",
      "Train Epoch: 7 [21120/37879 (56%)]\tLoss: 0.266603\n",
      "Train Epoch: 7 [21760/37879 (57%)]\tLoss: 0.204316\n",
      "Train Epoch: 7 [22400/37879 (59%)]\tLoss: 0.183841\n",
      "Train Epoch: 7 [23040/37879 (61%)]\tLoss: 0.265191\n",
      "Train Epoch: 7 [23680/37879 (62%)]\tLoss: 0.290984\n",
      "Train Epoch: 7 [24320/37879 (64%)]\tLoss: 0.134425\n",
      "Train Epoch: 7 [24960/37879 (66%)]\tLoss: 0.275785\n",
      "Train Epoch: 7 [25600/37879 (68%)]\tLoss: 0.322317\n",
      "Train Epoch: 7 [26240/37879 (69%)]\tLoss: 0.303879\n",
      "Train Epoch: 7 [26880/37879 (71%)]\tLoss: 0.140072\n",
      "Train Epoch: 7 [27520/37879 (73%)]\tLoss: 0.326066\n",
      "Train Epoch: 7 [28160/37879 (74%)]\tLoss: 0.178491\n",
      "Train Epoch: 7 [28800/37879 (76%)]\tLoss: 0.342200\n",
      "Train Epoch: 7 [29440/37879 (78%)]\tLoss: 0.197532\n",
      "Train Epoch: 7 [30080/37879 (79%)]\tLoss: 0.117235\n",
      "Train Epoch: 7 [30720/37879 (81%)]\tLoss: 0.217169\n",
      "Train Epoch: 7 [31360/37879 (83%)]\tLoss: 0.154075\n",
      "Train Epoch: 7 [32000/37879 (84%)]\tLoss: 0.095256\n",
      "Train Epoch: 7 [32640/37879 (86%)]\tLoss: 0.121384\n",
      "Train Epoch: 7 [33280/37879 (88%)]\tLoss: 0.155133\n",
      "Train Epoch: 7 [33920/37879 (90%)]\tLoss: 0.207242\n",
      "Train Epoch: 7 [34560/37879 (91%)]\tLoss: 0.146182\n",
      "Train Epoch: 7 [35200/37879 (93%)]\tLoss: 0.337431\n",
      "Train Epoch: 7 [35840/37879 (95%)]\tLoss: 0.147488\n",
      "Train Epoch: 7 [36480/37879 (96%)]\tLoss: 0.302470\n",
      "Train Epoch: 7 [37120/37879 (98%)]\tLoss: 0.460040\n",
      "Train Epoch: 7 [37760/37879 (100%)]\tLoss: 0.442414\n",
      "\n",
      "Test set: Avg. loss: 0.1136, Accuracy: 9667/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/37879 (0%)]\tLoss: 0.184146\n",
      "Train Epoch: 8 [640/37879 (2%)]\tLoss: 0.268721\n",
      "Train Epoch: 8 [1280/37879 (3%)]\tLoss: 0.233262\n",
      "Train Epoch: 8 [1920/37879 (5%)]\tLoss: 0.213842\n",
      "Train Epoch: 8 [2560/37879 (7%)]\tLoss: 0.094676\n",
      "Train Epoch: 8 [3200/37879 (8%)]\tLoss: 0.223484\n",
      "Train Epoch: 8 [3840/37879 (10%)]\tLoss: 0.163398\n",
      "Train Epoch: 8 [4480/37879 (12%)]\tLoss: 0.368433\n",
      "Train Epoch: 8 [5120/37879 (14%)]\tLoss: 0.212353\n",
      "Train Epoch: 8 [5760/37879 (15%)]\tLoss: 0.375526\n",
      "Train Epoch: 8 [6400/37879 (17%)]\tLoss: 0.323256\n",
      "Train Epoch: 8 [7040/37879 (19%)]\tLoss: 0.194069\n",
      "Train Epoch: 8 [7680/37879 (20%)]\tLoss: 0.423828\n",
      "Train Epoch: 8 [8320/37879 (22%)]\tLoss: 0.184148\n",
      "Train Epoch: 8 [8960/37879 (24%)]\tLoss: 0.216493\n",
      "Train Epoch: 8 [9600/37879 (25%)]\tLoss: 0.203499\n",
      "Train Epoch: 8 [10240/37879 (27%)]\tLoss: 0.188915\n",
      "Train Epoch: 8 [10880/37879 (29%)]\tLoss: 0.133147\n",
      "Train Epoch: 8 [11520/37879 (30%)]\tLoss: 0.128605\n",
      "Train Epoch: 8 [12160/37879 (32%)]\tLoss: 0.109866\n",
      "Train Epoch: 8 [12800/37879 (34%)]\tLoss: 0.088961\n",
      "Train Epoch: 8 [13440/37879 (35%)]\tLoss: 0.180951\n",
      "Train Epoch: 8 [14080/37879 (37%)]\tLoss: 0.200597\n",
      "Train Epoch: 8 [14720/37879 (39%)]\tLoss: 0.218611\n",
      "Train Epoch: 8 [15360/37879 (41%)]\tLoss: 0.154032\n",
      "Train Epoch: 8 [16000/37879 (42%)]\tLoss: 0.269887\n",
      "Train Epoch: 8 [16640/37879 (44%)]\tLoss: 0.129888\n",
      "Train Epoch: 8 [17280/37879 (46%)]\tLoss: 0.195497\n",
      "Train Epoch: 8 [17920/37879 (47%)]\tLoss: 0.210054\n",
      "Train Epoch: 8 [18560/37879 (49%)]\tLoss: 0.274282\n",
      "Train Epoch: 8 [19200/37879 (51%)]\tLoss: 0.309710\n",
      "Train Epoch: 8 [19840/37879 (52%)]\tLoss: 0.255228\n",
      "Train Epoch: 8 [20480/37879 (54%)]\tLoss: 0.200815\n",
      "Train Epoch: 8 [21120/37879 (56%)]\tLoss: 0.215501\n",
      "Train Epoch: 8 [21760/37879 (57%)]\tLoss: 0.171025\n",
      "Train Epoch: 8 [22400/37879 (59%)]\tLoss: 0.136225\n",
      "Train Epoch: 8 [23040/37879 (61%)]\tLoss: 0.374776\n",
      "Train Epoch: 8 [23680/37879 (62%)]\tLoss: 0.198212\n",
      "Train Epoch: 8 [24320/37879 (64%)]\tLoss: 0.182449\n",
      "Train Epoch: 8 [24960/37879 (66%)]\tLoss: 0.219862\n",
      "Train Epoch: 8 [25600/37879 (68%)]\tLoss: 0.225708\n",
      "Train Epoch: 8 [26240/37879 (69%)]\tLoss: 0.309574\n",
      "Train Epoch: 8 [26880/37879 (71%)]\tLoss: 0.185284\n",
      "Train Epoch: 8 [27520/37879 (73%)]\tLoss: 0.122934\n",
      "Train Epoch: 8 [28160/37879 (74%)]\tLoss: 0.264643\n",
      "Train Epoch: 8 [28800/37879 (76%)]\tLoss: 0.148236\n",
      "Train Epoch: 8 [29440/37879 (78%)]\tLoss: 0.270996\n",
      "Train Epoch: 8 [30080/37879 (79%)]\tLoss: 0.184656\n",
      "Train Epoch: 8 [30720/37879 (81%)]\tLoss: 0.198550\n",
      "Train Epoch: 8 [31360/37879 (83%)]\tLoss: 0.104873\n",
      "Train Epoch: 8 [32000/37879 (84%)]\tLoss: 0.179284\n",
      "Train Epoch: 8 [32640/37879 (86%)]\tLoss: 0.364566\n",
      "Train Epoch: 8 [33280/37879 (88%)]\tLoss: 0.132561\n",
      "Train Epoch: 8 [33920/37879 (90%)]\tLoss: 0.084096\n",
      "Train Epoch: 8 [34560/37879 (91%)]\tLoss: 0.501865\n",
      "Train Epoch: 8 [35200/37879 (93%)]\tLoss: 0.400355\n",
      "Train Epoch: 8 [35840/37879 (95%)]\tLoss: 0.188022\n",
      "Train Epoch: 8 [36480/37879 (96%)]\tLoss: 0.264581\n",
      "Train Epoch: 8 [37120/37879 (98%)]\tLoss: 0.274740\n",
      "Train Epoch: 8 [37760/37879 (100%)]\tLoss: 0.230842\n",
      "\n",
      "Test set: Avg. loss: 0.1046, Accuracy: 9691/10000 (96%)\n",
      "\n",
      "Train Epoch: 9 [0/37879 (0%)]\tLoss: 0.210318\n",
      "Train Epoch: 9 [640/37879 (2%)]\tLoss: 0.198074\n",
      "Train Epoch: 9 [1280/37879 (3%)]\tLoss: 0.267262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [1920/37879 (5%)]\tLoss: 0.188873\n",
      "Train Epoch: 9 [2560/37879 (7%)]\tLoss: 0.142705\n",
      "Train Epoch: 9 [3200/37879 (8%)]\tLoss: 0.442560\n",
      "Train Epoch: 9 [3840/37879 (10%)]\tLoss: 0.118739\n",
      "Train Epoch: 9 [4480/37879 (12%)]\tLoss: 0.146897\n",
      "Train Epoch: 9 [5120/37879 (14%)]\tLoss: 0.408047\n",
      "Train Epoch: 9 [5760/37879 (15%)]\tLoss: 0.277183\n",
      "Train Epoch: 9 [6400/37879 (17%)]\tLoss: 0.142143\n",
      "Train Epoch: 9 [7040/37879 (19%)]\tLoss: 0.209943\n",
      "Train Epoch: 9 [7680/37879 (20%)]\tLoss: 0.066885\n",
      "Train Epoch: 9 [8320/37879 (22%)]\tLoss: 0.227555\n",
      "Train Epoch: 9 [8960/37879 (24%)]\tLoss: 0.129380\n",
      "Train Epoch: 9 [9600/37879 (25%)]\tLoss: 0.121976\n",
      "Train Epoch: 9 [10240/37879 (27%)]\tLoss: 0.324117\n",
      "Train Epoch: 9 [10880/37879 (29%)]\tLoss: 0.274922\n",
      "Train Epoch: 9 [11520/37879 (30%)]\tLoss: 0.258980\n",
      "Train Epoch: 9 [12160/37879 (32%)]\tLoss: 0.256582\n",
      "Train Epoch: 9 [12800/37879 (34%)]\tLoss: 0.222292\n",
      "Train Epoch: 9 [13440/37879 (35%)]\tLoss: 0.228815\n",
      "Train Epoch: 9 [14080/37879 (37%)]\tLoss: 0.095956\n",
      "Train Epoch: 9 [14720/37879 (39%)]\tLoss: 0.231937\n",
      "Train Epoch: 9 [15360/37879 (41%)]\tLoss: 0.192909\n",
      "Train Epoch: 9 [16000/37879 (42%)]\tLoss: 0.117909\n",
      "Train Epoch: 9 [16640/37879 (44%)]\tLoss: 0.200458\n",
      "Train Epoch: 9 [17280/37879 (46%)]\tLoss: 0.278720\n",
      "Train Epoch: 9 [17920/37879 (47%)]\tLoss: 0.212484\n",
      "Train Epoch: 9 [18560/37879 (49%)]\tLoss: 0.131869\n",
      "Train Epoch: 9 [19200/37879 (51%)]\tLoss: 0.191348\n",
      "Train Epoch: 9 [19840/37879 (52%)]\tLoss: 0.274577\n",
      "Train Epoch: 9 [20480/37879 (54%)]\tLoss: 0.122722\n",
      "Train Epoch: 9 [21120/37879 (56%)]\tLoss: 0.183203\n",
      "Train Epoch: 9 [21760/37879 (57%)]\tLoss: 0.185623\n",
      "Train Epoch: 9 [22400/37879 (59%)]\tLoss: 0.314048\n",
      "Train Epoch: 9 [23040/37879 (61%)]\tLoss: 0.430542\n",
      "Train Epoch: 9 [23680/37879 (62%)]\tLoss: 0.255140\n",
      "Train Epoch: 9 [24320/37879 (64%)]\tLoss: 0.223385\n",
      "Train Epoch: 9 [24960/37879 (66%)]\tLoss: 0.155521\n",
      "Train Epoch: 9 [25600/37879 (68%)]\tLoss: 0.113335\n",
      "Train Epoch: 9 [26240/37879 (69%)]\tLoss: 0.201889\n",
      "Train Epoch: 9 [26880/37879 (71%)]\tLoss: 0.053500\n",
      "Train Epoch: 9 [27520/37879 (73%)]\tLoss: 0.218525\n",
      "Train Epoch: 9 [28160/37879 (74%)]\tLoss: 0.118411\n",
      "Train Epoch: 9 [28800/37879 (76%)]\tLoss: 0.193387\n",
      "Train Epoch: 9 [29440/37879 (78%)]\tLoss: 0.111297\n",
      "Train Epoch: 9 [30080/37879 (79%)]\tLoss: 0.170574\n",
      "Train Epoch: 9 [30720/37879 (81%)]\tLoss: 0.086572\n",
      "Train Epoch: 9 [31360/37879 (83%)]\tLoss: 0.277118\n",
      "Train Epoch: 9 [32000/37879 (84%)]\tLoss: 0.266883\n",
      "Train Epoch: 9 [32640/37879 (86%)]\tLoss: 0.233570\n",
      "Train Epoch: 9 [33280/37879 (88%)]\tLoss: 0.193444\n",
      "Train Epoch: 9 [33920/37879 (90%)]\tLoss: 0.128430\n",
      "Train Epoch: 9 [34560/37879 (91%)]\tLoss: 0.216877\n",
      "Train Epoch: 9 [35200/37879 (93%)]\tLoss: 0.178084\n",
      "Train Epoch: 9 [35840/37879 (95%)]\tLoss: 0.218885\n",
      "Train Epoch: 9 [36480/37879 (96%)]\tLoss: 0.347720\n",
      "Train Epoch: 9 [37120/37879 (98%)]\tLoss: 0.180777\n",
      "Train Epoch: 9 [37760/37879 (100%)]\tLoss: 0.245973\n",
      "\n",
      "Test set: Avg. loss: 0.0967, Accuracy: 9717/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/37879 (0%)]\tLoss: 0.185234\n",
      "Train Epoch: 10 [640/37879 (2%)]\tLoss: 0.185780\n",
      "Train Epoch: 10 [1280/37879 (3%)]\tLoss: 0.222770\n",
      "Train Epoch: 10 [1920/37879 (5%)]\tLoss: 0.327920\n",
      "Train Epoch: 10 [2560/37879 (7%)]\tLoss: 0.282049\n",
      "Train Epoch: 10 [3200/37879 (8%)]\tLoss: 0.163601\n",
      "Train Epoch: 10 [3840/37879 (10%)]\tLoss: 0.108707\n",
      "Train Epoch: 10 [4480/37879 (12%)]\tLoss: 0.230776\n",
      "Train Epoch: 10 [5120/37879 (14%)]\tLoss: 0.343712\n",
      "Train Epoch: 10 [5760/37879 (15%)]\tLoss: 0.170796\n",
      "Train Epoch: 10 [6400/37879 (17%)]\tLoss: 0.217346\n",
      "Train Epoch: 10 [7040/37879 (19%)]\tLoss: 0.490817\n",
      "Train Epoch: 10 [7680/37879 (20%)]\tLoss: 0.188344\n",
      "Train Epoch: 10 [8320/37879 (22%)]\tLoss: 0.178915\n",
      "Train Epoch: 10 [8960/37879 (24%)]\tLoss: 0.118243\n",
      "Train Epoch: 10 [9600/37879 (25%)]\tLoss: 0.241045\n",
      "Train Epoch: 10 [10240/37879 (27%)]\tLoss: 0.279879\n",
      "Train Epoch: 10 [10880/37879 (29%)]\tLoss: 0.168673\n",
      "Train Epoch: 10 [11520/37879 (30%)]\tLoss: 0.173418\n",
      "Train Epoch: 10 [12160/37879 (32%)]\tLoss: 0.229108\n",
      "Train Epoch: 10 [12800/37879 (34%)]\tLoss: 0.119549\n",
      "Train Epoch: 10 [13440/37879 (35%)]\tLoss: 0.133404\n",
      "Train Epoch: 10 [14080/37879 (37%)]\tLoss: 0.212125\n",
      "Train Epoch: 10 [14720/37879 (39%)]\tLoss: 0.082163\n",
      "Train Epoch: 10 [15360/37879 (41%)]\tLoss: 0.186315\n",
      "Train Epoch: 10 [16000/37879 (42%)]\tLoss: 0.164397\n",
      "Train Epoch: 10 [16640/37879 (44%)]\tLoss: 0.128795\n",
      "Train Epoch: 10 [17280/37879 (46%)]\tLoss: 0.340652\n",
      "Train Epoch: 10 [17920/37879 (47%)]\tLoss: 0.101457\n",
      "Train Epoch: 10 [18560/37879 (49%)]\tLoss: 0.379046\n",
      "Train Epoch: 10 [19200/37879 (51%)]\tLoss: 0.273216\n",
      "Train Epoch: 10 [19840/37879 (52%)]\tLoss: 0.135229\n",
      "Train Epoch: 10 [20480/37879 (54%)]\tLoss: 0.176815\n",
      "Train Epoch: 10 [21120/37879 (56%)]\tLoss: 0.408969\n",
      "Train Epoch: 10 [21760/37879 (57%)]\tLoss: 0.177701\n",
      "Train Epoch: 10 [22400/37879 (59%)]\tLoss: 0.112251\n",
      "Train Epoch: 10 [23040/37879 (61%)]\tLoss: 0.196893\n",
      "Train Epoch: 10 [23680/37879 (62%)]\tLoss: 0.173491\n",
      "Train Epoch: 10 [24320/37879 (64%)]\tLoss: 0.266357\n",
      "Train Epoch: 10 [24960/37879 (66%)]\tLoss: 0.354977\n",
      "Train Epoch: 10 [25600/37879 (68%)]\tLoss: 0.256040\n",
      "Train Epoch: 10 [26240/37879 (69%)]\tLoss: 0.344508\n",
      "Train Epoch: 10 [26880/37879 (71%)]\tLoss: 0.170272\n",
      "Train Epoch: 10 [27520/37879 (73%)]\tLoss: 0.370518\n",
      "Train Epoch: 10 [28160/37879 (74%)]\tLoss: 0.341187\n",
      "Train Epoch: 10 [28800/37879 (76%)]\tLoss: 0.174193\n",
      "Train Epoch: 10 [29440/37879 (78%)]\tLoss: 0.382986\n",
      "Train Epoch: 10 [30080/37879 (79%)]\tLoss: 0.173830\n",
      "Train Epoch: 10 [30720/37879 (81%)]\tLoss: 0.255301\n",
      "Train Epoch: 10 [31360/37879 (83%)]\tLoss: 0.193835\n",
      "Train Epoch: 10 [32000/37879 (84%)]\tLoss: 0.370662\n",
      "Train Epoch: 10 [32640/37879 (86%)]\tLoss: 0.127771\n",
      "Train Epoch: 10 [33280/37879 (88%)]\tLoss: 0.197089\n",
      "Train Epoch: 10 [33920/37879 (90%)]\tLoss: 0.137246\n",
      "Train Epoch: 10 [34560/37879 (91%)]\tLoss: 0.304286\n",
      "Train Epoch: 10 [35200/37879 (93%)]\tLoss: 0.227675\n",
      "Train Epoch: 10 [35840/37879 (95%)]\tLoss: 0.230512\n",
      "Train Epoch: 10 [36480/37879 (96%)]\tLoss: 0.246343\n",
      "Train Epoch: 10 [37120/37879 (98%)]\tLoss: 0.136977\n",
      "Train Epoch: 10 [37760/37879 (100%)]\tLoss: 0.585689\n",
      "\n",
      "Test set: Avg. loss: 0.0929, Accuracy: 9710/10000 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/37879 (0%)]\tLoss: 0.253238\n",
      "Train Epoch: 11 [640/37879 (2%)]\tLoss: 0.244963\n",
      "Train Epoch: 11 [1280/37879 (3%)]\tLoss: 0.440829\n",
      "Train Epoch: 11 [1920/37879 (5%)]\tLoss: 0.222168\n",
      "Train Epoch: 11 [2560/37879 (7%)]\tLoss: 0.206120\n",
      "Train Epoch: 11 [3200/37879 (8%)]\tLoss: 0.150744\n",
      "Train Epoch: 11 [3840/37879 (10%)]\tLoss: 0.132227\n",
      "Train Epoch: 11 [4480/37879 (12%)]\tLoss: 0.188861\n",
      "Train Epoch: 11 [5120/37879 (14%)]\tLoss: 0.171223\n",
      "Train Epoch: 11 [5760/37879 (15%)]\tLoss: 0.376832\n",
      "Train Epoch: 11 [6400/37879 (17%)]\tLoss: 0.461235\n",
      "Train Epoch: 11 [7040/37879 (19%)]\tLoss: 0.310349\n",
      "Train Epoch: 11 [7680/37879 (20%)]\tLoss: 0.223642\n",
      "Train Epoch: 11 [8320/37879 (22%)]\tLoss: 0.152625\n",
      "Train Epoch: 11 [8960/37879 (24%)]\tLoss: 0.120414\n",
      "Train Epoch: 11 [9600/37879 (25%)]\tLoss: 0.209378\n",
      "Train Epoch: 11 [10240/37879 (27%)]\tLoss: 0.369124\n",
      "Train Epoch: 11 [10880/37879 (29%)]\tLoss: 0.212431\n",
      "Train Epoch: 11 [11520/37879 (30%)]\tLoss: 0.075094\n",
      "Train Epoch: 11 [12160/37879 (32%)]\tLoss: 0.207919\n",
      "Train Epoch: 11 [12800/37879 (34%)]\tLoss: 0.224761\n",
      "Train Epoch: 11 [13440/37879 (35%)]\tLoss: 0.195105\n",
      "Train Epoch: 11 [14080/37879 (37%)]\tLoss: 0.068433\n",
      "Train Epoch: 11 [14720/37879 (39%)]\tLoss: 0.121105\n",
      "Train Epoch: 11 [15360/37879 (41%)]\tLoss: 0.216601\n",
      "Train Epoch: 11 [16000/37879 (42%)]\tLoss: 0.105964\n",
      "Train Epoch: 11 [16640/37879 (44%)]\tLoss: 0.212958\n",
      "Train Epoch: 11 [17280/37879 (46%)]\tLoss: 0.263504\n",
      "Train Epoch: 11 [17920/37879 (47%)]\tLoss: 0.202053\n",
      "Train Epoch: 11 [18560/37879 (49%)]\tLoss: 0.148916\n",
      "Train Epoch: 11 [19200/37879 (51%)]\tLoss: 0.277265\n",
      "Train Epoch: 11 [19840/37879 (52%)]\tLoss: 0.297373\n",
      "Train Epoch: 11 [20480/37879 (54%)]\tLoss: 0.243694\n",
      "Train Epoch: 11 [21120/37879 (56%)]\tLoss: 0.224760\n",
      "Train Epoch: 11 [21760/37879 (57%)]\tLoss: 0.220973\n",
      "Train Epoch: 11 [22400/37879 (59%)]\tLoss: 0.125729\n",
      "Train Epoch: 11 [23040/37879 (61%)]\tLoss: 0.205504\n",
      "Train Epoch: 11 [23680/37879 (62%)]\tLoss: 0.183521\n",
      "Train Epoch: 11 [24320/37879 (64%)]\tLoss: 0.155151\n",
      "Train Epoch: 11 [24960/37879 (66%)]\tLoss: 0.277442\n",
      "Train Epoch: 11 [25600/37879 (68%)]\tLoss: 0.254520\n",
      "Train Epoch: 11 [26240/37879 (69%)]\tLoss: 0.342587\n",
      "Train Epoch: 11 [26880/37879 (71%)]\tLoss: 0.233271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [27520/37879 (73%)]\tLoss: 0.162407\n",
      "Train Epoch: 11 [28160/37879 (74%)]\tLoss: 0.170332\n",
      "Train Epoch: 11 [28800/37879 (76%)]\tLoss: 0.100192\n",
      "Train Epoch: 11 [29440/37879 (78%)]\tLoss: 0.217332\n",
      "Train Epoch: 11 [30080/37879 (79%)]\tLoss: 0.095396\n",
      "Train Epoch: 11 [30720/37879 (81%)]\tLoss: 0.135011\n",
      "Train Epoch: 11 [31360/37879 (83%)]\tLoss: 0.274817\n",
      "Train Epoch: 11 [32000/37879 (84%)]\tLoss: 0.144821\n",
      "Train Epoch: 11 [32640/37879 (86%)]\tLoss: 0.130088\n",
      "Train Epoch: 11 [33280/37879 (88%)]\tLoss: 0.385734\n",
      "Train Epoch: 11 [33920/37879 (90%)]\tLoss: 0.382191\n",
      "Train Epoch: 11 [34560/37879 (91%)]\tLoss: 0.288041\n",
      "Train Epoch: 11 [35200/37879 (93%)]\tLoss: 0.197114\n",
      "Train Epoch: 11 [35840/37879 (95%)]\tLoss: 0.304863\n",
      "Train Epoch: 11 [36480/37879 (96%)]\tLoss: 0.128666\n",
      "Train Epoch: 11 [37120/37879 (98%)]\tLoss: 0.081832\n",
      "Train Epoch: 11 [37760/37879 (100%)]\tLoss: 0.228697\n",
      "\n",
      "Test set: Avg. loss: 0.0836, Accuracy: 9747/10000 (97%)\n",
      "\n",
      "Train Epoch: 12 [0/37879 (0%)]\tLoss: 0.409046\n",
      "Train Epoch: 12 [640/37879 (2%)]\tLoss: 0.162842\n",
      "Train Epoch: 12 [1280/37879 (3%)]\tLoss: 0.141590\n",
      "Train Epoch: 12 [1920/37879 (5%)]\tLoss: 0.169606\n",
      "Train Epoch: 12 [2560/37879 (7%)]\tLoss: 0.125353\n",
      "Train Epoch: 12 [3200/37879 (8%)]\tLoss: 0.138011\n",
      "Train Epoch: 12 [3840/37879 (10%)]\tLoss: 0.167101\n",
      "Train Epoch: 12 [4480/37879 (12%)]\tLoss: 0.307257\n",
      "Train Epoch: 12 [5120/37879 (14%)]\tLoss: 0.080482\n",
      "Train Epoch: 12 [5760/37879 (15%)]\tLoss: 0.265367\n",
      "Train Epoch: 12 [6400/37879 (17%)]\tLoss: 0.374032\n",
      "Train Epoch: 12 [7040/37879 (19%)]\tLoss: 0.195529\n",
      "Train Epoch: 12 [7680/37879 (20%)]\tLoss: 0.242340\n",
      "Train Epoch: 12 [8320/37879 (22%)]\tLoss: 0.238077\n",
      "Train Epoch: 12 [8960/37879 (24%)]\tLoss: 0.360274\n",
      "Train Epoch: 12 [9600/37879 (25%)]\tLoss: 0.090908\n",
      "Train Epoch: 12 [10240/37879 (27%)]\tLoss: 0.250679\n",
      "Train Epoch: 12 [10880/37879 (29%)]\tLoss: 0.226363\n",
      "Train Epoch: 12 [11520/37879 (30%)]\tLoss: 0.101413\n",
      "Train Epoch: 12 [12160/37879 (32%)]\tLoss: 0.157416\n",
      "Train Epoch: 12 [12800/37879 (34%)]\tLoss: 0.188610\n",
      "Train Epoch: 12 [13440/37879 (35%)]\tLoss: 0.365950\n",
      "Train Epoch: 12 [14080/37879 (37%)]\tLoss: 0.231976\n",
      "Train Epoch: 12 [14720/37879 (39%)]\tLoss: 0.086428\n",
      "Train Epoch: 12 [15360/37879 (41%)]\tLoss: 0.070556\n",
      "Train Epoch: 12 [16000/37879 (42%)]\tLoss: 0.460125\n",
      "Train Epoch: 12 [16640/37879 (44%)]\tLoss: 0.164276\n",
      "Train Epoch: 12 [17280/37879 (46%)]\tLoss: 0.363849\n",
      "Train Epoch: 12 [17920/37879 (47%)]\tLoss: 0.249975\n",
      "Train Epoch: 12 [18560/37879 (49%)]\tLoss: 0.199021\n",
      "Train Epoch: 12 [19200/37879 (51%)]\tLoss: 0.224957\n",
      "Train Epoch: 12 [19840/37879 (52%)]\tLoss: 0.276650\n",
      "Train Epoch: 12 [20480/37879 (54%)]\tLoss: 0.258719\n",
      "Train Epoch: 12 [21120/37879 (56%)]\tLoss: 0.218003\n",
      "Train Epoch: 12 [21760/37879 (57%)]\tLoss: 0.151598\n",
      "Train Epoch: 12 [22400/37879 (59%)]\tLoss: 0.158572\n",
      "Train Epoch: 12 [23040/37879 (61%)]\tLoss: 0.335499\n",
      "Train Epoch: 12 [23680/37879 (62%)]\tLoss: 0.302084\n",
      "Train Epoch: 12 [24320/37879 (64%)]\tLoss: 0.305966\n",
      "Train Epoch: 12 [24960/37879 (66%)]\tLoss: 0.075503\n",
      "Train Epoch: 12 [25600/37879 (68%)]\tLoss: 0.136624\n",
      "Train Epoch: 12 [26240/37879 (69%)]\tLoss: 0.172042\n",
      "Train Epoch: 12 [26880/37879 (71%)]\tLoss: 0.137730\n",
      "Train Epoch: 12 [27520/37879 (73%)]\tLoss: 0.195992\n",
      "Train Epoch: 12 [28160/37879 (74%)]\tLoss: 0.180532\n",
      "Train Epoch: 12 [28800/37879 (76%)]\tLoss: 0.196804\n",
      "Train Epoch: 12 [29440/37879 (78%)]\tLoss: 0.158959\n",
      "Train Epoch: 12 [30080/37879 (79%)]\tLoss: 0.302864\n",
      "Train Epoch: 12 [30720/37879 (81%)]\tLoss: 0.136055\n",
      "Train Epoch: 12 [31360/37879 (83%)]\tLoss: 0.345005\n",
      "Train Epoch: 12 [32000/37879 (84%)]\tLoss: 0.111365\n",
      "Train Epoch: 12 [32640/37879 (86%)]\tLoss: 0.255657\n",
      "Train Epoch: 12 [33280/37879 (88%)]\tLoss: 0.270506\n",
      "Train Epoch: 12 [33920/37879 (90%)]\tLoss: 0.497699\n",
      "Train Epoch: 12 [34560/37879 (91%)]\tLoss: 0.103619\n",
      "Train Epoch: 12 [35200/37879 (93%)]\tLoss: 0.231067\n",
      "Train Epoch: 12 [35840/37879 (95%)]\tLoss: 0.085395\n",
      "Train Epoch: 12 [36480/37879 (96%)]\tLoss: 0.131696\n",
      "Train Epoch: 12 [37120/37879 (98%)]\tLoss: 0.127346\n",
      "Train Epoch: 12 [37760/37879 (100%)]\tLoss: 0.168945\n",
      "\n",
      "Test set: Avg. loss: 0.0854, Accuracy: 9751/10000 (97%)\n",
      "\n",
      "Train Epoch: 13 [0/37879 (0%)]\tLoss: 0.124450\n",
      "Train Epoch: 13 [640/37879 (2%)]\tLoss: 0.119193\n",
      "Train Epoch: 13 [1280/37879 (3%)]\tLoss: 0.293053\n",
      "Train Epoch: 13 [1920/37879 (5%)]\tLoss: 0.140542\n",
      "Train Epoch: 13 [2560/37879 (7%)]\tLoss: 0.181603\n",
      "Train Epoch: 13 [3200/37879 (8%)]\tLoss: 0.170344\n",
      "Train Epoch: 13 [3840/37879 (10%)]\tLoss: 0.312083\n",
      "Train Epoch: 13 [4480/37879 (12%)]\tLoss: 0.229560\n",
      "Train Epoch: 13 [5120/37879 (14%)]\tLoss: 0.222108\n",
      "Train Epoch: 13 [5760/37879 (15%)]\tLoss: 0.321691\n",
      "Train Epoch: 13 [6400/37879 (17%)]\tLoss: 0.181122\n",
      "Train Epoch: 13 [7040/37879 (19%)]\tLoss: 0.238731\n",
      "Train Epoch: 13 [7680/37879 (20%)]\tLoss: 0.296071\n",
      "Train Epoch: 13 [8320/37879 (22%)]\tLoss: 0.287351\n",
      "Train Epoch: 13 [8960/37879 (24%)]\tLoss: 0.488550\n",
      "Train Epoch: 13 [9600/37879 (25%)]\tLoss: 0.158029\n",
      "Train Epoch: 13 [10240/37879 (27%)]\tLoss: 0.245292\n",
      "Train Epoch: 13 [10880/37879 (29%)]\tLoss: 0.181815\n",
      "Train Epoch: 13 [11520/37879 (30%)]\tLoss: 0.124595\n",
      "Train Epoch: 13 [12160/37879 (32%)]\tLoss: 0.423115\n",
      "Train Epoch: 13 [12800/37879 (34%)]\tLoss: 0.161301\n",
      "Train Epoch: 13 [13440/37879 (35%)]\tLoss: 0.183267\n",
      "Train Epoch: 13 [14080/37879 (37%)]\tLoss: 0.076786\n",
      "Train Epoch: 13 [14720/37879 (39%)]\tLoss: 0.149823\n",
      "Train Epoch: 13 [15360/37879 (41%)]\tLoss: 0.168463\n",
      "Train Epoch: 13 [16000/37879 (42%)]\tLoss: 0.208664\n",
      "Train Epoch: 13 [16640/37879 (44%)]\tLoss: 0.139521\n",
      "Train Epoch: 13 [17280/37879 (46%)]\tLoss: 0.320989\n",
      "Train Epoch: 13 [17920/37879 (47%)]\tLoss: 0.286190\n",
      "Train Epoch: 13 [18560/37879 (49%)]\tLoss: 0.096457\n",
      "Train Epoch: 13 [19200/37879 (51%)]\tLoss: 0.172390\n",
      "Train Epoch: 13 [19840/37879 (52%)]\tLoss: 0.321775\n",
      "Train Epoch: 13 [20480/37879 (54%)]\tLoss: 0.311870\n",
      "Train Epoch: 13 [21120/37879 (56%)]\tLoss: 0.110291\n",
      "Train Epoch: 13 [21760/37879 (57%)]\tLoss: 0.107597\n",
      "Train Epoch: 13 [22400/37879 (59%)]\tLoss: 0.185144\n",
      "Train Epoch: 13 [23040/37879 (61%)]\tLoss: 0.224451\n",
      "Train Epoch: 13 [23680/37879 (62%)]\tLoss: 0.233555\n",
      "Train Epoch: 13 [24320/37879 (64%)]\tLoss: 0.191700\n",
      "Train Epoch: 13 [24960/37879 (66%)]\tLoss: 0.123218\n",
      "Train Epoch: 13 [25600/37879 (68%)]\tLoss: 0.085877\n",
      "Train Epoch: 13 [26240/37879 (69%)]\tLoss: 0.307845\n",
      "Train Epoch: 13 [26880/37879 (71%)]\tLoss: 0.187824\n",
      "Train Epoch: 13 [27520/37879 (73%)]\tLoss: 0.099654\n",
      "Train Epoch: 13 [28160/37879 (74%)]\tLoss: 0.213866\n",
      "Train Epoch: 13 [28800/37879 (76%)]\tLoss: 0.126861\n",
      "Train Epoch: 13 [29440/37879 (78%)]\tLoss: 0.137438\n",
      "Train Epoch: 13 [30080/37879 (79%)]\tLoss: 0.204967\n",
      "Train Epoch: 13 [30720/37879 (81%)]\tLoss: 0.223699\n",
      "Train Epoch: 13 [31360/37879 (83%)]\tLoss: 0.189598\n",
      "Train Epoch: 13 [32000/37879 (84%)]\tLoss: 0.071658\n",
      "Train Epoch: 13 [32640/37879 (86%)]\tLoss: 0.283512\n",
      "Train Epoch: 13 [33280/37879 (88%)]\tLoss: 0.451462\n",
      "Train Epoch: 13 [33920/37879 (90%)]\tLoss: 0.140933\n",
      "Train Epoch: 13 [34560/37879 (91%)]\tLoss: 0.151159\n",
      "Train Epoch: 13 [35200/37879 (93%)]\tLoss: 0.177290\n",
      "Train Epoch: 13 [35840/37879 (95%)]\tLoss: 0.173334\n",
      "Train Epoch: 13 [36480/37879 (96%)]\tLoss: 0.094089\n",
      "Train Epoch: 13 [37120/37879 (98%)]\tLoss: 0.188556\n",
      "Train Epoch: 13 [37760/37879 (100%)]\tLoss: 0.067864\n",
      "\n",
      "Test set: Avg. loss: 0.0830, Accuracy: 9750/10000 (97%)\n",
      "\n",
      "Train Epoch: 14 [0/37879 (0%)]\tLoss: 0.222385\n",
      "Train Epoch: 14 [640/37879 (2%)]\tLoss: 0.276924\n",
      "Train Epoch: 14 [1280/37879 (3%)]\tLoss: 0.281210\n",
      "Train Epoch: 14 [1920/37879 (5%)]\tLoss: 0.134239\n",
      "Train Epoch: 14 [2560/37879 (7%)]\tLoss: 0.381129\n",
      "Train Epoch: 14 [3200/37879 (8%)]\tLoss: 0.102239\n",
      "Train Epoch: 14 [3840/37879 (10%)]\tLoss: 0.089589\n",
      "Train Epoch: 14 [4480/37879 (12%)]\tLoss: 0.258459\n",
      "Train Epoch: 14 [5120/37879 (14%)]\tLoss: 0.224497\n",
      "Train Epoch: 14 [5760/37879 (15%)]\tLoss: 0.363612\n",
      "Train Epoch: 14 [6400/37879 (17%)]\tLoss: 0.196655\n",
      "Train Epoch: 14 [7040/37879 (19%)]\tLoss: 0.143456\n",
      "Train Epoch: 14 [7680/37879 (20%)]\tLoss: 0.390252\n",
      "Train Epoch: 14 [8320/37879 (22%)]\tLoss: 0.146475\n",
      "Train Epoch: 14 [8960/37879 (24%)]\tLoss: 0.119737\n",
      "Train Epoch: 14 [9600/37879 (25%)]\tLoss: 0.113818\n",
      "Train Epoch: 14 [10240/37879 (27%)]\tLoss: 0.317455\n",
      "Train Epoch: 14 [10880/37879 (29%)]\tLoss: 0.243663\n",
      "Train Epoch: 14 [11520/37879 (30%)]\tLoss: 0.287150\n",
      "Train Epoch: 14 [12160/37879 (32%)]\tLoss: 0.062131\n",
      "Train Epoch: 14 [12800/37879 (34%)]\tLoss: 0.322371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [13440/37879 (35%)]\tLoss: 0.206650\n",
      "Train Epoch: 14 [14080/37879 (37%)]\tLoss: 0.178884\n",
      "Train Epoch: 14 [14720/37879 (39%)]\tLoss: 0.194670\n",
      "Train Epoch: 14 [15360/37879 (41%)]\tLoss: 0.253505\n",
      "Train Epoch: 14 [16000/37879 (42%)]\tLoss: 0.038090\n",
      "Train Epoch: 14 [16640/37879 (44%)]\tLoss: 0.202954\n",
      "Train Epoch: 14 [17280/37879 (46%)]\tLoss: 0.213893\n",
      "Train Epoch: 14 [17920/37879 (47%)]\tLoss: 0.332834\n",
      "Train Epoch: 14 [18560/37879 (49%)]\tLoss: 0.260653\n",
      "Train Epoch: 14 [19200/37879 (51%)]\tLoss: 0.214072\n",
      "Train Epoch: 14 [19840/37879 (52%)]\tLoss: 0.361580\n",
      "Train Epoch: 14 [20480/37879 (54%)]\tLoss: 0.384314\n",
      "Train Epoch: 14 [21120/37879 (56%)]\tLoss: 0.161803\n",
      "Train Epoch: 14 [21760/37879 (57%)]\tLoss: 0.238762\n",
      "Train Epoch: 14 [22400/37879 (59%)]\tLoss: 0.078207\n",
      "Train Epoch: 14 [23040/37879 (61%)]\tLoss: 0.071961\n",
      "Train Epoch: 14 [23680/37879 (62%)]\tLoss: 0.136692\n",
      "Train Epoch: 14 [24320/37879 (64%)]\tLoss: 0.159488\n",
      "Train Epoch: 14 [24960/37879 (66%)]\tLoss: 0.161679\n",
      "Train Epoch: 14 [25600/37879 (68%)]\tLoss: 0.416793\n",
      "Train Epoch: 14 [26240/37879 (69%)]\tLoss: 0.108125\n",
      "Train Epoch: 14 [26880/37879 (71%)]\tLoss: 0.156981\n",
      "Train Epoch: 14 [27520/37879 (73%)]\tLoss: 0.206446\n",
      "Train Epoch: 14 [28160/37879 (74%)]\tLoss: 0.257235\n",
      "Train Epoch: 14 [28800/37879 (76%)]\tLoss: 0.148430\n",
      "Train Epoch: 14 [29440/37879 (78%)]\tLoss: 0.227290\n",
      "Train Epoch: 14 [30080/37879 (79%)]\tLoss: 0.244501\n",
      "Train Epoch: 14 [30720/37879 (81%)]\tLoss: 0.291216\n",
      "Train Epoch: 14 [31360/37879 (83%)]\tLoss: 0.090465\n",
      "Train Epoch: 14 [32000/37879 (84%)]\tLoss: 0.178372\n",
      "Train Epoch: 14 [32640/37879 (86%)]\tLoss: 0.115792\n",
      "Train Epoch: 14 [33280/37879 (88%)]\tLoss: 0.304421\n",
      "Train Epoch: 14 [33920/37879 (90%)]\tLoss: 0.222670\n",
      "Train Epoch: 14 [34560/37879 (91%)]\tLoss: 0.104599\n",
      "Train Epoch: 14 [35200/37879 (93%)]\tLoss: 0.139982\n",
      "Train Epoch: 14 [35840/37879 (95%)]\tLoss: 0.108381\n",
      "Train Epoch: 14 [36480/37879 (96%)]\tLoss: 0.189259\n",
      "Train Epoch: 14 [37120/37879 (98%)]\tLoss: 0.187358\n",
      "Train Epoch: 14 [37760/37879 (100%)]\tLoss: 0.231945\n",
      "\n",
      "Test set: Avg. loss: 0.0763, Accuracy: 9773/10000 (97%)\n",
      "\n",
      "Train Epoch: 15 [0/37879 (0%)]\tLoss: 0.168984\n",
      "Train Epoch: 15 [640/37879 (2%)]\tLoss: 0.113809\n",
      "Train Epoch: 15 [1280/37879 (3%)]\tLoss: 0.163820\n",
      "Train Epoch: 15 [1920/37879 (5%)]\tLoss: 0.145455\n",
      "Train Epoch: 15 [2560/37879 (7%)]\tLoss: 0.167747\n",
      "Train Epoch: 15 [3200/37879 (8%)]\tLoss: 0.154301\n",
      "Train Epoch: 15 [3840/37879 (10%)]\tLoss: 0.173620\n",
      "Train Epoch: 15 [4480/37879 (12%)]\tLoss: 0.144589\n",
      "Train Epoch: 15 [5120/37879 (14%)]\tLoss: 0.098393\n",
      "Train Epoch: 15 [5760/37879 (15%)]\tLoss: 0.281456\n",
      "Train Epoch: 15 [6400/37879 (17%)]\tLoss: 0.227615\n",
      "Train Epoch: 15 [7040/37879 (19%)]\tLoss: 0.194280\n",
      "Train Epoch: 15 [7680/37879 (20%)]\tLoss: 0.200406\n",
      "Train Epoch: 15 [8320/37879 (22%)]\tLoss: 0.155098\n",
      "Train Epoch: 15 [8960/37879 (24%)]\tLoss: 0.160242\n",
      "Train Epoch: 15 [9600/37879 (25%)]\tLoss: 0.165359\n",
      "Train Epoch: 15 [10240/37879 (27%)]\tLoss: 0.085274\n",
      "Train Epoch: 15 [10880/37879 (29%)]\tLoss: 0.236591\n",
      "Train Epoch: 15 [11520/37879 (30%)]\tLoss: 0.227168\n",
      "Train Epoch: 15 [12160/37879 (32%)]\tLoss: 0.109997\n",
      "Train Epoch: 15 [12800/37879 (34%)]\tLoss: 0.121391\n",
      "Train Epoch: 15 [13440/37879 (35%)]\tLoss: 0.231141\n",
      "Train Epoch: 15 [14080/37879 (37%)]\tLoss: 0.132858\n",
      "Train Epoch: 15 [14720/37879 (39%)]\tLoss: 0.068794\n",
      "Train Epoch: 15 [15360/37879 (41%)]\tLoss: 0.220574\n",
      "Train Epoch: 15 [16000/37879 (42%)]\tLoss: 0.150122\n",
      "Train Epoch: 15 [16640/37879 (44%)]\tLoss: 0.336927\n",
      "Train Epoch: 15 [17280/37879 (46%)]\tLoss: 0.091396\n",
      "Train Epoch: 15 [17920/37879 (47%)]\tLoss: 0.252473\n",
      "Train Epoch: 15 [18560/37879 (49%)]\tLoss: 0.149377\n",
      "Train Epoch: 15 [19200/37879 (51%)]\tLoss: 0.251460\n",
      "Train Epoch: 15 [19840/37879 (52%)]\tLoss: 0.252062\n",
      "Train Epoch: 15 [20480/37879 (54%)]\tLoss: 0.141876\n",
      "Train Epoch: 15 [21120/37879 (56%)]\tLoss: 0.144891\n",
      "Train Epoch: 15 [21760/37879 (57%)]\tLoss: 0.051071\n",
      "Train Epoch: 15 [22400/37879 (59%)]\tLoss: 0.126536\n",
      "Train Epoch: 15 [23040/37879 (61%)]\tLoss: 0.165627\n",
      "Train Epoch: 15 [23680/37879 (62%)]\tLoss: 0.062606\n",
      "Train Epoch: 15 [24320/37879 (64%)]\tLoss: 0.197164\n",
      "Train Epoch: 15 [24960/37879 (66%)]\tLoss: 0.177785\n",
      "Train Epoch: 15 [25600/37879 (68%)]\tLoss: 0.074542\n",
      "Train Epoch: 15 [26240/37879 (69%)]\tLoss: 0.122128\n",
      "Train Epoch: 15 [26880/37879 (71%)]\tLoss: 0.111920\n",
      "Train Epoch: 15 [27520/37879 (73%)]\tLoss: 0.051907\n",
      "Train Epoch: 15 [28160/37879 (74%)]\tLoss: 0.139954\n",
      "Train Epoch: 15 [28800/37879 (76%)]\tLoss: 0.310431\n",
      "Train Epoch: 15 [29440/37879 (78%)]\tLoss: 0.136519\n",
      "Train Epoch: 15 [30080/37879 (79%)]\tLoss: 0.105620\n",
      "Train Epoch: 15 [30720/37879 (81%)]\tLoss: 0.146706\n",
      "Train Epoch: 15 [31360/37879 (83%)]\tLoss: 0.308795\n",
      "Train Epoch: 15 [32000/37879 (84%)]\tLoss: 0.192238\n",
      "Train Epoch: 15 [32640/37879 (86%)]\tLoss: 0.078920\n",
      "Train Epoch: 15 [33280/37879 (88%)]\tLoss: 0.142228\n",
      "Train Epoch: 15 [33920/37879 (90%)]\tLoss: 0.145279\n",
      "Train Epoch: 15 [34560/37879 (91%)]\tLoss: 0.213533\n",
      "Train Epoch: 15 [35200/37879 (93%)]\tLoss: 0.292669\n",
      "Train Epoch: 15 [35840/37879 (95%)]\tLoss: 0.100655\n",
      "Train Epoch: 15 [36480/37879 (96%)]\tLoss: 0.360587\n",
      "Train Epoch: 15 [37120/37879 (98%)]\tLoss: 0.226152\n",
      "Train Epoch: 15 [37760/37879 (100%)]\tLoss: 0.220191\n",
      "\n",
      "Test set: Avg. loss: 0.0747, Accuracy: 9782/10000 (97%)\n",
      "\n",
      "Train Epoch: 16 [0/37879 (0%)]\tLoss: 0.132768\n",
      "Train Epoch: 16 [640/37879 (2%)]\tLoss: 0.183700\n",
      "Train Epoch: 16 [1280/37879 (3%)]\tLoss: 0.297891\n",
      "Train Epoch: 16 [1920/37879 (5%)]\tLoss: 0.263189\n",
      "Train Epoch: 16 [2560/37879 (7%)]\tLoss: 0.090398\n",
      "Train Epoch: 16 [3200/37879 (8%)]\tLoss: 0.091960\n",
      "Train Epoch: 16 [3840/37879 (10%)]\tLoss: 0.263748\n",
      "Train Epoch: 16 [4480/37879 (12%)]\tLoss: 0.181686\n",
      "Train Epoch: 16 [5120/37879 (14%)]\tLoss: 0.209497\n",
      "Train Epoch: 16 [5760/37879 (15%)]\tLoss: 0.246498\n",
      "Train Epoch: 16 [6400/37879 (17%)]\tLoss: 0.147155\n",
      "Train Epoch: 16 [7040/37879 (19%)]\tLoss: 0.483565\n",
      "Train Epoch: 16 [7680/37879 (20%)]\tLoss: 0.233701\n",
      "Train Epoch: 16 [8320/37879 (22%)]\tLoss: 0.058851\n",
      "Train Epoch: 16 [8960/37879 (24%)]\tLoss: 0.221064\n",
      "Train Epoch: 16 [9600/37879 (25%)]\tLoss: 0.369586\n",
      "Train Epoch: 16 [10240/37879 (27%)]\tLoss: 0.092754\n",
      "Train Epoch: 16 [10880/37879 (29%)]\tLoss: 0.327323\n",
      "Train Epoch: 16 [11520/37879 (30%)]\tLoss: 0.159853\n",
      "Train Epoch: 16 [12160/37879 (32%)]\tLoss: 0.152450\n",
      "Train Epoch: 16 [12800/37879 (34%)]\tLoss: 0.227105\n",
      "Train Epoch: 16 [13440/37879 (35%)]\tLoss: 0.105580\n",
      "Train Epoch: 16 [14080/37879 (37%)]\tLoss: 0.039014\n",
      "Train Epoch: 16 [14720/37879 (39%)]\tLoss: 0.249670\n",
      "Train Epoch: 16 [15360/37879 (41%)]\tLoss: 0.270573\n",
      "Train Epoch: 16 [16000/37879 (42%)]\tLoss: 0.174834\n",
      "Train Epoch: 16 [16640/37879 (44%)]\tLoss: 0.099697\n",
      "Train Epoch: 16 [17280/37879 (46%)]\tLoss: 0.197273\n",
      "Train Epoch: 16 [17920/37879 (47%)]\tLoss: 0.105594\n",
      "Train Epoch: 16 [18560/37879 (49%)]\tLoss: 0.139099\n",
      "Train Epoch: 16 [19200/37879 (51%)]\tLoss: 0.148333\n",
      "Train Epoch: 16 [19840/37879 (52%)]\tLoss: 0.202135\n",
      "Train Epoch: 16 [20480/37879 (54%)]\tLoss: 0.134551\n",
      "Train Epoch: 16 [21120/37879 (56%)]\tLoss: 0.031617\n",
      "Train Epoch: 16 [21760/37879 (57%)]\tLoss: 0.301301\n",
      "Train Epoch: 16 [22400/37879 (59%)]\tLoss: 0.165437\n",
      "Train Epoch: 16 [23040/37879 (61%)]\tLoss: 0.177962\n",
      "Train Epoch: 16 [23680/37879 (62%)]\tLoss: 0.301010\n",
      "Train Epoch: 16 [24320/37879 (64%)]\tLoss: 0.049379\n",
      "Train Epoch: 16 [24960/37879 (66%)]\tLoss: 0.227924\n",
      "Train Epoch: 16 [25600/37879 (68%)]\tLoss: 0.109544\n",
      "Train Epoch: 16 [26240/37879 (69%)]\tLoss: 0.155524\n",
      "Train Epoch: 16 [26880/37879 (71%)]\tLoss: 0.202264\n",
      "Train Epoch: 16 [27520/37879 (73%)]\tLoss: 0.204040\n",
      "Train Epoch: 16 [28160/37879 (74%)]\tLoss: 0.146483\n",
      "Train Epoch: 16 [28800/37879 (76%)]\tLoss: 0.368154\n",
      "Train Epoch: 16 [29440/37879 (78%)]\tLoss: 0.139123\n",
      "Train Epoch: 16 [30080/37879 (79%)]\tLoss: 0.195113\n",
      "Train Epoch: 16 [30720/37879 (81%)]\tLoss: 0.108611\n",
      "Train Epoch: 16 [31360/37879 (83%)]\tLoss: 0.115872\n",
      "Train Epoch: 16 [32000/37879 (84%)]\tLoss: 0.278321\n",
      "Train Epoch: 16 [32640/37879 (86%)]\tLoss: 0.166465\n",
      "Train Epoch: 16 [33280/37879 (88%)]\tLoss: 0.139275\n",
      "Train Epoch: 16 [33920/37879 (90%)]\tLoss: 0.270713\n",
      "Train Epoch: 16 [34560/37879 (91%)]\tLoss: 0.245298\n",
      "Train Epoch: 16 [35200/37879 (93%)]\tLoss: 0.170324\n",
      "Train Epoch: 16 [35840/37879 (95%)]\tLoss: 0.174619\n",
      "Train Epoch: 16 [36480/37879 (96%)]\tLoss: 0.169391\n",
      "Train Epoch: 16 [37120/37879 (98%)]\tLoss: 0.249658\n",
      "Train Epoch: 16 [37760/37879 (100%)]\tLoss: 0.291393\n",
      "\n",
      "Test set: Avg. loss: 0.0751, Accuracy: 9782/10000 (97%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 17 [0/37879 (0%)]\tLoss: 0.130785\n",
      "Train Epoch: 17 [640/37879 (2%)]\tLoss: 0.088723\n",
      "Train Epoch: 17 [1280/37879 (3%)]\tLoss: 0.135860\n",
      "Train Epoch: 17 [1920/37879 (5%)]\tLoss: 0.094261\n",
      "Train Epoch: 17 [2560/37879 (7%)]\tLoss: 0.049087\n",
      "Train Epoch: 17 [3200/37879 (8%)]\tLoss: 0.265980\n",
      "Train Epoch: 17 [3840/37879 (10%)]\tLoss: 0.134691\n",
      "Train Epoch: 17 [4480/37879 (12%)]\tLoss: 0.264535\n",
      "Train Epoch: 17 [5120/37879 (14%)]\tLoss: 0.328802\n",
      "Train Epoch: 17 [5760/37879 (15%)]\tLoss: 0.240745\n",
      "Train Epoch: 17 [6400/37879 (17%)]\tLoss: 0.165449\n",
      "Train Epoch: 17 [7040/37879 (19%)]\tLoss: 0.210558\n",
      "Train Epoch: 17 [7680/37879 (20%)]\tLoss: 0.214920\n",
      "Train Epoch: 17 [8320/37879 (22%)]\tLoss: 0.138952\n",
      "Train Epoch: 17 [8960/37879 (24%)]\tLoss: 0.366297\n",
      "Train Epoch: 17 [9600/37879 (25%)]\tLoss: 0.238203\n",
      "Train Epoch: 17 [10240/37879 (27%)]\tLoss: 0.272515\n",
      "Train Epoch: 17 [10880/37879 (29%)]\tLoss: 0.321256\n",
      "Train Epoch: 17 [11520/37879 (30%)]\tLoss: 0.132328\n",
      "Train Epoch: 17 [12160/37879 (32%)]\tLoss: 0.181885\n",
      "Train Epoch: 17 [12800/37879 (34%)]\tLoss: 0.108368\n",
      "Train Epoch: 17 [13440/37879 (35%)]\tLoss: 0.139769\n",
      "Train Epoch: 17 [14080/37879 (37%)]\tLoss: 0.196575\n",
      "Train Epoch: 17 [14720/37879 (39%)]\tLoss: 0.313297\n",
      "Train Epoch: 17 [15360/37879 (41%)]\tLoss: 0.148006\n",
      "Train Epoch: 17 [16000/37879 (42%)]\tLoss: 0.068582\n",
      "Train Epoch: 17 [16640/37879 (44%)]\tLoss: 0.162999\n",
      "Train Epoch: 17 [17280/37879 (46%)]\tLoss: 0.166595\n",
      "Train Epoch: 17 [17920/37879 (47%)]\tLoss: 0.151293\n",
      "Train Epoch: 17 [18560/37879 (49%)]\tLoss: 0.276765\n",
      "Train Epoch: 17 [19200/37879 (51%)]\tLoss: 0.283928\n",
      "Train Epoch: 17 [19840/37879 (52%)]\tLoss: 0.253121\n",
      "Train Epoch: 17 [20480/37879 (54%)]\tLoss: 0.062165\n",
      "Train Epoch: 17 [21120/37879 (56%)]\tLoss: 0.390226\n",
      "Train Epoch: 17 [21760/37879 (57%)]\tLoss: 0.184917\n",
      "Train Epoch: 17 [22400/37879 (59%)]\tLoss: 0.133597\n",
      "Train Epoch: 17 [23040/37879 (61%)]\tLoss: 0.168847\n",
      "Train Epoch: 17 [23680/37879 (62%)]\tLoss: 0.080967\n",
      "Train Epoch: 17 [24320/37879 (64%)]\tLoss: 0.027966\n",
      "Train Epoch: 17 [24960/37879 (66%)]\tLoss: 0.159100\n",
      "Train Epoch: 17 [25600/37879 (68%)]\tLoss: 0.173988\n",
      "Train Epoch: 17 [26240/37879 (69%)]\tLoss: 0.214807\n",
      "Train Epoch: 17 [26880/37879 (71%)]\tLoss: 0.108338\n",
      "Train Epoch: 17 [27520/37879 (73%)]\tLoss: 0.220919\n",
      "Train Epoch: 17 [28160/37879 (74%)]\tLoss: 0.311594\n",
      "Train Epoch: 17 [28800/37879 (76%)]\tLoss: 0.143313\n",
      "Train Epoch: 17 [29440/37879 (78%)]\tLoss: 0.123847\n",
      "Train Epoch: 17 [30080/37879 (79%)]\tLoss: 0.349329\n",
      "Train Epoch: 17 [30720/37879 (81%)]\tLoss: 0.144628\n",
      "Train Epoch: 17 [31360/37879 (83%)]\tLoss: 0.209212\n",
      "Train Epoch: 17 [32000/37879 (84%)]\tLoss: 0.227988\n",
      "Train Epoch: 17 [32640/37879 (86%)]\tLoss: 0.161155\n",
      "Train Epoch: 17 [33280/37879 (88%)]\tLoss: 0.034087\n",
      "Train Epoch: 17 [33920/37879 (90%)]\tLoss: 0.131181\n",
      "Train Epoch: 17 [34560/37879 (91%)]\tLoss: 0.113885\n",
      "Train Epoch: 17 [35200/37879 (93%)]\tLoss: 0.142845\n",
      "Train Epoch: 17 [35840/37879 (95%)]\tLoss: 0.245438\n",
      "Train Epoch: 17 [36480/37879 (96%)]\tLoss: 0.130357\n",
      "Train Epoch: 17 [37120/37879 (98%)]\tLoss: 0.083876\n",
      "Train Epoch: 17 [37760/37879 (100%)]\tLoss: 0.099735\n",
      "\n",
      "Test set: Avg. loss: 0.0741, Accuracy: 9787/10000 (97%)\n",
      "\n",
      "Train Epoch: 18 [0/37879 (0%)]\tLoss: 0.215589\n",
      "Train Epoch: 18 [640/37879 (2%)]\tLoss: 0.193399\n",
      "Train Epoch: 18 [1280/37879 (3%)]\tLoss: 0.244524\n",
      "Train Epoch: 18 [1920/37879 (5%)]\tLoss: 0.247149\n",
      "Train Epoch: 18 [2560/37879 (7%)]\tLoss: 0.053651\n",
      "Train Epoch: 18 [3200/37879 (8%)]\tLoss: 0.146357\n",
      "Train Epoch: 18 [3840/37879 (10%)]\tLoss: 0.117043\n",
      "Train Epoch: 18 [4480/37879 (12%)]\tLoss: 0.092804\n",
      "Train Epoch: 18 [5120/37879 (14%)]\tLoss: 0.207350\n",
      "Train Epoch: 18 [5760/37879 (15%)]\tLoss: 0.175049\n",
      "Train Epoch: 18 [6400/37879 (17%)]\tLoss: 0.139172\n",
      "Train Epoch: 18 [7040/37879 (19%)]\tLoss: 0.409218\n",
      "Train Epoch: 18 [7680/37879 (20%)]\tLoss: 0.118639\n",
      "Train Epoch: 18 [8320/37879 (22%)]\tLoss: 0.211824\n",
      "Train Epoch: 18 [8960/37879 (24%)]\tLoss: 0.084965\n",
      "Train Epoch: 18 [9600/37879 (25%)]\tLoss: 0.173842\n",
      "Train Epoch: 18 [10240/37879 (27%)]\tLoss: 0.127760\n",
      "Train Epoch: 18 [10880/37879 (29%)]\tLoss: 0.326491\n",
      "Train Epoch: 18 [11520/37879 (30%)]\tLoss: 0.181257\n",
      "Train Epoch: 18 [12160/37879 (32%)]\tLoss: 0.058627\n",
      "Train Epoch: 18 [12800/37879 (34%)]\tLoss: 0.142882\n",
      "Train Epoch: 18 [13440/37879 (35%)]\tLoss: 0.093825\n",
      "Train Epoch: 18 [14080/37879 (37%)]\tLoss: 0.099774\n",
      "Train Epoch: 18 [14720/37879 (39%)]\tLoss: 0.121675\n",
      "Train Epoch: 18 [15360/37879 (41%)]\tLoss: 0.095281\n",
      "Train Epoch: 18 [16000/37879 (42%)]\tLoss: 0.045599\n",
      "Train Epoch: 18 [16640/37879 (44%)]\tLoss: 0.149011\n",
      "Train Epoch: 18 [17280/37879 (46%)]\tLoss: 0.227718\n",
      "Train Epoch: 18 [17920/37879 (47%)]\tLoss: 0.104972\n",
      "Train Epoch: 18 [18560/37879 (49%)]\tLoss: 0.158022\n",
      "Train Epoch: 18 [19200/37879 (51%)]\tLoss: 0.170658\n",
      "Train Epoch: 18 [19840/37879 (52%)]\tLoss: 0.141874\n",
      "Train Epoch: 18 [20480/37879 (54%)]\tLoss: 0.309344\n",
      "Train Epoch: 18 [21120/37879 (56%)]\tLoss: 0.099619\n",
      "Train Epoch: 18 [21760/37879 (57%)]\tLoss: 0.107356\n",
      "Train Epoch: 18 [22400/37879 (59%)]\tLoss: 0.251008\n",
      "Train Epoch: 18 [23040/37879 (61%)]\tLoss: 0.111864\n",
      "Train Epoch: 18 [23680/37879 (62%)]\tLoss: 0.340672\n",
      "Train Epoch: 18 [24320/37879 (64%)]\tLoss: 0.104579\n",
      "Train Epoch: 18 [24960/37879 (66%)]\tLoss: 0.065442\n",
      "Train Epoch: 18 [25600/37879 (68%)]\tLoss: 0.178085\n",
      "Train Epoch: 18 [26240/37879 (69%)]\tLoss: 0.136743\n",
      "Train Epoch: 18 [26880/37879 (71%)]\tLoss: 0.229787\n",
      "Train Epoch: 18 [27520/37879 (73%)]\tLoss: 0.195192\n",
      "Train Epoch: 18 [28160/37879 (74%)]\tLoss: 0.096596\n",
      "Train Epoch: 18 [28800/37879 (76%)]\tLoss: 0.115619\n",
      "Train Epoch: 18 [29440/37879 (78%)]\tLoss: 0.247328\n",
      "Train Epoch: 18 [30080/37879 (79%)]\tLoss: 0.148870\n",
      "Train Epoch: 18 [30720/37879 (81%)]\tLoss: 0.083125\n",
      "Train Epoch: 18 [31360/37879 (83%)]\tLoss: 0.128004\n",
      "Train Epoch: 18 [32000/37879 (84%)]\tLoss: 0.268678\n",
      "Train Epoch: 18 [32640/37879 (86%)]\tLoss: 0.096433\n",
      "Train Epoch: 18 [33280/37879 (88%)]\tLoss: 0.109275\n",
      "Train Epoch: 18 [33920/37879 (90%)]\tLoss: 0.126690\n",
      "Train Epoch: 18 [34560/37879 (91%)]\tLoss: 0.089011\n",
      "Train Epoch: 18 [35200/37879 (93%)]\tLoss: 0.132774\n",
      "Train Epoch: 18 [35840/37879 (95%)]\tLoss: 0.140956\n",
      "Train Epoch: 18 [36480/37879 (96%)]\tLoss: 0.075395\n",
      "Train Epoch: 18 [37120/37879 (98%)]\tLoss: 0.136304\n",
      "Train Epoch: 18 [37760/37879 (100%)]\tLoss: 0.208839\n",
      "\n",
      "Test set: Avg. loss: 0.0680, Accuracy: 9801/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/37879 (0%)]\tLoss: 0.184139\n",
      "Train Epoch: 19 [640/37879 (2%)]\tLoss: 0.142230\n",
      "Train Epoch: 19 [1280/37879 (3%)]\tLoss: 0.129978\n",
      "Train Epoch: 19 [1920/37879 (5%)]\tLoss: 0.117949\n",
      "Train Epoch: 19 [2560/37879 (7%)]\tLoss: 0.106331\n",
      "Train Epoch: 19 [3200/37879 (8%)]\tLoss: 0.327065\n",
      "Train Epoch: 19 [3840/37879 (10%)]\tLoss: 0.109710\n",
      "Train Epoch: 19 [4480/37879 (12%)]\tLoss: 0.171982\n",
      "Train Epoch: 19 [5120/37879 (14%)]\tLoss: 0.306235\n",
      "Train Epoch: 19 [5760/37879 (15%)]\tLoss: 0.144964\n",
      "Train Epoch: 19 [6400/37879 (17%)]\tLoss: 0.268000\n",
      "Train Epoch: 19 [7040/37879 (19%)]\tLoss: 0.278835\n",
      "Train Epoch: 19 [7680/37879 (20%)]\tLoss: 0.284582\n",
      "Train Epoch: 19 [8320/37879 (22%)]\tLoss: 0.283259\n",
      "Train Epoch: 19 [8960/37879 (24%)]\tLoss: 0.165193\n",
      "Train Epoch: 19 [9600/37879 (25%)]\tLoss: 0.162295\n",
      "Train Epoch: 19 [10240/37879 (27%)]\tLoss: 0.067393\n",
      "Train Epoch: 19 [10880/37879 (29%)]\tLoss: 0.074752\n",
      "Train Epoch: 19 [11520/37879 (30%)]\tLoss: 0.167349\n",
      "Train Epoch: 19 [12160/37879 (32%)]\tLoss: 0.171254\n",
      "Train Epoch: 19 [12800/37879 (34%)]\tLoss: 0.137213\n",
      "Train Epoch: 19 [13440/37879 (35%)]\tLoss: 0.151112\n",
      "Train Epoch: 19 [14080/37879 (37%)]\tLoss: 0.190950\n",
      "Train Epoch: 19 [14720/37879 (39%)]\tLoss: 0.347938\n",
      "Train Epoch: 19 [15360/37879 (41%)]\tLoss: 0.071610\n",
      "Train Epoch: 19 [16000/37879 (42%)]\tLoss: 0.083449\n",
      "Train Epoch: 19 [16640/37879 (44%)]\tLoss: 0.079558\n",
      "Train Epoch: 19 [17280/37879 (46%)]\tLoss: 0.163821\n",
      "Train Epoch: 19 [17920/37879 (47%)]\tLoss: 0.129501\n",
      "Train Epoch: 19 [18560/37879 (49%)]\tLoss: 0.221637\n",
      "Train Epoch: 19 [19200/37879 (51%)]\tLoss: 0.321326\n",
      "Train Epoch: 19 [19840/37879 (52%)]\tLoss: 0.260514\n",
      "Train Epoch: 19 [20480/37879 (54%)]\tLoss: 0.049757\n",
      "Train Epoch: 19 [21120/37879 (56%)]\tLoss: 0.150142\n",
      "Train Epoch: 19 [21760/37879 (57%)]\tLoss: 0.206677\n",
      "Train Epoch: 19 [22400/37879 (59%)]\tLoss: 0.120394\n",
      "Train Epoch: 19 [23040/37879 (61%)]\tLoss: 0.191490\n",
      "Train Epoch: 19 [23680/37879 (62%)]\tLoss: 0.252702\n",
      "Train Epoch: 19 [24320/37879 (64%)]\tLoss: 0.210642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [24960/37879 (66%)]\tLoss: 0.244466\n",
      "Train Epoch: 19 [25600/37879 (68%)]\tLoss: 0.223908\n",
      "Train Epoch: 19 [26240/37879 (69%)]\tLoss: 0.162699\n",
      "Train Epoch: 19 [26880/37879 (71%)]\tLoss: 0.158342\n",
      "Train Epoch: 19 [27520/37879 (73%)]\tLoss: 0.210654\n",
      "Train Epoch: 19 [28160/37879 (74%)]\tLoss: 0.093871\n",
      "Train Epoch: 19 [28800/37879 (76%)]\tLoss: 0.274744\n",
      "Train Epoch: 19 [29440/37879 (78%)]\tLoss: 0.277840\n",
      "Train Epoch: 19 [30080/37879 (79%)]\tLoss: 0.179087\n",
      "Train Epoch: 19 [30720/37879 (81%)]\tLoss: 0.131142\n",
      "Train Epoch: 19 [31360/37879 (83%)]\tLoss: 0.212252\n",
      "Train Epoch: 19 [32000/37879 (84%)]\tLoss: 0.125145\n",
      "Train Epoch: 19 [32640/37879 (86%)]\tLoss: 0.171673\n",
      "Train Epoch: 19 [33280/37879 (88%)]\tLoss: 0.122336\n",
      "Train Epoch: 19 [33920/37879 (90%)]\tLoss: 0.179736\n",
      "Train Epoch: 19 [34560/37879 (91%)]\tLoss: 0.147445\n",
      "Train Epoch: 19 [35200/37879 (93%)]\tLoss: 0.142144\n",
      "Train Epoch: 19 [35840/37879 (95%)]\tLoss: 0.193489\n",
      "Train Epoch: 19 [36480/37879 (96%)]\tLoss: 0.235510\n",
      "Train Epoch: 19 [37120/37879 (98%)]\tLoss: 0.147944\n",
      "Train Epoch: 19 [37760/37879 (100%)]\tLoss: 0.132567\n",
      "\n",
      "Test set: Avg. loss: 0.0653, Accuracy: 9802/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/37879 (0%)]\tLoss: 0.174420\n",
      "Train Epoch: 20 [640/37879 (2%)]\tLoss: 0.168510\n",
      "Train Epoch: 20 [1280/37879 (3%)]\tLoss: 0.316120\n",
      "Train Epoch: 20 [1920/37879 (5%)]\tLoss: 0.149886\n",
      "Train Epoch: 20 [2560/37879 (7%)]\tLoss: 0.120875\n",
      "Train Epoch: 20 [3200/37879 (8%)]\tLoss: 0.141310\n",
      "Train Epoch: 20 [3840/37879 (10%)]\tLoss: 0.250185\n",
      "Train Epoch: 20 [4480/37879 (12%)]\tLoss: 0.131752\n",
      "Train Epoch: 20 [5120/37879 (14%)]\tLoss: 0.132939\n",
      "Train Epoch: 20 [5760/37879 (15%)]\tLoss: 0.192046\n",
      "Train Epoch: 20 [6400/37879 (17%)]\tLoss: 0.138588\n",
      "Train Epoch: 20 [7040/37879 (19%)]\tLoss: 0.168601\n",
      "Train Epoch: 20 [7680/37879 (20%)]\tLoss: 0.164576\n",
      "Train Epoch: 20 [8320/37879 (22%)]\tLoss: 0.212746\n",
      "Train Epoch: 20 [8960/37879 (24%)]\tLoss: 0.047371\n",
      "Train Epoch: 20 [9600/37879 (25%)]\tLoss: 0.108181\n",
      "Train Epoch: 20 [10240/37879 (27%)]\tLoss: 0.046532\n",
      "Train Epoch: 20 [10880/37879 (29%)]\tLoss: 0.132201\n",
      "Train Epoch: 20 [11520/37879 (30%)]\tLoss: 0.264761\n",
      "Train Epoch: 20 [12160/37879 (32%)]\tLoss: 0.158874\n",
      "Train Epoch: 20 [12800/37879 (34%)]\tLoss: 0.059629\n",
      "Train Epoch: 20 [13440/37879 (35%)]\tLoss: 0.137441\n",
      "Train Epoch: 20 [14080/37879 (37%)]\tLoss: 0.254381\n",
      "Train Epoch: 20 [14720/37879 (39%)]\tLoss: 0.146887\n",
      "Train Epoch: 20 [15360/37879 (41%)]\tLoss: 0.159472\n",
      "Train Epoch: 20 [16000/37879 (42%)]\tLoss: 0.089739\n",
      "Train Epoch: 20 [16640/37879 (44%)]\tLoss: 0.254676\n",
      "Train Epoch: 20 [17280/37879 (46%)]\tLoss: 0.293907\n",
      "Train Epoch: 20 [17920/37879 (47%)]\tLoss: 0.136529\n",
      "Train Epoch: 20 [18560/37879 (49%)]\tLoss: 0.087243\n",
      "Train Epoch: 20 [19200/37879 (51%)]\tLoss: 0.161653\n",
      "Train Epoch: 20 [19840/37879 (52%)]\tLoss: 0.239066\n",
      "Train Epoch: 20 [20480/37879 (54%)]\tLoss: 0.158640\n",
      "Train Epoch: 20 [21120/37879 (56%)]\tLoss: 0.123073\n",
      "Train Epoch: 20 [21760/37879 (57%)]\tLoss: 0.217018\n",
      "Train Epoch: 20 [22400/37879 (59%)]\tLoss: 0.100708\n",
      "Train Epoch: 20 [23040/37879 (61%)]\tLoss: 0.124545\n",
      "Train Epoch: 20 [23680/37879 (62%)]\tLoss: 0.244996\n",
      "Train Epoch: 20 [24320/37879 (64%)]\tLoss: 0.256289\n",
      "Train Epoch: 20 [24960/37879 (66%)]\tLoss: 0.163262\n",
      "Train Epoch: 20 [25600/37879 (68%)]\tLoss: 0.249642\n",
      "Train Epoch: 20 [26240/37879 (69%)]\tLoss: 0.098404\n",
      "Train Epoch: 20 [26880/37879 (71%)]\tLoss: 0.091465\n",
      "Train Epoch: 20 [27520/37879 (73%)]\tLoss: 0.090190\n",
      "Train Epoch: 20 [28160/37879 (74%)]\tLoss: 0.101318\n",
      "Train Epoch: 20 [28800/37879 (76%)]\tLoss: 0.168257\n",
      "Train Epoch: 20 [29440/37879 (78%)]\tLoss: 0.160400\n",
      "Train Epoch: 20 [30080/37879 (79%)]\tLoss: 0.225769\n",
      "Train Epoch: 20 [30720/37879 (81%)]\tLoss: 0.219833\n",
      "Train Epoch: 20 [31360/37879 (83%)]\tLoss: 0.205065\n",
      "Train Epoch: 20 [32000/37879 (84%)]\tLoss: 0.483830\n",
      "Train Epoch: 20 [32640/37879 (86%)]\tLoss: 0.057455\n",
      "Train Epoch: 20 [33280/37879 (88%)]\tLoss: 0.094421\n",
      "Train Epoch: 20 [33920/37879 (90%)]\tLoss: 0.103227\n",
      "Train Epoch: 20 [34560/37879 (91%)]\tLoss: 0.174944\n",
      "Train Epoch: 20 [35200/37879 (93%)]\tLoss: 0.153812\n",
      "Train Epoch: 20 [35840/37879 (95%)]\tLoss: 0.227288\n",
      "Train Epoch: 20 [36480/37879 (96%)]\tLoss: 0.122630\n",
      "Train Epoch: 20 [37120/37879 (98%)]\tLoss: 0.291754\n",
      "Train Epoch: 20 [37760/37879 (100%)]\tLoss: 0.268261\n",
      "\n",
      "Test set: Avg. loss: 0.0713, Accuracy: 9788/10000 (97%)\n",
      "\n",
      "Train Epoch: 21 [0/37879 (0%)]\tLoss: 0.114586\n",
      "Train Epoch: 21 [640/37879 (2%)]\tLoss: 0.140251\n",
      "Train Epoch: 21 [1280/37879 (3%)]\tLoss: 0.180389\n",
      "Train Epoch: 21 [1920/37879 (5%)]\tLoss: 0.107931\n",
      "Train Epoch: 21 [2560/37879 (7%)]\tLoss: 0.225831\n",
      "Train Epoch: 21 [3200/37879 (8%)]\tLoss: 0.126866\n",
      "Train Epoch: 21 [3840/37879 (10%)]\tLoss: 0.064755\n",
      "Train Epoch: 21 [4480/37879 (12%)]\tLoss: 0.081399\n",
      "Train Epoch: 21 [5120/37879 (14%)]\tLoss: 0.321262\n",
      "Train Epoch: 21 [5760/37879 (15%)]\tLoss: 0.162639\n",
      "Train Epoch: 21 [6400/37879 (17%)]\tLoss: 0.196203\n",
      "Train Epoch: 21 [7040/37879 (19%)]\tLoss: 0.137172\n",
      "Train Epoch: 21 [7680/37879 (20%)]\tLoss: 0.089122\n",
      "Train Epoch: 21 [8320/37879 (22%)]\tLoss: 0.150097\n",
      "Train Epoch: 21 [8960/37879 (24%)]\tLoss: 0.023687\n",
      "Train Epoch: 21 [9600/37879 (25%)]\tLoss: 0.316648\n",
      "Train Epoch: 21 [10240/37879 (27%)]\tLoss: 0.155219\n",
      "Train Epoch: 21 [10880/37879 (29%)]\tLoss: 0.157098\n",
      "Train Epoch: 21 [11520/37879 (30%)]\tLoss: 0.432873\n",
      "Train Epoch: 21 [12160/37879 (32%)]\tLoss: 0.129763\n",
      "Train Epoch: 21 [12800/37879 (34%)]\tLoss: 0.170176\n",
      "Train Epoch: 21 [13440/37879 (35%)]\tLoss: 0.170128\n",
      "Train Epoch: 21 [14080/37879 (37%)]\tLoss: 0.275128\n",
      "Train Epoch: 21 [14720/37879 (39%)]\tLoss: 0.313824\n",
      "Train Epoch: 21 [15360/37879 (41%)]\tLoss: 0.108708\n",
      "Train Epoch: 21 [16000/37879 (42%)]\tLoss: 0.158636\n",
      "Train Epoch: 21 [16640/37879 (44%)]\tLoss: 0.381771\n",
      "Train Epoch: 21 [17280/37879 (46%)]\tLoss: 0.158716\n",
      "Train Epoch: 21 [17920/37879 (47%)]\tLoss: 0.134704\n",
      "Train Epoch: 21 [18560/37879 (49%)]\tLoss: 0.222282\n",
      "Train Epoch: 21 [19200/37879 (51%)]\tLoss: 0.194626\n",
      "Train Epoch: 21 [19840/37879 (52%)]\tLoss: 0.121908\n",
      "Train Epoch: 21 [20480/37879 (54%)]\tLoss: 0.143701\n",
      "Train Epoch: 21 [21120/37879 (56%)]\tLoss: 0.101540\n",
      "Train Epoch: 21 [21760/37879 (57%)]\tLoss: 0.091623\n",
      "Train Epoch: 21 [22400/37879 (59%)]\tLoss: 0.214109\n",
      "Train Epoch: 21 [23040/37879 (61%)]\tLoss: 0.144237\n",
      "Train Epoch: 21 [23680/37879 (62%)]\tLoss: 0.159577\n",
      "Train Epoch: 21 [24320/37879 (64%)]\tLoss: 0.094848\n",
      "Train Epoch: 21 [24960/37879 (66%)]\tLoss: 0.250319\n",
      "Train Epoch: 21 [25600/37879 (68%)]\tLoss: 0.082815\n",
      "Train Epoch: 21 [26240/37879 (69%)]\tLoss: 0.084563\n",
      "Train Epoch: 21 [26880/37879 (71%)]\tLoss: 0.148082\n",
      "Train Epoch: 21 [27520/37879 (73%)]\tLoss: 0.052290\n",
      "Train Epoch: 21 [28160/37879 (74%)]\tLoss: 0.117408\n",
      "Train Epoch: 21 [28800/37879 (76%)]\tLoss: 0.300598\n",
      "Train Epoch: 21 [29440/37879 (78%)]\tLoss: 0.158091\n",
      "Train Epoch: 21 [30080/37879 (79%)]\tLoss: 0.301879\n",
      "Train Epoch: 21 [30720/37879 (81%)]\tLoss: 0.150184\n",
      "Train Epoch: 21 [31360/37879 (83%)]\tLoss: 0.093157\n",
      "Train Epoch: 21 [32000/37879 (84%)]\tLoss: 0.087695\n",
      "Train Epoch: 21 [32640/37879 (86%)]\tLoss: 0.095385\n",
      "Train Epoch: 21 [33280/37879 (88%)]\tLoss: 0.038719\n",
      "Train Epoch: 21 [33920/37879 (90%)]\tLoss: 0.094788\n",
      "Train Epoch: 21 [34560/37879 (91%)]\tLoss: 0.064593\n",
      "Train Epoch: 21 [35200/37879 (93%)]\tLoss: 0.251341\n",
      "Train Epoch: 21 [35840/37879 (95%)]\tLoss: 0.210088\n",
      "Train Epoch: 21 [36480/37879 (96%)]\tLoss: 0.094446\n",
      "Train Epoch: 21 [37120/37879 (98%)]\tLoss: 0.078806\n",
      "Train Epoch: 21 [37760/37879 (100%)]\tLoss: 0.096330\n",
      "\n",
      "Test set: Avg. loss: 0.0691, Accuracy: 9794/10000 (97%)\n",
      "\n",
      "Train Epoch: 22 [0/37879 (0%)]\tLoss: 0.196196\n",
      "Train Epoch: 22 [640/37879 (2%)]\tLoss: 0.332712\n",
      "Train Epoch: 22 [1280/37879 (3%)]\tLoss: 0.352004\n",
      "Train Epoch: 22 [1920/37879 (5%)]\tLoss: 0.189871\n",
      "Train Epoch: 22 [2560/37879 (7%)]\tLoss: 0.204146\n",
      "Train Epoch: 22 [3200/37879 (8%)]\tLoss: 0.025321\n",
      "Train Epoch: 22 [3840/37879 (10%)]\tLoss: 0.249491\n",
      "Train Epoch: 22 [4480/37879 (12%)]\tLoss: 0.149454\n",
      "Train Epoch: 22 [5120/37879 (14%)]\tLoss: 0.064163\n",
      "Train Epoch: 22 [5760/37879 (15%)]\tLoss: 0.095864\n",
      "Train Epoch: 22 [6400/37879 (17%)]\tLoss: 0.493696\n",
      "Train Epoch: 22 [7040/37879 (19%)]\tLoss: 0.164936\n",
      "Train Epoch: 22 [7680/37879 (20%)]\tLoss: 0.301976\n",
      "Train Epoch: 22 [8320/37879 (22%)]\tLoss: 0.105996\n",
      "Train Epoch: 22 [8960/37879 (24%)]\tLoss: 0.051071\n",
      "Train Epoch: 22 [9600/37879 (25%)]\tLoss: 0.108313\n",
      "Train Epoch: 22 [10240/37879 (27%)]\tLoss: 0.067678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [10880/37879 (29%)]\tLoss: 0.040904\n",
      "Train Epoch: 22 [11520/37879 (30%)]\tLoss: 0.169788\n",
      "Train Epoch: 22 [12160/37879 (32%)]\tLoss: 0.466293\n",
      "Train Epoch: 22 [12800/37879 (34%)]\tLoss: 0.148270\n",
      "Train Epoch: 22 [13440/37879 (35%)]\tLoss: 0.328234\n",
      "Train Epoch: 22 [14080/37879 (37%)]\tLoss: 0.117161\n",
      "Train Epoch: 22 [14720/37879 (39%)]\tLoss: 0.249145\n",
      "Train Epoch: 22 [15360/37879 (41%)]\tLoss: 0.225688\n",
      "Train Epoch: 22 [16000/37879 (42%)]\tLoss: 0.265600\n",
      "Train Epoch: 22 [16640/37879 (44%)]\tLoss: 0.145503\n",
      "Train Epoch: 22 [17280/37879 (46%)]\tLoss: 0.305782\n",
      "Train Epoch: 22 [17920/37879 (47%)]\tLoss: 0.100330\n",
      "Train Epoch: 22 [18560/37879 (49%)]\tLoss: 0.049824\n",
      "Train Epoch: 22 [19200/37879 (51%)]\tLoss: 0.130675\n",
      "Train Epoch: 22 [19840/37879 (52%)]\tLoss: 0.147331\n",
      "Train Epoch: 22 [20480/37879 (54%)]\tLoss: 0.047118\n",
      "Train Epoch: 22 [21120/37879 (56%)]\tLoss: 0.213169\n",
      "Train Epoch: 22 [21760/37879 (57%)]\tLoss: 0.101922\n",
      "Train Epoch: 22 [22400/37879 (59%)]\tLoss: 0.162118\n",
      "Train Epoch: 22 [23040/37879 (61%)]\tLoss: 0.303322\n",
      "Train Epoch: 22 [23680/37879 (62%)]\tLoss: 0.041701\n",
      "Train Epoch: 22 [24320/37879 (64%)]\tLoss: 0.182605\n",
      "Train Epoch: 22 [24960/37879 (66%)]\tLoss: 0.607644\n",
      "Train Epoch: 22 [25600/37879 (68%)]\tLoss: 0.084129\n",
      "Train Epoch: 22 [26240/37879 (69%)]\tLoss: 0.194461\n",
      "Train Epoch: 22 [26880/37879 (71%)]\tLoss: 0.081640\n",
      "Train Epoch: 22 [27520/37879 (73%)]\tLoss: 0.037704\n",
      "Train Epoch: 22 [28160/37879 (74%)]\tLoss: 0.210303\n",
      "Train Epoch: 22 [28800/37879 (76%)]\tLoss: 0.091592\n",
      "Train Epoch: 22 [29440/37879 (78%)]\tLoss: 0.182194\n",
      "Train Epoch: 22 [30080/37879 (79%)]\tLoss: 0.159850\n",
      "Train Epoch: 22 [30720/37879 (81%)]\tLoss: 0.164676\n",
      "Train Epoch: 22 [31360/37879 (83%)]\tLoss: 0.102266\n",
      "Train Epoch: 22 [32000/37879 (84%)]\tLoss: 0.180621\n",
      "Train Epoch: 22 [32640/37879 (86%)]\tLoss: 0.096517\n",
      "Train Epoch: 22 [33280/37879 (88%)]\tLoss: 0.203754\n",
      "Train Epoch: 22 [33920/37879 (90%)]\tLoss: 0.212738\n",
      "Train Epoch: 22 [34560/37879 (91%)]\tLoss: 0.165629\n",
      "Train Epoch: 22 [35200/37879 (93%)]\tLoss: 0.231356\n",
      "Train Epoch: 22 [35840/37879 (95%)]\tLoss: 0.084472\n",
      "Train Epoch: 22 [36480/37879 (96%)]\tLoss: 0.188264\n",
      "Train Epoch: 22 [37120/37879 (98%)]\tLoss: 0.189021\n",
      "Train Epoch: 22 [37760/37879 (100%)]\tLoss: 0.058372\n",
      "\n",
      "Test set: Avg. loss: 0.0603, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/37879 (0%)]\tLoss: 0.091895\n",
      "Train Epoch: 23 [640/37879 (2%)]\tLoss: 0.208410\n",
      "Train Epoch: 23 [1280/37879 (3%)]\tLoss: 0.061035\n",
      "Train Epoch: 23 [1920/37879 (5%)]\tLoss: 0.164115\n",
      "Train Epoch: 23 [2560/37879 (7%)]\tLoss: 0.134587\n",
      "Train Epoch: 23 [3200/37879 (8%)]\tLoss: 0.064401\n",
      "Train Epoch: 23 [3840/37879 (10%)]\tLoss: 0.121642\n",
      "Train Epoch: 23 [4480/37879 (12%)]\tLoss: 0.096586\n",
      "Train Epoch: 23 [5120/37879 (14%)]\tLoss: 0.236706\n",
      "Train Epoch: 23 [5760/37879 (15%)]\tLoss: 0.124676\n",
      "Train Epoch: 23 [6400/37879 (17%)]\tLoss: 0.406102\n",
      "Train Epoch: 23 [7040/37879 (19%)]\tLoss: 0.208890\n",
      "Train Epoch: 23 [7680/37879 (20%)]\tLoss: 0.096429\n",
      "Train Epoch: 23 [8320/37879 (22%)]\tLoss: 0.187493\n",
      "Train Epoch: 23 [8960/37879 (24%)]\tLoss: 0.136336\n",
      "Train Epoch: 23 [9600/37879 (25%)]\tLoss: 0.115978\n",
      "Train Epoch: 23 [10240/37879 (27%)]\tLoss: 0.063491\n",
      "Train Epoch: 23 [10880/37879 (29%)]\tLoss: 0.147081\n",
      "Train Epoch: 23 [11520/37879 (30%)]\tLoss: 0.113066\n",
      "Train Epoch: 23 [12160/37879 (32%)]\tLoss: 0.209022\n",
      "Train Epoch: 23 [12800/37879 (34%)]\tLoss: 0.225107\n",
      "Train Epoch: 23 [13440/37879 (35%)]\tLoss: 0.107235\n",
      "Train Epoch: 23 [14080/37879 (37%)]\tLoss: 0.160085\n",
      "Train Epoch: 23 [14720/37879 (39%)]\tLoss: 0.179967\n",
      "Train Epoch: 23 [15360/37879 (41%)]\tLoss: 0.025246\n",
      "Train Epoch: 23 [16000/37879 (42%)]\tLoss: 0.150927\n",
      "Train Epoch: 23 [16640/37879 (44%)]\tLoss: 0.202273\n",
      "Train Epoch: 23 [17280/37879 (46%)]\tLoss: 0.118164\n",
      "Train Epoch: 23 [17920/37879 (47%)]\tLoss: 0.314463\n",
      "Train Epoch: 23 [18560/37879 (49%)]\tLoss: 0.564484\n",
      "Train Epoch: 23 [19200/37879 (51%)]\tLoss: 0.284729\n",
      "Train Epoch: 23 [19840/37879 (52%)]\tLoss: 0.105764\n",
      "Train Epoch: 23 [20480/37879 (54%)]\tLoss: 0.393947\n",
      "Train Epoch: 23 [21120/37879 (56%)]\tLoss: 0.166132\n",
      "Train Epoch: 23 [21760/37879 (57%)]\tLoss: 0.240949\n",
      "Train Epoch: 23 [22400/37879 (59%)]\tLoss: 0.393438\n",
      "Train Epoch: 23 [23040/37879 (61%)]\tLoss: 0.174164\n",
      "Train Epoch: 23 [23680/37879 (62%)]\tLoss: 0.108503\n",
      "Train Epoch: 23 [24320/37879 (64%)]\tLoss: 0.201914\n",
      "Train Epoch: 23 [24960/37879 (66%)]\tLoss: 0.093551\n",
      "Train Epoch: 23 [25600/37879 (68%)]\tLoss: 0.121326\n",
      "Train Epoch: 23 [26240/37879 (69%)]\tLoss: 0.197265\n",
      "Train Epoch: 23 [26880/37879 (71%)]\tLoss: 0.119688\n",
      "Train Epoch: 23 [27520/37879 (73%)]\tLoss: 0.220535\n",
      "Train Epoch: 23 [28160/37879 (74%)]\tLoss: 0.067265\n",
      "Train Epoch: 23 [28800/37879 (76%)]\tLoss: 0.062425\n",
      "Train Epoch: 23 [29440/37879 (78%)]\tLoss: 0.035656\n",
      "Train Epoch: 23 [30080/37879 (79%)]\tLoss: 0.123998\n",
      "Train Epoch: 23 [30720/37879 (81%)]\tLoss: 0.100140\n",
      "Train Epoch: 23 [31360/37879 (83%)]\tLoss: 0.078820\n",
      "Train Epoch: 23 [32000/37879 (84%)]\tLoss: 0.226251\n",
      "Train Epoch: 23 [32640/37879 (86%)]\tLoss: 0.108620\n",
      "Train Epoch: 23 [33280/37879 (88%)]\tLoss: 0.243354\n",
      "Train Epoch: 23 [33920/37879 (90%)]\tLoss: 0.117841\n",
      "Train Epoch: 23 [34560/37879 (91%)]\tLoss: 0.141098\n",
      "Train Epoch: 23 [35200/37879 (93%)]\tLoss: 0.152309\n",
      "Train Epoch: 23 [35840/37879 (95%)]\tLoss: 0.171910\n",
      "Train Epoch: 23 [36480/37879 (96%)]\tLoss: 0.126667\n",
      "Train Epoch: 23 [37120/37879 (98%)]\tLoss: 0.248031\n",
      "Train Epoch: 23 [37760/37879 (100%)]\tLoss: 0.132438\n",
      "\n",
      "Test set: Avg. loss: 0.0641, Accuracy: 9805/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/37879 (0%)]\tLoss: 0.211335\n",
      "Train Epoch: 24 [640/37879 (2%)]\tLoss: 0.145455\n",
      "Train Epoch: 24 [1280/37879 (3%)]\tLoss: 0.096694\n",
      "Train Epoch: 24 [1920/37879 (5%)]\tLoss: 0.257245\n",
      "Train Epoch: 24 [2560/37879 (7%)]\tLoss: 0.162904\n",
      "Train Epoch: 24 [3200/37879 (8%)]\tLoss: 0.168904\n",
      "Train Epoch: 24 [3840/37879 (10%)]\tLoss: 0.069487\n",
      "Train Epoch: 24 [4480/37879 (12%)]\tLoss: 0.250479\n",
      "Train Epoch: 24 [5120/37879 (14%)]\tLoss: 0.231302\n",
      "Train Epoch: 24 [5760/37879 (15%)]\tLoss: 0.080254\n",
      "Train Epoch: 24 [6400/37879 (17%)]\tLoss: 0.267219\n",
      "Train Epoch: 24 [7040/37879 (19%)]\tLoss: 0.340634\n",
      "Train Epoch: 24 [7680/37879 (20%)]\tLoss: 0.129359\n",
      "Train Epoch: 24 [8320/37879 (22%)]\tLoss: 0.129215\n",
      "Train Epoch: 24 [8960/37879 (24%)]\tLoss: 0.107303\n",
      "Train Epoch: 24 [9600/37879 (25%)]\tLoss: 0.128898\n",
      "Train Epoch: 24 [10240/37879 (27%)]\tLoss: 0.326919\n",
      "Train Epoch: 24 [10880/37879 (29%)]\tLoss: 0.086710\n",
      "Train Epoch: 24 [11520/37879 (30%)]\tLoss: 0.131935\n",
      "Train Epoch: 24 [12160/37879 (32%)]\tLoss: 0.177875\n",
      "Train Epoch: 24 [12800/37879 (34%)]\tLoss: 0.183829\n",
      "Train Epoch: 24 [13440/37879 (35%)]\tLoss: 0.184099\n",
      "Train Epoch: 24 [14080/37879 (37%)]\tLoss: 0.068875\n",
      "Train Epoch: 24 [14720/37879 (39%)]\tLoss: 0.192263\n",
      "Train Epoch: 24 [15360/37879 (41%)]\tLoss: 0.070807\n",
      "Train Epoch: 24 [16000/37879 (42%)]\tLoss: 0.343811\n",
      "Train Epoch: 24 [16640/37879 (44%)]\tLoss: 0.433309\n",
      "Train Epoch: 24 [17280/37879 (46%)]\tLoss: 0.153379\n",
      "Train Epoch: 24 [17920/37879 (47%)]\tLoss: 0.142496\n",
      "Train Epoch: 24 [18560/37879 (49%)]\tLoss: 0.267666\n",
      "Train Epoch: 24 [19200/37879 (51%)]\tLoss: 0.247719\n",
      "Train Epoch: 24 [19840/37879 (52%)]\tLoss: 0.228211\n",
      "Train Epoch: 24 [20480/37879 (54%)]\tLoss: 0.151243\n",
      "Train Epoch: 24 [21120/37879 (56%)]\tLoss: 0.109237\n",
      "Train Epoch: 24 [21760/37879 (57%)]\tLoss: 0.267557\n",
      "Train Epoch: 24 [22400/37879 (59%)]\tLoss: 0.281423\n",
      "Train Epoch: 24 [23040/37879 (61%)]\tLoss: 0.071924\n",
      "Train Epoch: 24 [23680/37879 (62%)]\tLoss: 0.050484\n",
      "Train Epoch: 24 [24320/37879 (64%)]\tLoss: 0.103515\n",
      "Train Epoch: 24 [24960/37879 (66%)]\tLoss: 0.259506\n",
      "Train Epoch: 24 [25600/37879 (68%)]\tLoss: 0.271476\n",
      "Train Epoch: 24 [26240/37879 (69%)]\tLoss: 0.063778\n",
      "Train Epoch: 24 [26880/37879 (71%)]\tLoss: 0.055677\n",
      "Train Epoch: 24 [27520/37879 (73%)]\tLoss: 0.168293\n",
      "Train Epoch: 24 [28160/37879 (74%)]\tLoss: 0.256444\n",
      "Train Epoch: 24 [28800/37879 (76%)]\tLoss: 0.040537\n",
      "Train Epoch: 24 [29440/37879 (78%)]\tLoss: 0.131506\n",
      "Train Epoch: 24 [30080/37879 (79%)]\tLoss: 0.073099\n",
      "Train Epoch: 24 [30720/37879 (81%)]\tLoss: 0.307556\n",
      "Train Epoch: 24 [31360/37879 (83%)]\tLoss: 0.113477\n",
      "Train Epoch: 24 [32000/37879 (84%)]\tLoss: 0.148156\n",
      "Train Epoch: 24 [32640/37879 (86%)]\tLoss: 0.167801\n",
      "Train Epoch: 24 [33280/37879 (88%)]\tLoss: 0.209767\n",
      "Train Epoch: 24 [33920/37879 (90%)]\tLoss: 0.143406\n",
      "Train Epoch: 24 [34560/37879 (91%)]\tLoss: 0.108130\n",
      "Train Epoch: 24 [35200/37879 (93%)]\tLoss: 0.180637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [35840/37879 (95%)]\tLoss: 0.049591\n",
      "Train Epoch: 24 [36480/37879 (96%)]\tLoss: 0.060445\n",
      "Train Epoch: 24 [37120/37879 (98%)]\tLoss: 0.194052\n",
      "Train Epoch: 24 [37760/37879 (100%)]\tLoss: 0.087293\n",
      "\n",
      "Test set: Avg. loss: 0.0595, Accuracy: 9824/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/37879 (0%)]\tLoss: 0.052112\n",
      "Train Epoch: 25 [640/37879 (2%)]\tLoss: 0.092733\n",
      "Train Epoch: 25 [1280/37879 (3%)]\tLoss: 0.102260\n",
      "Train Epoch: 25 [1920/37879 (5%)]\tLoss: 0.161196\n",
      "Train Epoch: 25 [2560/37879 (7%)]\tLoss: 0.434945\n",
      "Train Epoch: 25 [3200/37879 (8%)]\tLoss: 0.074811\n",
      "Train Epoch: 25 [3840/37879 (10%)]\tLoss: 0.224659\n",
      "Train Epoch: 25 [4480/37879 (12%)]\tLoss: 0.483927\n",
      "Train Epoch: 25 [5120/37879 (14%)]\tLoss: 0.112964\n",
      "Train Epoch: 25 [5760/37879 (15%)]\tLoss: 0.067910\n",
      "Train Epoch: 25 [6400/37879 (17%)]\tLoss: 0.082982\n",
      "Train Epoch: 25 [7040/37879 (19%)]\tLoss: 0.218344\n",
      "Train Epoch: 25 [7680/37879 (20%)]\tLoss: 0.187008\n",
      "Train Epoch: 25 [8320/37879 (22%)]\tLoss: 0.137249\n",
      "Train Epoch: 25 [8960/37879 (24%)]\tLoss: 0.250971\n",
      "Train Epoch: 25 [9600/37879 (25%)]\tLoss: 0.151516\n",
      "Train Epoch: 25 [10240/37879 (27%)]\tLoss: 0.221478\n",
      "Train Epoch: 25 [10880/37879 (29%)]\tLoss: 0.136001\n",
      "Train Epoch: 25 [11520/37879 (30%)]\tLoss: 0.126410\n",
      "Train Epoch: 25 [12160/37879 (32%)]\tLoss: 0.074308\n",
      "Train Epoch: 25 [12800/37879 (34%)]\tLoss: 0.117297\n",
      "Train Epoch: 25 [13440/37879 (35%)]\tLoss: 0.179590\n",
      "Train Epoch: 25 [14080/37879 (37%)]\tLoss: 0.181153\n",
      "Train Epoch: 25 [14720/37879 (39%)]\tLoss: 0.069543\n",
      "Train Epoch: 25 [15360/37879 (41%)]\tLoss: 0.195166\n",
      "Train Epoch: 25 [16000/37879 (42%)]\tLoss: 0.128907\n",
      "Train Epoch: 25 [16640/37879 (44%)]\tLoss: 0.072552\n",
      "Train Epoch: 25 [17280/37879 (46%)]\tLoss: 0.147962\n",
      "Train Epoch: 25 [17920/37879 (47%)]\tLoss: 0.142210\n",
      "Train Epoch: 25 [18560/37879 (49%)]\tLoss: 0.154207\n",
      "Train Epoch: 25 [19200/37879 (51%)]\tLoss: 0.140251\n",
      "Train Epoch: 25 [19840/37879 (52%)]\tLoss: 0.142482\n",
      "Train Epoch: 25 [20480/37879 (54%)]\tLoss: 0.089917\n",
      "Train Epoch: 25 [21120/37879 (56%)]\tLoss: 0.112649\n",
      "Train Epoch: 25 [21760/37879 (57%)]\tLoss: 0.126807\n",
      "Train Epoch: 25 [22400/37879 (59%)]\tLoss: 0.109110\n",
      "Train Epoch: 25 [23040/37879 (61%)]\tLoss: 0.239373\n",
      "Train Epoch: 25 [23680/37879 (62%)]\tLoss: 0.063599\n",
      "Train Epoch: 25 [24320/37879 (64%)]\tLoss: 0.258633\n",
      "Train Epoch: 25 [24960/37879 (66%)]\tLoss: 0.090059\n",
      "Train Epoch: 25 [25600/37879 (68%)]\tLoss: 0.207684\n",
      "Train Epoch: 25 [26240/37879 (69%)]\tLoss: 0.140567\n",
      "Train Epoch: 25 [26880/37879 (71%)]\tLoss: 0.157262\n",
      "Train Epoch: 25 [27520/37879 (73%)]\tLoss: 0.058601\n",
      "Train Epoch: 25 [28160/37879 (74%)]\tLoss: 0.233492\n",
      "Train Epoch: 25 [28800/37879 (76%)]\tLoss: 0.119936\n",
      "Train Epoch: 25 [29440/37879 (78%)]\tLoss: 0.124429\n",
      "Train Epoch: 25 [30080/37879 (79%)]\tLoss: 0.133751\n",
      "Train Epoch: 25 [30720/37879 (81%)]\tLoss: 0.147653\n",
      "Train Epoch: 25 [31360/37879 (83%)]\tLoss: 0.086182\n",
      "Train Epoch: 25 [32000/37879 (84%)]\tLoss: 0.110603\n",
      "Train Epoch: 25 [32640/37879 (86%)]\tLoss: 0.270718\n",
      "Train Epoch: 25 [33280/37879 (88%)]\tLoss: 0.168234\n",
      "Train Epoch: 25 [33920/37879 (90%)]\tLoss: 0.161050\n",
      "Train Epoch: 25 [34560/37879 (91%)]\tLoss: 0.222802\n",
      "Train Epoch: 25 [35200/37879 (93%)]\tLoss: 0.081295\n",
      "Train Epoch: 25 [35840/37879 (95%)]\tLoss: 0.126796\n",
      "Train Epoch: 25 [36480/37879 (96%)]\tLoss: 0.108386\n",
      "Train Epoch: 25 [37120/37879 (98%)]\tLoss: 0.240113\n",
      "Train Epoch: 25 [37760/37879 (100%)]\tLoss: 0.080523\n",
      "\n",
      "Test set: Avg. loss: 0.0559, Accuracy: 9826/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(network)\n",
    "for epoch in range(1, args.n_epochs + 1):\n",
    "    train(epoch, imbalanced_linear_train_loader, network, optimizer)\n",
    "    test(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3158, Accuracy: 667/10000 (6%)\n",
      "\n",
      "Train Epoch: 1 [0/41964 (0%)]\tLoss: 2.332769\n",
      "Train Epoch: 1 [640/41964 (2%)]\tLoss: 2.325893\n",
      "Train Epoch: 1 [1280/41964 (3%)]\tLoss: 2.246783\n",
      "Train Epoch: 1 [1920/41964 (5%)]\tLoss: 2.224069\n",
      "Train Epoch: 1 [2560/41964 (6%)]\tLoss: 2.163418\n",
      "Train Epoch: 1 [3200/41964 (8%)]\tLoss: 2.188685\n",
      "Train Epoch: 1 [3840/41964 (9%)]\tLoss: 2.179769\n",
      "Train Epoch: 1 [4480/41964 (11%)]\tLoss: 2.082011\n",
      "Train Epoch: 1 [5120/41964 (12%)]\tLoss: 1.950175\n",
      "Train Epoch: 1 [5760/41964 (14%)]\tLoss: 1.863544\n",
      "Train Epoch: 1 [6400/41964 (15%)]\tLoss: 1.877378\n",
      "Train Epoch: 1 [7040/41964 (17%)]\tLoss: 1.832883\n",
      "Train Epoch: 1 [7680/41964 (18%)]\tLoss: 1.931687\n",
      "Train Epoch: 1 [8320/41964 (20%)]\tLoss: 1.769928\n",
      "Train Epoch: 1 [8960/41964 (21%)]\tLoss: 1.579049\n",
      "Train Epoch: 1 [9600/41964 (23%)]\tLoss: 1.389954\n",
      "Train Epoch: 1 [10240/41964 (24%)]\tLoss: 1.301887\n",
      "Train Epoch: 1 [10880/41964 (26%)]\tLoss: 1.504839\n",
      "Train Epoch: 1 [11520/41964 (27%)]\tLoss: 1.332594\n",
      "Train Epoch: 1 [12160/41964 (29%)]\tLoss: 1.172156\n",
      "Train Epoch: 1 [12800/41964 (30%)]\tLoss: 1.273130\n",
      "Train Epoch: 1 [13440/41964 (32%)]\tLoss: 1.116362\n",
      "Train Epoch: 1 [14080/41964 (34%)]\tLoss: 1.181061\n",
      "Train Epoch: 1 [14720/41964 (35%)]\tLoss: 1.092239\n",
      "Train Epoch: 1 [15360/41964 (37%)]\tLoss: 1.121816\n",
      "Train Epoch: 1 [16000/41964 (38%)]\tLoss: 1.299394\n",
      "Train Epoch: 1 [16640/41964 (40%)]\tLoss: 1.000453\n",
      "Train Epoch: 1 [17280/41964 (41%)]\tLoss: 1.295281\n",
      "Train Epoch: 1 [17920/41964 (43%)]\tLoss: 0.986046\n",
      "Train Epoch: 1 [18560/41964 (44%)]\tLoss: 0.996942\n",
      "Train Epoch: 1 [19200/41964 (46%)]\tLoss: 1.030447\n",
      "Train Epoch: 1 [19840/41964 (47%)]\tLoss: 0.872604\n",
      "Train Epoch: 1 [20480/41964 (49%)]\tLoss: 0.791555\n",
      "Train Epoch: 1 [21120/41964 (50%)]\tLoss: 0.809303\n",
      "Train Epoch: 1 [21760/41964 (52%)]\tLoss: 0.975030\n",
      "Train Epoch: 1 [22400/41964 (53%)]\tLoss: 0.916022\n",
      "Train Epoch: 1 [23040/41964 (55%)]\tLoss: 0.558930\n",
      "Train Epoch: 1 [23680/41964 (56%)]\tLoss: 0.737943\n",
      "Train Epoch: 1 [24320/41964 (58%)]\tLoss: 0.771241\n",
      "Train Epoch: 1 [24960/41964 (59%)]\tLoss: 0.794226\n",
      "Train Epoch: 1 [25600/41964 (61%)]\tLoss: 0.725419\n",
      "Train Epoch: 1 [26240/41964 (62%)]\tLoss: 0.517970\n",
      "Train Epoch: 1 [26880/41964 (64%)]\tLoss: 0.640002\n",
      "Train Epoch: 1 [27520/41964 (66%)]\tLoss: 0.580900\n",
      "Train Epoch: 1 [28160/41964 (67%)]\tLoss: 0.704832\n",
      "Train Epoch: 1 [28800/41964 (69%)]\tLoss: 0.734571\n",
      "Train Epoch: 1 [29440/41964 (70%)]\tLoss: 0.739400\n",
      "Train Epoch: 1 [30080/41964 (72%)]\tLoss: 0.757808\n",
      "Train Epoch: 1 [30720/41964 (73%)]\tLoss: 0.579517\n",
      "Train Epoch: 1 [31360/41964 (75%)]\tLoss: 0.868672\n",
      "Train Epoch: 1 [32000/41964 (76%)]\tLoss: 0.730987\n",
      "Train Epoch: 1 [32640/41964 (78%)]\tLoss: 0.699136\n",
      "Train Epoch: 1 [33280/41964 (79%)]\tLoss: 0.794027\n",
      "Train Epoch: 1 [33920/41964 (81%)]\tLoss: 0.660060\n",
      "Train Epoch: 1 [34560/41964 (82%)]\tLoss: 0.501896\n",
      "Train Epoch: 1 [35200/41964 (84%)]\tLoss: 0.725053\n",
      "Train Epoch: 1 [35840/41964 (85%)]\tLoss: 0.545505\n",
      "Train Epoch: 1 [36480/41964 (87%)]\tLoss: 0.952345\n",
      "Train Epoch: 1 [37120/41964 (88%)]\tLoss: 0.651907\n",
      "Train Epoch: 1 [37760/41964 (90%)]\tLoss: 0.639490\n",
      "Train Epoch: 1 [38400/41964 (91%)]\tLoss: 0.519516\n",
      "Train Epoch: 1 [39040/41964 (93%)]\tLoss: 0.547891\n",
      "Train Epoch: 1 [39680/41964 (95%)]\tLoss: 0.527325\n",
      "Train Epoch: 1 [40320/41964 (96%)]\tLoss: 0.820613\n",
      "Train Epoch: 1 [40960/41964 (98%)]\tLoss: 0.851444\n",
      "Train Epoch: 1 [41600/41964 (99%)]\tLoss: 0.460848\n",
      "\n",
      "Test set: Avg. loss: 0.3017, Accuracy: 9127/10000 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/41964 (0%)]\tLoss: 0.936009\n",
      "Train Epoch: 2 [640/41964 (2%)]\tLoss: 0.797648\n",
      "Train Epoch: 2 [1280/41964 (3%)]\tLoss: 0.448496\n",
      "Train Epoch: 2 [1920/41964 (5%)]\tLoss: 0.624137\n",
      "Train Epoch: 2 [2560/41964 (6%)]\tLoss: 0.749638\n",
      "Train Epoch: 2 [3200/41964 (8%)]\tLoss: 0.578560\n",
      "Train Epoch: 2 [3840/41964 (9%)]\tLoss: 0.669494\n",
      "Train Epoch: 2 [4480/41964 (11%)]\tLoss: 0.441651\n",
      "Train Epoch: 2 [5120/41964 (12%)]\tLoss: 0.783023\n",
      "Train Epoch: 2 [5760/41964 (14%)]\tLoss: 0.471581\n",
      "Train Epoch: 2 [6400/41964 (15%)]\tLoss: 0.734264\n",
      "Train Epoch: 2 [7040/41964 (17%)]\tLoss: 0.759331\n",
      "Train Epoch: 2 [7680/41964 (18%)]\tLoss: 0.341971\n",
      "Train Epoch: 2 [8320/41964 (20%)]\tLoss: 0.665354\n",
      "Train Epoch: 2 [8960/41964 (21%)]\tLoss: 0.465919\n",
      "Train Epoch: 2 [9600/41964 (23%)]\tLoss: 0.432935\n",
      "Train Epoch: 2 [10240/41964 (24%)]\tLoss: 0.625838\n",
      "Train Epoch: 2 [10880/41964 (26%)]\tLoss: 0.788127\n",
      "Train Epoch: 2 [11520/41964 (27%)]\tLoss: 0.404082\n",
      "Train Epoch: 2 [12160/41964 (29%)]\tLoss: 0.448566\n",
      "Train Epoch: 2 [12800/41964 (30%)]\tLoss: 0.463164\n",
      "Train Epoch: 2 [13440/41964 (32%)]\tLoss: 0.731965\n",
      "Train Epoch: 2 [14080/41964 (34%)]\tLoss: 0.414403\n",
      "Train Epoch: 2 [14720/41964 (35%)]\tLoss: 0.561435\n",
      "Train Epoch: 2 [15360/41964 (37%)]\tLoss: 0.400957\n",
      "Train Epoch: 2 [16000/41964 (38%)]\tLoss: 0.484638\n",
      "Train Epoch: 2 [16640/41964 (40%)]\tLoss: 0.463246\n",
      "Train Epoch: 2 [17280/41964 (41%)]\tLoss: 0.515797\n",
      "Train Epoch: 2 [17920/41964 (43%)]\tLoss: 0.555137\n",
      "Train Epoch: 2 [18560/41964 (44%)]\tLoss: 0.359359\n",
      "Train Epoch: 2 [19200/41964 (46%)]\tLoss: 0.498083\n",
      "Train Epoch: 2 [19840/41964 (47%)]\tLoss: 0.521613\n",
      "Train Epoch: 2 [20480/41964 (49%)]\tLoss: 0.591025\n",
      "Train Epoch: 2 [21120/41964 (50%)]\tLoss: 0.457128\n",
      "Train Epoch: 2 [21760/41964 (52%)]\tLoss: 0.679164\n",
      "Train Epoch: 2 [22400/41964 (53%)]\tLoss: 0.588019\n",
      "Train Epoch: 2 [23040/41964 (55%)]\tLoss: 0.434454\n",
      "Train Epoch: 2 [23680/41964 (56%)]\tLoss: 0.452286\n",
      "Train Epoch: 2 [24320/41964 (58%)]\tLoss: 0.569489\n",
      "Train Epoch: 2 [24960/41964 (59%)]\tLoss: 0.552574\n",
      "Train Epoch: 2 [25600/41964 (61%)]\tLoss: 0.782939\n",
      "Train Epoch: 2 [26240/41964 (62%)]\tLoss: 0.380806\n",
      "Train Epoch: 2 [26880/41964 (64%)]\tLoss: 0.376255\n",
      "Train Epoch: 2 [27520/41964 (66%)]\tLoss: 0.576343\n",
      "Train Epoch: 2 [28160/41964 (67%)]\tLoss: 0.357874\n",
      "Train Epoch: 2 [28800/41964 (69%)]\tLoss: 0.619858\n",
      "Train Epoch: 2 [29440/41964 (70%)]\tLoss: 0.538279\n",
      "Train Epoch: 2 [30080/41964 (72%)]\tLoss: 0.271273\n",
      "Train Epoch: 2 [30720/41964 (73%)]\tLoss: 0.320689\n",
      "Train Epoch: 2 [31360/41964 (75%)]\tLoss: 0.337173\n",
      "Train Epoch: 2 [32000/41964 (76%)]\tLoss: 0.307348\n",
      "Train Epoch: 2 [32640/41964 (78%)]\tLoss: 0.405445\n",
      "Train Epoch: 2 [33280/41964 (79%)]\tLoss: 0.355219\n",
      "Train Epoch: 2 [33920/41964 (81%)]\tLoss: 0.431368\n",
      "Train Epoch: 2 [34560/41964 (82%)]\tLoss: 0.622485\n",
      "Train Epoch: 2 [35200/41964 (84%)]\tLoss: 0.331436\n",
      "Train Epoch: 2 [35840/41964 (85%)]\tLoss: 0.679492\n",
      "Train Epoch: 2 [36480/41964 (87%)]\tLoss: 0.305182\n",
      "Train Epoch: 2 [37120/41964 (88%)]\tLoss: 0.635615\n",
      "Train Epoch: 2 [37760/41964 (90%)]\tLoss: 0.397055\n",
      "Train Epoch: 2 [38400/41964 (91%)]\tLoss: 0.477967\n",
      "Train Epoch: 2 [39040/41964 (93%)]\tLoss: 0.560530\n",
      "Train Epoch: 2 [39680/41964 (95%)]\tLoss: 0.370166\n",
      "Train Epoch: 2 [40320/41964 (96%)]\tLoss: 0.541996\n",
      "Train Epoch: 2 [40960/41964 (98%)]\tLoss: 0.251911\n",
      "Train Epoch: 2 [41600/41964 (99%)]\tLoss: 0.783248\n",
      "\n",
      "Test set: Avg. loss: 0.1954, Accuracy: 9414/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/41964 (0%)]\tLoss: 0.412433\n",
      "Train Epoch: 3 [640/41964 (2%)]\tLoss: 0.382502\n",
      "Train Epoch: 3 [1280/41964 (3%)]\tLoss: 0.348517\n",
      "Train Epoch: 3 [1920/41964 (5%)]\tLoss: 0.386769\n",
      "Train Epoch: 3 [2560/41964 (6%)]\tLoss: 0.589625\n",
      "Train Epoch: 3 [3200/41964 (8%)]\tLoss: 0.809652\n",
      "Train Epoch: 3 [3840/41964 (9%)]\tLoss: 0.368070\n",
      "Train Epoch: 3 [4480/41964 (11%)]\tLoss: 0.412037\n",
      "Train Epoch: 3 [5120/41964 (12%)]\tLoss: 0.652684\n",
      "Train Epoch: 3 [5760/41964 (14%)]\tLoss: 0.540856\n",
      "Train Epoch: 3 [6400/41964 (15%)]\tLoss: 0.335622\n",
      "Train Epoch: 3 [7040/41964 (17%)]\tLoss: 0.424983\n",
      "Train Epoch: 3 [7680/41964 (18%)]\tLoss: 0.264378\n",
      "Train Epoch: 3 [8320/41964 (20%)]\tLoss: 0.245009\n",
      "Train Epoch: 3 [8960/41964 (21%)]\tLoss: 0.536144\n",
      "Train Epoch: 3 [9600/41964 (23%)]\tLoss: 0.448679\n",
      "Train Epoch: 3 [10240/41964 (24%)]\tLoss: 0.383708\n",
      "Train Epoch: 3 [10880/41964 (26%)]\tLoss: 0.320929\n",
      "Train Epoch: 3 [11520/41964 (27%)]\tLoss: 0.714139\n",
      "Train Epoch: 3 [12160/41964 (29%)]\tLoss: 0.483525\n",
      "Train Epoch: 3 [12800/41964 (30%)]\tLoss: 0.432860\n",
      "Train Epoch: 3 [13440/41964 (32%)]\tLoss: 0.488906\n",
      "Train Epoch: 3 [14080/41964 (34%)]\tLoss: 0.339529\n",
      "Train Epoch: 3 [14720/41964 (35%)]\tLoss: 0.360581\n",
      "Train Epoch: 3 [15360/41964 (37%)]\tLoss: 0.397656\n",
      "Train Epoch: 3 [16000/41964 (38%)]\tLoss: 0.561798\n",
      "Train Epoch: 3 [16640/41964 (40%)]\tLoss: 0.428707\n",
      "Train Epoch: 3 [17280/41964 (41%)]\tLoss: 0.361291\n",
      "Train Epoch: 3 [17920/41964 (43%)]\tLoss: 0.278217\n",
      "Train Epoch: 3 [18560/41964 (44%)]\tLoss: 0.409784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [19200/41964 (46%)]\tLoss: 0.329830\n",
      "Train Epoch: 3 [19840/41964 (47%)]\tLoss: 0.708050\n",
      "Train Epoch: 3 [20480/41964 (49%)]\tLoss: 0.355070\n",
      "Train Epoch: 3 [21120/41964 (50%)]\tLoss: 0.377308\n",
      "Train Epoch: 3 [21760/41964 (52%)]\tLoss: 0.373034\n",
      "Train Epoch: 3 [22400/41964 (53%)]\tLoss: 0.298212\n",
      "Train Epoch: 3 [23040/41964 (55%)]\tLoss: 0.472705\n",
      "Train Epoch: 3 [23680/41964 (56%)]\tLoss: 0.545766\n",
      "Train Epoch: 3 [24320/41964 (58%)]\tLoss: 0.226295\n",
      "Train Epoch: 3 [24960/41964 (59%)]\tLoss: 0.686878\n",
      "Train Epoch: 3 [25600/41964 (61%)]\tLoss: 0.387277\n",
      "Train Epoch: 3 [26240/41964 (62%)]\tLoss: 0.299693\n",
      "Train Epoch: 3 [26880/41964 (64%)]\tLoss: 0.572352\n",
      "Train Epoch: 3 [27520/41964 (66%)]\tLoss: 0.513576\n",
      "Train Epoch: 3 [28160/41964 (67%)]\tLoss: 0.433318\n",
      "Train Epoch: 3 [28800/41964 (69%)]\tLoss: 0.356469\n",
      "Train Epoch: 3 [29440/41964 (70%)]\tLoss: 0.568218\n",
      "Train Epoch: 3 [30080/41964 (72%)]\tLoss: 0.457715\n",
      "Train Epoch: 3 [30720/41964 (73%)]\tLoss: 0.475054\n",
      "Train Epoch: 3 [31360/41964 (75%)]\tLoss: 0.454727\n",
      "Train Epoch: 3 [32000/41964 (76%)]\tLoss: 0.357127\n",
      "Train Epoch: 3 [32640/41964 (78%)]\tLoss: 0.326493\n",
      "Train Epoch: 3 [33280/41964 (79%)]\tLoss: 0.281383\n",
      "Train Epoch: 3 [33920/41964 (81%)]\tLoss: 0.369734\n",
      "Train Epoch: 3 [34560/41964 (82%)]\tLoss: 0.405532\n",
      "Train Epoch: 3 [35200/41964 (84%)]\tLoss: 0.252054\n",
      "Train Epoch: 3 [35840/41964 (85%)]\tLoss: 0.392265\n",
      "Train Epoch: 3 [36480/41964 (87%)]\tLoss: 0.370895\n",
      "Train Epoch: 3 [37120/41964 (88%)]\tLoss: 0.231041\n",
      "Train Epoch: 3 [37760/41964 (90%)]\tLoss: 0.350011\n",
      "Train Epoch: 3 [38400/41964 (91%)]\tLoss: 0.482029\n",
      "Train Epoch: 3 [39040/41964 (93%)]\tLoss: 0.293603\n",
      "Train Epoch: 3 [39680/41964 (95%)]\tLoss: 0.186854\n",
      "Train Epoch: 3 [40320/41964 (96%)]\tLoss: 0.354781\n",
      "Train Epoch: 3 [40960/41964 (98%)]\tLoss: 0.385009\n",
      "Train Epoch: 3 [41600/41964 (99%)]\tLoss: 0.381191\n",
      "\n",
      "Test set: Avg. loss: 0.1535, Accuracy: 9551/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/41964 (0%)]\tLoss: 0.278879\n",
      "Train Epoch: 4 [640/41964 (2%)]\tLoss: 0.441881\n",
      "Train Epoch: 4 [1280/41964 (3%)]\tLoss: 0.605901\n",
      "Train Epoch: 4 [1920/41964 (5%)]\tLoss: 0.395968\n",
      "Train Epoch: 4 [2560/41964 (6%)]\tLoss: 0.561455\n",
      "Train Epoch: 4 [3200/41964 (8%)]\tLoss: 0.327783\n",
      "Train Epoch: 4 [3840/41964 (9%)]\tLoss: 0.287007\n",
      "Train Epoch: 4 [4480/41964 (11%)]\tLoss: 0.262630\n",
      "Train Epoch: 4 [5120/41964 (12%)]\tLoss: 0.246915\n",
      "Train Epoch: 4 [5760/41964 (14%)]\tLoss: 0.192364\n",
      "Train Epoch: 4 [6400/41964 (15%)]\tLoss: 0.314656\n",
      "Train Epoch: 4 [7040/41964 (17%)]\tLoss: 0.399986\n",
      "Train Epoch: 4 [7680/41964 (18%)]\tLoss: 0.571665\n",
      "Train Epoch: 4 [8320/41964 (20%)]\tLoss: 0.457628\n",
      "Train Epoch: 4 [8960/41964 (21%)]\tLoss: 0.330756\n",
      "Train Epoch: 4 [9600/41964 (23%)]\tLoss: 0.297836\n",
      "Train Epoch: 4 [10240/41964 (24%)]\tLoss: 0.305100\n",
      "Train Epoch: 4 [10880/41964 (26%)]\tLoss: 0.407555\n",
      "Train Epoch: 4 [11520/41964 (27%)]\tLoss: 0.391247\n",
      "Train Epoch: 4 [12160/41964 (29%)]\tLoss: 0.202358\n",
      "Train Epoch: 4 [12800/41964 (30%)]\tLoss: 0.371140\n",
      "Train Epoch: 4 [13440/41964 (32%)]\tLoss: 0.308531\n",
      "Train Epoch: 4 [14080/41964 (34%)]\tLoss: 0.484781\n",
      "Train Epoch: 4 [14720/41964 (35%)]\tLoss: 0.441151\n",
      "Train Epoch: 4 [15360/41964 (37%)]\tLoss: 0.294948\n",
      "Train Epoch: 4 [16000/41964 (38%)]\tLoss: 0.235889\n",
      "Train Epoch: 4 [16640/41964 (40%)]\tLoss: 0.299297\n",
      "Train Epoch: 4 [17280/41964 (41%)]\tLoss: 0.284111\n",
      "Train Epoch: 4 [17920/41964 (43%)]\tLoss: 0.405228\n",
      "Train Epoch: 4 [18560/41964 (44%)]\tLoss: 0.342576\n",
      "Train Epoch: 4 [19200/41964 (46%)]\tLoss: 0.205088\n",
      "Train Epoch: 4 [19840/41964 (47%)]\tLoss: 0.345454\n",
      "Train Epoch: 4 [20480/41964 (49%)]\tLoss: 0.476804\n",
      "Train Epoch: 4 [21120/41964 (50%)]\tLoss: 0.349838\n",
      "Train Epoch: 4 [21760/41964 (52%)]\tLoss: 0.300485\n",
      "Train Epoch: 4 [22400/41964 (53%)]\tLoss: 0.400075\n",
      "Train Epoch: 4 [23040/41964 (55%)]\tLoss: 0.370887\n",
      "Train Epoch: 4 [23680/41964 (56%)]\tLoss: 0.313480\n",
      "Train Epoch: 4 [24320/41964 (58%)]\tLoss: 0.291051\n",
      "Train Epoch: 4 [24960/41964 (59%)]\tLoss: 0.361408\n",
      "Train Epoch: 4 [25600/41964 (61%)]\tLoss: 0.220687\n",
      "Train Epoch: 4 [26240/41964 (62%)]\tLoss: 0.241503\n",
      "Train Epoch: 4 [26880/41964 (64%)]\tLoss: 0.367653\n",
      "Train Epoch: 4 [27520/41964 (66%)]\tLoss: 0.260594\n",
      "Train Epoch: 4 [28160/41964 (67%)]\tLoss: 0.243499\n",
      "Train Epoch: 4 [28800/41964 (69%)]\tLoss: 0.339691\n",
      "Train Epoch: 4 [29440/41964 (70%)]\tLoss: 0.590792\n",
      "Train Epoch: 4 [30080/41964 (72%)]\tLoss: 0.217346\n",
      "Train Epoch: 4 [30720/41964 (73%)]\tLoss: 0.512375\n",
      "Train Epoch: 4 [31360/41964 (75%)]\tLoss: 0.629745\n",
      "Train Epoch: 4 [32000/41964 (76%)]\tLoss: 0.211509\n",
      "Train Epoch: 4 [32640/41964 (78%)]\tLoss: 0.472762\n",
      "Train Epoch: 4 [33280/41964 (79%)]\tLoss: 0.301504\n",
      "Train Epoch: 4 [33920/41964 (81%)]\tLoss: 0.438997\n",
      "Train Epoch: 4 [34560/41964 (82%)]\tLoss: 0.406478\n",
      "Train Epoch: 4 [35200/41964 (84%)]\tLoss: 0.408913\n",
      "Train Epoch: 4 [35840/41964 (85%)]\tLoss: 0.220388\n",
      "Train Epoch: 4 [36480/41964 (87%)]\tLoss: 0.549446\n",
      "Train Epoch: 4 [37120/41964 (88%)]\tLoss: 0.197406\n",
      "Train Epoch: 4 [37760/41964 (90%)]\tLoss: 0.393602\n",
      "Train Epoch: 4 [38400/41964 (91%)]\tLoss: 0.192104\n",
      "Train Epoch: 4 [39040/41964 (93%)]\tLoss: 0.381231\n",
      "Train Epoch: 4 [39680/41964 (95%)]\tLoss: 0.329149\n",
      "Train Epoch: 4 [40320/41964 (96%)]\tLoss: 0.367984\n",
      "Train Epoch: 4 [40960/41964 (98%)]\tLoss: 0.283221\n",
      "Train Epoch: 4 [41600/41964 (99%)]\tLoss: 0.526308\n",
      "\n",
      "Test set: Avg. loss: 0.1234, Accuracy: 9637/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/41964 (0%)]\tLoss: 0.387223\n",
      "Train Epoch: 5 [640/41964 (2%)]\tLoss: 0.295525\n",
      "Train Epoch: 5 [1280/41964 (3%)]\tLoss: 0.290139\n",
      "Train Epoch: 5 [1920/41964 (5%)]\tLoss: 0.243913\n",
      "Train Epoch: 5 [2560/41964 (6%)]\tLoss: 0.432722\n",
      "Train Epoch: 5 [3200/41964 (8%)]\tLoss: 0.206952\n",
      "Train Epoch: 5 [3840/41964 (9%)]\tLoss: 0.340437\n",
      "Train Epoch: 5 [4480/41964 (11%)]\tLoss: 0.359591\n",
      "Train Epoch: 5 [5120/41964 (12%)]\tLoss: 0.176307\n",
      "Train Epoch: 5 [5760/41964 (14%)]\tLoss: 0.342536\n",
      "Train Epoch: 5 [6400/41964 (15%)]\tLoss: 0.428542\n",
      "Train Epoch: 5 [7040/41964 (17%)]\tLoss: 0.338175\n",
      "Train Epoch: 5 [7680/41964 (18%)]\tLoss: 0.586129\n",
      "Train Epoch: 5 [8320/41964 (20%)]\tLoss: 0.230716\n",
      "Train Epoch: 5 [8960/41964 (21%)]\tLoss: 0.256840\n",
      "Train Epoch: 5 [9600/41964 (23%)]\tLoss: 0.277445\n",
      "Train Epoch: 5 [10240/41964 (24%)]\tLoss: 0.322424\n",
      "Train Epoch: 5 [10880/41964 (26%)]\tLoss: 0.160047\n",
      "Train Epoch: 5 [11520/41964 (27%)]\tLoss: 0.258566\n",
      "Train Epoch: 5 [12160/41964 (29%)]\tLoss: 0.156603\n",
      "Train Epoch: 5 [12800/41964 (30%)]\tLoss: 0.368904\n",
      "Train Epoch: 5 [13440/41964 (32%)]\tLoss: 0.301876\n",
      "Train Epoch: 5 [14080/41964 (34%)]\tLoss: 0.248792\n",
      "Train Epoch: 5 [14720/41964 (35%)]\tLoss: 0.290582\n",
      "Train Epoch: 5 [15360/41964 (37%)]\tLoss: 0.288827\n",
      "Train Epoch: 5 [16000/41964 (38%)]\tLoss: 0.402097\n",
      "Train Epoch: 5 [16640/41964 (40%)]\tLoss: 0.375185\n",
      "Train Epoch: 5 [17280/41964 (41%)]\tLoss: 0.455944\n",
      "Train Epoch: 5 [17920/41964 (43%)]\tLoss: 0.306480\n",
      "Train Epoch: 5 [18560/41964 (44%)]\tLoss: 0.277696\n",
      "Train Epoch: 5 [19200/41964 (46%)]\tLoss: 0.300097\n",
      "Train Epoch: 5 [19840/41964 (47%)]\tLoss: 0.457847\n",
      "Train Epoch: 5 [20480/41964 (49%)]\tLoss: 0.177149\n",
      "Train Epoch: 5 [21120/41964 (50%)]\tLoss: 0.186931\n",
      "Train Epoch: 5 [21760/41964 (52%)]\tLoss: 0.147379\n",
      "Train Epoch: 5 [22400/41964 (53%)]\tLoss: 0.574309\n",
      "Train Epoch: 5 [23040/41964 (55%)]\tLoss: 0.396510\n",
      "Train Epoch: 5 [23680/41964 (56%)]\tLoss: 0.264982\n",
      "Train Epoch: 5 [24320/41964 (58%)]\tLoss: 0.495937\n",
      "Train Epoch: 5 [24960/41964 (59%)]\tLoss: 0.498428\n",
      "Train Epoch: 5 [25600/41964 (61%)]\tLoss: 0.317435\n",
      "Train Epoch: 5 [26240/41964 (62%)]\tLoss: 0.394933\n",
      "Train Epoch: 5 [26880/41964 (64%)]\tLoss: 0.448338\n",
      "Train Epoch: 5 [27520/41964 (66%)]\tLoss: 0.220252\n",
      "Train Epoch: 5 [28160/41964 (67%)]\tLoss: 0.463917\n",
      "Train Epoch: 5 [28800/41964 (69%)]\tLoss: 0.291710\n",
      "Train Epoch: 5 [29440/41964 (70%)]\tLoss: 0.316189\n",
      "Train Epoch: 5 [30080/41964 (72%)]\tLoss: 0.233470\n",
      "Train Epoch: 5 [30720/41964 (73%)]\tLoss: 0.325400\n",
      "Train Epoch: 5 [31360/41964 (75%)]\tLoss: 0.267501\n",
      "Train Epoch: 5 [32000/41964 (76%)]\tLoss: 0.374902\n",
      "Train Epoch: 5 [32640/41964 (78%)]\tLoss: 0.440209\n",
      "Train Epoch: 5 [33280/41964 (79%)]\tLoss: 0.475971\n",
      "Train Epoch: 5 [33920/41964 (81%)]\tLoss: 0.408237\n",
      "Train Epoch: 5 [34560/41964 (82%)]\tLoss: 0.215547\n",
      "Train Epoch: 5 [35200/41964 (84%)]\tLoss: 0.249037\n",
      "Train Epoch: 5 [35840/41964 (85%)]\tLoss: 0.589151\n",
      "Train Epoch: 5 [36480/41964 (87%)]\tLoss: 0.391840\n",
      "Train Epoch: 5 [37120/41964 (88%)]\tLoss: 0.307360\n",
      "Train Epoch: 5 [37760/41964 (90%)]\tLoss: 0.301078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [38400/41964 (91%)]\tLoss: 0.212313\n",
      "Train Epoch: 5 [39040/41964 (93%)]\tLoss: 0.213398\n",
      "Train Epoch: 5 [39680/41964 (95%)]\tLoss: 0.146912\n",
      "Train Epoch: 5 [40320/41964 (96%)]\tLoss: 0.312016\n",
      "Train Epoch: 5 [40960/41964 (98%)]\tLoss: 0.285090\n",
      "Train Epoch: 5 [41600/41964 (99%)]\tLoss: 0.302394\n",
      "\n",
      "Test set: Avg. loss: 0.1083, Accuracy: 9669/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/41964 (0%)]\tLoss: 0.276055\n",
      "Train Epoch: 6 [640/41964 (2%)]\tLoss: 0.385486\n",
      "Train Epoch: 6 [1280/41964 (3%)]\tLoss: 0.300206\n",
      "Train Epoch: 6 [1920/41964 (5%)]\tLoss: 0.272848\n",
      "Train Epoch: 6 [2560/41964 (6%)]\tLoss: 0.304404\n",
      "Train Epoch: 6 [3200/41964 (8%)]\tLoss: 0.322994\n",
      "Train Epoch: 6 [3840/41964 (9%)]\tLoss: 0.276475\n",
      "Train Epoch: 6 [4480/41964 (11%)]\tLoss: 0.241819\n",
      "Train Epoch: 6 [5120/41964 (12%)]\tLoss: 0.454435\n",
      "Train Epoch: 6 [5760/41964 (14%)]\tLoss: 0.350045\n",
      "Train Epoch: 6 [6400/41964 (15%)]\tLoss: 0.333465\n",
      "Train Epoch: 6 [7040/41964 (17%)]\tLoss: 0.301899\n",
      "Train Epoch: 6 [7680/41964 (18%)]\tLoss: 0.378330\n",
      "Train Epoch: 6 [8320/41964 (20%)]\tLoss: 0.160277\n",
      "Train Epoch: 6 [8960/41964 (21%)]\tLoss: 0.293527\n",
      "Train Epoch: 6 [9600/41964 (23%)]\tLoss: 0.282439\n",
      "Train Epoch: 6 [10240/41964 (24%)]\tLoss: 0.368478\n",
      "Train Epoch: 6 [10880/41964 (26%)]\tLoss: 0.390674\n",
      "Train Epoch: 6 [11520/41964 (27%)]\tLoss: 0.294935\n",
      "Train Epoch: 6 [12160/41964 (29%)]\tLoss: 0.294081\n",
      "Train Epoch: 6 [12800/41964 (30%)]\tLoss: 0.154196\n",
      "Train Epoch: 6 [13440/41964 (32%)]\tLoss: 0.141038\n",
      "Train Epoch: 6 [14080/41964 (34%)]\tLoss: 0.397852\n",
      "Train Epoch: 6 [14720/41964 (35%)]\tLoss: 0.384485\n",
      "Train Epoch: 6 [15360/41964 (37%)]\tLoss: 0.409367\n",
      "Train Epoch: 6 [16000/41964 (38%)]\tLoss: 0.145810\n",
      "Train Epoch: 6 [16640/41964 (40%)]\tLoss: 0.316464\n",
      "Train Epoch: 6 [17280/41964 (41%)]\tLoss: 0.428956\n",
      "Train Epoch: 6 [17920/41964 (43%)]\tLoss: 0.308897\n",
      "Train Epoch: 6 [18560/41964 (44%)]\tLoss: 0.381665\n",
      "Train Epoch: 6 [19200/41964 (46%)]\tLoss: 0.257822\n",
      "Train Epoch: 6 [19840/41964 (47%)]\tLoss: 0.183594\n",
      "Train Epoch: 6 [20480/41964 (49%)]\tLoss: 0.500192\n",
      "Train Epoch: 6 [21120/41964 (50%)]\tLoss: 0.397685\n",
      "Train Epoch: 6 [21760/41964 (52%)]\tLoss: 0.273678\n",
      "Train Epoch: 6 [22400/41964 (53%)]\tLoss: 0.236899\n",
      "Train Epoch: 6 [23040/41964 (55%)]\tLoss: 0.196838\n",
      "Train Epoch: 6 [23680/41964 (56%)]\tLoss: 0.232215\n",
      "Train Epoch: 6 [24320/41964 (58%)]\tLoss: 0.247834\n",
      "Train Epoch: 6 [24960/41964 (59%)]\tLoss: 0.476718\n",
      "Train Epoch: 6 [25600/41964 (61%)]\tLoss: 0.410071\n",
      "Train Epoch: 6 [26240/41964 (62%)]\tLoss: 0.152631\n",
      "Train Epoch: 6 [26880/41964 (64%)]\tLoss: 0.306906\n",
      "Train Epoch: 6 [27520/41964 (66%)]\tLoss: 0.427807\n",
      "Train Epoch: 6 [28160/41964 (67%)]\tLoss: 0.148827\n",
      "Train Epoch: 6 [28800/41964 (69%)]\tLoss: 0.520438\n",
      "Train Epoch: 6 [29440/41964 (70%)]\tLoss: 0.240457\n",
      "Train Epoch: 6 [30080/41964 (72%)]\tLoss: 0.276038\n",
      "Train Epoch: 6 [30720/41964 (73%)]\tLoss: 0.241236\n",
      "Train Epoch: 6 [31360/41964 (75%)]\tLoss: 0.382607\n",
      "Train Epoch: 6 [32000/41964 (76%)]\tLoss: 0.237818\n",
      "Train Epoch: 6 [32640/41964 (78%)]\tLoss: 0.400719\n",
      "Train Epoch: 6 [33280/41964 (79%)]\tLoss: 0.316117\n",
      "Train Epoch: 6 [33920/41964 (81%)]\tLoss: 0.139128\n",
      "Train Epoch: 6 [34560/41964 (82%)]\tLoss: 0.335645\n",
      "Train Epoch: 6 [35200/41964 (84%)]\tLoss: 0.295650\n",
      "Train Epoch: 6 [35840/41964 (85%)]\tLoss: 0.338178\n",
      "Train Epoch: 6 [36480/41964 (87%)]\tLoss: 0.339366\n",
      "Train Epoch: 6 [37120/41964 (88%)]\tLoss: 0.179874\n",
      "Train Epoch: 6 [37760/41964 (90%)]\tLoss: 0.369743\n",
      "Train Epoch: 6 [38400/41964 (91%)]\tLoss: 0.150766\n",
      "Train Epoch: 6 [39040/41964 (93%)]\tLoss: 0.326850\n",
      "Train Epoch: 6 [39680/41964 (95%)]\tLoss: 0.295393\n",
      "Train Epoch: 6 [40320/41964 (96%)]\tLoss: 0.236576\n",
      "Train Epoch: 6 [40960/41964 (98%)]\tLoss: 0.279055\n",
      "Train Epoch: 6 [41600/41964 (99%)]\tLoss: 0.401428\n",
      "\n",
      "Test set: Avg. loss: 0.0947, Accuracy: 9718/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/41964 (0%)]\tLoss: 0.324325\n",
      "Train Epoch: 7 [640/41964 (2%)]\tLoss: 0.329599\n",
      "Train Epoch: 7 [1280/41964 (3%)]\tLoss: 0.185226\n",
      "Train Epoch: 7 [1920/41964 (5%)]\tLoss: 0.165850\n",
      "Train Epoch: 7 [2560/41964 (6%)]\tLoss: 0.443696\n",
      "Train Epoch: 7 [3200/41964 (8%)]\tLoss: 0.315200\n",
      "Train Epoch: 7 [3840/41964 (9%)]\tLoss: 0.340783\n",
      "Train Epoch: 7 [4480/41964 (11%)]\tLoss: 0.213406\n",
      "Train Epoch: 7 [5120/41964 (12%)]\tLoss: 0.224290\n",
      "Train Epoch: 7 [5760/41964 (14%)]\tLoss: 0.388655\n",
      "Train Epoch: 7 [6400/41964 (15%)]\tLoss: 0.512958\n",
      "Train Epoch: 7 [7040/41964 (17%)]\tLoss: 0.196670\n",
      "Train Epoch: 7 [7680/41964 (18%)]\tLoss: 0.114939\n",
      "Train Epoch: 7 [8320/41964 (20%)]\tLoss: 0.366751\n",
      "Train Epoch: 7 [8960/41964 (21%)]\tLoss: 0.178973\n",
      "Train Epoch: 7 [9600/41964 (23%)]\tLoss: 0.285418\n",
      "Train Epoch: 7 [10240/41964 (24%)]\tLoss: 0.308422\n",
      "Train Epoch: 7 [10880/41964 (26%)]\tLoss: 0.277287\n",
      "Train Epoch: 7 [11520/41964 (27%)]\tLoss: 0.156711\n",
      "Train Epoch: 7 [12160/41964 (29%)]\tLoss: 0.188862\n",
      "Train Epoch: 7 [12800/41964 (30%)]\tLoss: 0.287699\n",
      "Train Epoch: 7 [13440/41964 (32%)]\tLoss: 0.289162\n",
      "Train Epoch: 7 [14080/41964 (34%)]\tLoss: 0.424970\n",
      "Train Epoch: 7 [14720/41964 (35%)]\tLoss: 0.367030\n",
      "Train Epoch: 7 [15360/41964 (37%)]\tLoss: 0.312710\n",
      "Train Epoch: 7 [16000/41964 (38%)]\tLoss: 0.309014\n",
      "Train Epoch: 7 [16640/41964 (40%)]\tLoss: 0.233588\n",
      "Train Epoch: 7 [17280/41964 (41%)]\tLoss: 0.171752\n",
      "Train Epoch: 7 [17920/41964 (43%)]\tLoss: 0.181243\n",
      "Train Epoch: 7 [18560/41964 (44%)]\tLoss: 0.427077\n",
      "Train Epoch: 7 [19200/41964 (46%)]\tLoss: 0.348170\n",
      "Train Epoch: 7 [19840/41964 (47%)]\tLoss: 0.325807\n",
      "Train Epoch: 7 [20480/41964 (49%)]\tLoss: 0.449800\n",
      "Train Epoch: 7 [21120/41964 (50%)]\tLoss: 0.251724\n",
      "Train Epoch: 7 [21760/41964 (52%)]\tLoss: 0.326223\n",
      "Train Epoch: 7 [22400/41964 (53%)]\tLoss: 0.345550\n",
      "Train Epoch: 7 [23040/41964 (55%)]\tLoss: 0.244518\n",
      "Train Epoch: 7 [23680/41964 (56%)]\tLoss: 0.237368\n",
      "Train Epoch: 7 [24320/41964 (58%)]\tLoss: 0.257004\n",
      "Train Epoch: 7 [24960/41964 (59%)]\tLoss: 0.131736\n",
      "Train Epoch: 7 [25600/41964 (61%)]\tLoss: 0.315886\n",
      "Train Epoch: 7 [26240/41964 (62%)]\tLoss: 0.245864\n",
      "Train Epoch: 7 [26880/41964 (64%)]\tLoss: 0.251490\n",
      "Train Epoch: 7 [27520/41964 (66%)]\tLoss: 0.262969\n",
      "Train Epoch: 7 [28160/41964 (67%)]\tLoss: 0.289860\n",
      "Train Epoch: 7 [28800/41964 (69%)]\tLoss: 0.208381\n",
      "Train Epoch: 7 [29440/41964 (70%)]\tLoss: 0.302439\n",
      "Train Epoch: 7 [30080/41964 (72%)]\tLoss: 0.188454\n",
      "Train Epoch: 7 [30720/41964 (73%)]\tLoss: 0.373573\n",
      "Train Epoch: 7 [31360/41964 (75%)]\tLoss: 0.180107\n",
      "Train Epoch: 7 [32000/41964 (76%)]\tLoss: 0.378209\n",
      "Train Epoch: 7 [32640/41964 (78%)]\tLoss: 0.164488\n",
      "Train Epoch: 7 [33280/41964 (79%)]\tLoss: 0.259346\n",
      "Train Epoch: 7 [33920/41964 (81%)]\tLoss: 0.396720\n",
      "Train Epoch: 7 [34560/41964 (82%)]\tLoss: 0.479319\n",
      "Train Epoch: 7 [35200/41964 (84%)]\tLoss: 0.155878\n",
      "Train Epoch: 7 [35840/41964 (85%)]\tLoss: 0.202144\n",
      "Train Epoch: 7 [36480/41964 (87%)]\tLoss: 0.171714\n",
      "Train Epoch: 7 [37120/41964 (88%)]\tLoss: 0.301277\n",
      "Train Epoch: 7 [37760/41964 (90%)]\tLoss: 0.270837\n",
      "Train Epoch: 7 [38400/41964 (91%)]\tLoss: 0.167248\n",
      "Train Epoch: 7 [39040/41964 (93%)]\tLoss: 0.184430\n",
      "Train Epoch: 7 [39680/41964 (95%)]\tLoss: 0.228365\n",
      "Train Epoch: 7 [40320/41964 (96%)]\tLoss: 0.167266\n",
      "Train Epoch: 7 [40960/41964 (98%)]\tLoss: 0.277415\n",
      "Train Epoch: 7 [41600/41964 (99%)]\tLoss: 0.079908\n",
      "\n",
      "Test set: Avg. loss: 0.0883, Accuracy: 9737/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/41964 (0%)]\tLoss: 0.275373\n",
      "Train Epoch: 8 [640/41964 (2%)]\tLoss: 0.320481\n",
      "Train Epoch: 8 [1280/41964 (3%)]\tLoss: 0.384683\n",
      "Train Epoch: 8 [1920/41964 (5%)]\tLoss: 0.236538\n",
      "Train Epoch: 8 [2560/41964 (6%)]\tLoss: 0.309470\n",
      "Train Epoch: 8 [3200/41964 (8%)]\tLoss: 0.183364\n",
      "Train Epoch: 8 [3840/41964 (9%)]\tLoss: 0.252991\n",
      "Train Epoch: 8 [4480/41964 (11%)]\tLoss: 0.400972\n",
      "Train Epoch: 8 [5120/41964 (12%)]\tLoss: 0.248802\n",
      "Train Epoch: 8 [5760/41964 (14%)]\tLoss: 0.217893\n",
      "Train Epoch: 8 [6400/41964 (15%)]\tLoss: 0.324613\n",
      "Train Epoch: 8 [7040/41964 (17%)]\tLoss: 0.214285\n",
      "Train Epoch: 8 [7680/41964 (18%)]\tLoss: 0.318055\n",
      "Train Epoch: 8 [8320/41964 (20%)]\tLoss: 0.309013\n",
      "Train Epoch: 8 [8960/41964 (21%)]\tLoss: 0.236762\n",
      "Train Epoch: 8 [9600/41964 (23%)]\tLoss: 0.517727\n",
      "Train Epoch: 8 [10240/41964 (24%)]\tLoss: 0.271808\n",
      "Train Epoch: 8 [10880/41964 (26%)]\tLoss: 0.307530\n",
      "Train Epoch: 8 [11520/41964 (27%)]\tLoss: 0.225109\n",
      "Train Epoch: 8 [12160/41964 (29%)]\tLoss: 0.538358\n",
      "Train Epoch: 8 [12800/41964 (30%)]\tLoss: 0.186490\n",
      "Train Epoch: 8 [13440/41964 (32%)]\tLoss: 0.229074\n",
      "Train Epoch: 8 [14080/41964 (34%)]\tLoss: 0.232736\n",
      "Train Epoch: 8 [14720/41964 (35%)]\tLoss: 0.228098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [15360/41964 (37%)]\tLoss: 0.155450\n",
      "Train Epoch: 8 [16000/41964 (38%)]\tLoss: 0.408982\n",
      "Train Epoch: 8 [16640/41964 (40%)]\tLoss: 0.239886\n",
      "Train Epoch: 8 [17280/41964 (41%)]\tLoss: 0.231563\n",
      "Train Epoch: 8 [17920/41964 (43%)]\tLoss: 0.284778\n",
      "Train Epoch: 8 [18560/41964 (44%)]\tLoss: 0.315738\n",
      "Train Epoch: 8 [19200/41964 (46%)]\tLoss: 0.143564\n",
      "Train Epoch: 8 [19840/41964 (47%)]\tLoss: 0.214584\n",
      "Train Epoch: 8 [20480/41964 (49%)]\tLoss: 0.174144\n",
      "Train Epoch: 8 [21120/41964 (50%)]\tLoss: 0.208516\n",
      "Train Epoch: 8 [21760/41964 (52%)]\tLoss: 0.323373\n",
      "Train Epoch: 8 [22400/41964 (53%)]\tLoss: 0.186340\n",
      "Train Epoch: 8 [23040/41964 (55%)]\tLoss: 0.143113\n",
      "Train Epoch: 8 [23680/41964 (56%)]\tLoss: 0.213041\n",
      "Train Epoch: 8 [24320/41964 (58%)]\tLoss: 0.150900\n",
      "Train Epoch: 8 [24960/41964 (59%)]\tLoss: 0.280769\n",
      "Train Epoch: 8 [25600/41964 (61%)]\tLoss: 0.238746\n",
      "Train Epoch: 8 [26240/41964 (62%)]\tLoss: 0.414719\n",
      "Train Epoch: 8 [26880/41964 (64%)]\tLoss: 0.288042\n",
      "Train Epoch: 8 [27520/41964 (66%)]\tLoss: 0.166418\n",
      "Train Epoch: 8 [28160/41964 (67%)]\tLoss: 0.167146\n",
      "Train Epoch: 8 [28800/41964 (69%)]\tLoss: 0.230258\n",
      "Train Epoch: 8 [29440/41964 (70%)]\tLoss: 0.147807\n",
      "Train Epoch: 8 [30080/41964 (72%)]\tLoss: 0.315399\n",
      "Train Epoch: 8 [30720/41964 (73%)]\tLoss: 0.206218\n",
      "Train Epoch: 8 [31360/41964 (75%)]\tLoss: 0.399580\n",
      "Train Epoch: 8 [32000/41964 (76%)]\tLoss: 0.157130\n",
      "Train Epoch: 8 [32640/41964 (78%)]\tLoss: 0.241699\n",
      "Train Epoch: 8 [33280/41964 (79%)]\tLoss: 0.247787\n",
      "Train Epoch: 8 [33920/41964 (81%)]\tLoss: 0.324534\n",
      "Train Epoch: 8 [34560/41964 (82%)]\tLoss: 0.199389\n",
      "Train Epoch: 8 [35200/41964 (84%)]\tLoss: 0.351167\n",
      "Train Epoch: 8 [35840/41964 (85%)]\tLoss: 0.206886\n",
      "Train Epoch: 8 [36480/41964 (87%)]\tLoss: 0.471422\n",
      "Train Epoch: 8 [37120/41964 (88%)]\tLoss: 0.224173\n",
      "Train Epoch: 8 [37760/41964 (90%)]\tLoss: 0.369390\n",
      "Train Epoch: 8 [38400/41964 (91%)]\tLoss: 0.204180\n",
      "Train Epoch: 8 [39040/41964 (93%)]\tLoss: 0.193002\n",
      "Train Epoch: 8 [39680/41964 (95%)]\tLoss: 0.230060\n",
      "Train Epoch: 8 [40320/41964 (96%)]\tLoss: 0.157263\n",
      "Train Epoch: 8 [40960/41964 (98%)]\tLoss: 0.203770\n",
      "Train Epoch: 8 [41600/41964 (99%)]\tLoss: 0.477667\n",
      "\n",
      "Test set: Avg. loss: 0.0807, Accuracy: 9743/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/41964 (0%)]\tLoss: 0.205988\n",
      "Train Epoch: 9 [640/41964 (2%)]\tLoss: 0.118776\n",
      "Train Epoch: 9 [1280/41964 (3%)]\tLoss: 0.169239\n",
      "Train Epoch: 9 [1920/41964 (5%)]\tLoss: 0.287402\n",
      "Train Epoch: 9 [2560/41964 (6%)]\tLoss: 0.130837\n",
      "Train Epoch: 9 [3200/41964 (8%)]\tLoss: 0.340486\n",
      "Train Epoch: 9 [3840/41964 (9%)]\tLoss: 0.096056\n",
      "Train Epoch: 9 [4480/41964 (11%)]\tLoss: 0.182593\n",
      "Train Epoch: 9 [5120/41964 (12%)]\tLoss: 0.342976\n",
      "Train Epoch: 9 [5760/41964 (14%)]\tLoss: 0.420109\n",
      "Train Epoch: 9 [6400/41964 (15%)]\tLoss: 0.158498\n",
      "Train Epoch: 9 [7040/41964 (17%)]\tLoss: 0.286438\n",
      "Train Epoch: 9 [7680/41964 (18%)]\tLoss: 0.366568\n",
      "Train Epoch: 9 [8320/41964 (20%)]\tLoss: 0.441498\n",
      "Train Epoch: 9 [8960/41964 (21%)]\tLoss: 0.174009\n",
      "Train Epoch: 9 [9600/41964 (23%)]\tLoss: 0.084328\n",
      "Train Epoch: 9 [10240/41964 (24%)]\tLoss: 0.229957\n",
      "Train Epoch: 9 [10880/41964 (26%)]\tLoss: 0.322757\n",
      "Train Epoch: 9 [11520/41964 (27%)]\tLoss: 0.379545\n",
      "Train Epoch: 9 [12160/41964 (29%)]\tLoss: 0.335550\n",
      "Train Epoch: 9 [12800/41964 (30%)]\tLoss: 0.239230\n",
      "Train Epoch: 9 [13440/41964 (32%)]\tLoss: 0.281023\n",
      "Train Epoch: 9 [14080/41964 (34%)]\tLoss: 0.569500\n",
      "Train Epoch: 9 [14720/41964 (35%)]\tLoss: 0.354406\n",
      "Train Epoch: 9 [15360/41964 (37%)]\tLoss: 0.470020\n",
      "Train Epoch: 9 [16000/41964 (38%)]\tLoss: 0.292053\n",
      "Train Epoch: 9 [16640/41964 (40%)]\tLoss: 0.156780\n",
      "Train Epoch: 9 [17280/41964 (41%)]\tLoss: 0.181011\n",
      "Train Epoch: 9 [17920/41964 (43%)]\tLoss: 0.349981\n",
      "Train Epoch: 9 [18560/41964 (44%)]\tLoss: 0.325668\n",
      "Train Epoch: 9 [19200/41964 (46%)]\tLoss: 0.111477\n",
      "Train Epoch: 9 [19840/41964 (47%)]\tLoss: 0.211849\n",
      "Train Epoch: 9 [20480/41964 (49%)]\tLoss: 0.269178\n",
      "Train Epoch: 9 [21120/41964 (50%)]\tLoss: 0.367063\n",
      "Train Epoch: 9 [21760/41964 (52%)]\tLoss: 0.186691\n",
      "Train Epoch: 9 [22400/41964 (53%)]\tLoss: 0.158723\n",
      "Train Epoch: 9 [23040/41964 (55%)]\tLoss: 0.296063\n",
      "Train Epoch: 9 [23680/41964 (56%)]\tLoss: 0.178868\n",
      "Train Epoch: 9 [24320/41964 (58%)]\tLoss: 0.163783\n",
      "Train Epoch: 9 [24960/41964 (59%)]\tLoss: 0.204829\n",
      "Train Epoch: 9 [25600/41964 (61%)]\tLoss: 0.442528\n",
      "Train Epoch: 9 [26240/41964 (62%)]\tLoss: 0.270223\n",
      "Train Epoch: 9 [26880/41964 (64%)]\tLoss: 0.222718\n",
      "Train Epoch: 9 [27520/41964 (66%)]\tLoss: 0.245052\n",
      "Train Epoch: 9 [28160/41964 (67%)]\tLoss: 0.183889\n",
      "Train Epoch: 9 [28800/41964 (69%)]\tLoss: 0.174358\n",
      "Train Epoch: 9 [29440/41964 (70%)]\tLoss: 0.239255\n",
      "Train Epoch: 9 [30080/41964 (72%)]\tLoss: 0.377533\n",
      "Train Epoch: 9 [30720/41964 (73%)]\tLoss: 0.197927\n",
      "Train Epoch: 9 [31360/41964 (75%)]\tLoss: 0.091078\n",
      "Train Epoch: 9 [32000/41964 (76%)]\tLoss: 0.348862\n",
      "Train Epoch: 9 [32640/41964 (78%)]\tLoss: 0.355455\n",
      "Train Epoch: 9 [33280/41964 (79%)]\tLoss: 0.194554\n",
      "Train Epoch: 9 [33920/41964 (81%)]\tLoss: 0.305642\n",
      "Train Epoch: 9 [34560/41964 (82%)]\tLoss: 0.300305\n",
      "Train Epoch: 9 [35200/41964 (84%)]\tLoss: 0.139739\n",
      "Train Epoch: 9 [35840/41964 (85%)]\tLoss: 0.188528\n",
      "Train Epoch: 9 [36480/41964 (87%)]\tLoss: 0.344638\n",
      "Train Epoch: 9 [37120/41964 (88%)]\tLoss: 0.236377\n",
      "Train Epoch: 9 [37760/41964 (90%)]\tLoss: 0.282645\n",
      "Train Epoch: 9 [38400/41964 (91%)]\tLoss: 0.121249\n",
      "Train Epoch: 9 [39040/41964 (93%)]\tLoss: 0.156449\n",
      "Train Epoch: 9 [39680/41964 (95%)]\tLoss: 0.186209\n",
      "Train Epoch: 9 [40320/41964 (96%)]\tLoss: 0.233909\n",
      "Train Epoch: 9 [40960/41964 (98%)]\tLoss: 0.154766\n",
      "Train Epoch: 9 [41600/41964 (99%)]\tLoss: 0.170419\n",
      "\n",
      "Test set: Avg. loss: 0.0790, Accuracy: 9748/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/41964 (0%)]\tLoss: 0.284297\n",
      "Train Epoch: 10 [640/41964 (2%)]\tLoss: 0.096671\n",
      "Train Epoch: 10 [1280/41964 (3%)]\tLoss: 0.331802\n",
      "Train Epoch: 10 [1920/41964 (5%)]\tLoss: 0.226319\n",
      "Train Epoch: 10 [2560/41964 (6%)]\tLoss: 0.200167\n",
      "Train Epoch: 10 [3200/41964 (8%)]\tLoss: 0.304379\n",
      "Train Epoch: 10 [3840/41964 (9%)]\tLoss: 0.326023\n",
      "Train Epoch: 10 [4480/41964 (11%)]\tLoss: 0.221883\n",
      "Train Epoch: 10 [5120/41964 (12%)]\tLoss: 0.380619\n",
      "Train Epoch: 10 [5760/41964 (14%)]\tLoss: 0.176492\n",
      "Train Epoch: 10 [6400/41964 (15%)]\tLoss: 0.192290\n",
      "Train Epoch: 10 [7040/41964 (17%)]\tLoss: 0.318878\n",
      "Train Epoch: 10 [7680/41964 (18%)]\tLoss: 0.406510\n",
      "Train Epoch: 10 [8320/41964 (20%)]\tLoss: 0.159948\n",
      "Train Epoch: 10 [8960/41964 (21%)]\tLoss: 0.222177\n",
      "Train Epoch: 10 [9600/41964 (23%)]\tLoss: 0.160668\n",
      "Train Epoch: 10 [10240/41964 (24%)]\tLoss: 0.134698\n",
      "Train Epoch: 10 [10880/41964 (26%)]\tLoss: 0.225808\n",
      "Train Epoch: 10 [11520/41964 (27%)]\tLoss: 0.159888\n",
      "Train Epoch: 10 [12160/41964 (29%)]\tLoss: 0.202962\n",
      "Train Epoch: 10 [12800/41964 (30%)]\tLoss: 0.225243\n",
      "Train Epoch: 10 [13440/41964 (32%)]\tLoss: 0.243797\n",
      "Train Epoch: 10 [14080/41964 (34%)]\tLoss: 0.335857\n",
      "Train Epoch: 10 [14720/41964 (35%)]\tLoss: 0.162392\n",
      "Train Epoch: 10 [15360/41964 (37%)]\tLoss: 0.198821\n",
      "Train Epoch: 10 [16000/41964 (38%)]\tLoss: 0.516542\n",
      "Train Epoch: 10 [16640/41964 (40%)]\tLoss: 0.439002\n",
      "Train Epoch: 10 [17280/41964 (41%)]\tLoss: 0.116221\n",
      "Train Epoch: 10 [17920/41964 (43%)]\tLoss: 0.282841\n",
      "Train Epoch: 10 [18560/41964 (44%)]\tLoss: 0.259221\n",
      "Train Epoch: 10 [19200/41964 (46%)]\tLoss: 0.264407\n",
      "Train Epoch: 10 [19840/41964 (47%)]\tLoss: 0.175179\n",
      "Train Epoch: 10 [20480/41964 (49%)]\tLoss: 0.373151\n",
      "Train Epoch: 10 [21120/41964 (50%)]\tLoss: 0.313184\n",
      "Train Epoch: 10 [21760/41964 (52%)]\tLoss: 0.174759\n",
      "Train Epoch: 10 [22400/41964 (53%)]\tLoss: 0.117158\n",
      "Train Epoch: 10 [23040/41964 (55%)]\tLoss: 0.227660\n",
      "Train Epoch: 10 [23680/41964 (56%)]\tLoss: 0.108475\n",
      "Train Epoch: 10 [24320/41964 (58%)]\tLoss: 0.136718\n",
      "Train Epoch: 10 [24960/41964 (59%)]\tLoss: 0.276849\n",
      "Train Epoch: 10 [25600/41964 (61%)]\tLoss: 0.254644\n",
      "Train Epoch: 10 [26240/41964 (62%)]\tLoss: 0.330613\n",
      "Train Epoch: 10 [26880/41964 (64%)]\tLoss: 0.167213\n",
      "Train Epoch: 10 [27520/41964 (66%)]\tLoss: 0.396704\n",
      "Train Epoch: 10 [28160/41964 (67%)]\tLoss: 0.198777\n",
      "Train Epoch: 10 [28800/41964 (69%)]\tLoss: 0.173890\n",
      "Train Epoch: 10 [29440/41964 (70%)]\tLoss: 0.180112\n",
      "Train Epoch: 10 [30080/41964 (72%)]\tLoss: 0.386823\n",
      "Train Epoch: 10 [30720/41964 (73%)]\tLoss: 0.227133\n",
      "Train Epoch: 10 [31360/41964 (75%)]\tLoss: 0.212046\n",
      "Train Epoch: 10 [32000/41964 (76%)]\tLoss: 0.252014\n",
      "Train Epoch: 10 [32640/41964 (78%)]\tLoss: 0.347950\n",
      "Train Epoch: 10 [33280/41964 (79%)]\tLoss: 0.240743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [33920/41964 (81%)]\tLoss: 0.165099\n",
      "Train Epoch: 10 [34560/41964 (82%)]\tLoss: 0.190041\n",
      "Train Epoch: 10 [35200/41964 (84%)]\tLoss: 0.185814\n",
      "Train Epoch: 10 [35840/41964 (85%)]\tLoss: 0.190343\n",
      "Train Epoch: 10 [36480/41964 (87%)]\tLoss: 0.484387\n",
      "Train Epoch: 10 [37120/41964 (88%)]\tLoss: 0.231815\n",
      "Train Epoch: 10 [37760/41964 (90%)]\tLoss: 0.295091\n",
      "Train Epoch: 10 [38400/41964 (91%)]\tLoss: 0.200864\n",
      "Train Epoch: 10 [39040/41964 (93%)]\tLoss: 0.111210\n",
      "Train Epoch: 10 [39680/41964 (95%)]\tLoss: 0.117660\n",
      "Train Epoch: 10 [40320/41964 (96%)]\tLoss: 0.195988\n",
      "Train Epoch: 10 [40960/41964 (98%)]\tLoss: 0.211053\n",
      "Train Epoch: 10 [41600/41964 (99%)]\tLoss: 0.571109\n",
      "\n",
      "Test set: Avg. loss: 0.0714, Accuracy: 9782/10000 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/41964 (0%)]\tLoss: 0.607227\n",
      "Train Epoch: 11 [640/41964 (2%)]\tLoss: 0.387090\n",
      "Train Epoch: 11 [1280/41964 (3%)]\tLoss: 0.287362\n",
      "Train Epoch: 11 [1920/41964 (5%)]\tLoss: 0.190083\n",
      "Train Epoch: 11 [2560/41964 (6%)]\tLoss: 0.203404\n",
      "Train Epoch: 11 [3200/41964 (8%)]\tLoss: 0.175885\n",
      "Train Epoch: 11 [3840/41964 (9%)]\tLoss: 0.207547\n",
      "Train Epoch: 11 [4480/41964 (11%)]\tLoss: 0.262263\n",
      "Train Epoch: 11 [5120/41964 (12%)]\tLoss: 0.124734\n",
      "Train Epoch: 11 [5760/41964 (14%)]\tLoss: 0.198627\n",
      "Train Epoch: 11 [6400/41964 (15%)]\tLoss: 0.446710\n",
      "Train Epoch: 11 [7040/41964 (17%)]\tLoss: 0.208177\n",
      "Train Epoch: 11 [7680/41964 (18%)]\tLoss: 0.187880\n",
      "Train Epoch: 11 [8320/41964 (20%)]\tLoss: 0.117103\n",
      "Train Epoch: 11 [8960/41964 (21%)]\tLoss: 0.130329\n",
      "Train Epoch: 11 [9600/41964 (23%)]\tLoss: 0.155750\n",
      "Train Epoch: 11 [10240/41964 (24%)]\tLoss: 0.218547\n",
      "Train Epoch: 11 [10880/41964 (26%)]\tLoss: 0.303649\n",
      "Train Epoch: 11 [11520/41964 (27%)]\tLoss: 0.163885\n",
      "Train Epoch: 11 [12160/41964 (29%)]\tLoss: 0.329557\n",
      "Train Epoch: 11 [12800/41964 (30%)]\tLoss: 0.142123\n",
      "Train Epoch: 11 [13440/41964 (32%)]\tLoss: 0.245499\n",
      "Train Epoch: 11 [14080/41964 (34%)]\tLoss: 0.195766\n",
      "Train Epoch: 11 [14720/41964 (35%)]\tLoss: 0.199708\n",
      "Train Epoch: 11 [15360/41964 (37%)]\tLoss: 0.088827\n",
      "Train Epoch: 11 [16000/41964 (38%)]\tLoss: 0.372504\n",
      "Train Epoch: 11 [16640/41964 (40%)]\tLoss: 0.200157\n",
      "Train Epoch: 11 [17280/41964 (41%)]\tLoss: 0.426150\n",
      "Train Epoch: 11 [17920/41964 (43%)]\tLoss: 0.232625\n",
      "Train Epoch: 11 [18560/41964 (44%)]\tLoss: 0.126327\n",
      "Train Epoch: 11 [19200/41964 (46%)]\tLoss: 0.355178\n",
      "Train Epoch: 11 [19840/41964 (47%)]\tLoss: 0.278230\n",
      "Train Epoch: 11 [20480/41964 (49%)]\tLoss: 0.201620\n",
      "Train Epoch: 11 [21120/41964 (50%)]\tLoss: 0.230594\n",
      "Train Epoch: 11 [21760/41964 (52%)]\tLoss: 0.320825\n",
      "Train Epoch: 11 [22400/41964 (53%)]\tLoss: 0.274671\n",
      "Train Epoch: 11 [23040/41964 (55%)]\tLoss: 0.129033\n",
      "Train Epoch: 11 [23680/41964 (56%)]\tLoss: 0.333136\n",
      "Train Epoch: 11 [24320/41964 (58%)]\tLoss: 0.088151\n",
      "Train Epoch: 11 [24960/41964 (59%)]\tLoss: 0.217277\n",
      "Train Epoch: 11 [25600/41964 (61%)]\tLoss: 0.112950\n",
      "Train Epoch: 11 [26240/41964 (62%)]\tLoss: 0.073826\n",
      "Train Epoch: 11 [26880/41964 (64%)]\tLoss: 0.248196\n",
      "Train Epoch: 11 [27520/41964 (66%)]\tLoss: 0.254572\n",
      "Train Epoch: 11 [28160/41964 (67%)]\tLoss: 0.295678\n",
      "Train Epoch: 11 [28800/41964 (69%)]\tLoss: 0.323517\n",
      "Train Epoch: 11 [29440/41964 (70%)]\tLoss: 0.211583\n",
      "Train Epoch: 11 [30080/41964 (72%)]\tLoss: 0.302246\n",
      "Train Epoch: 11 [30720/41964 (73%)]\tLoss: 0.342582\n",
      "Train Epoch: 11 [31360/41964 (75%)]\tLoss: 0.233129\n",
      "Train Epoch: 11 [32000/41964 (76%)]\tLoss: 0.200862\n",
      "Train Epoch: 11 [32640/41964 (78%)]\tLoss: 0.271150\n",
      "Train Epoch: 11 [33280/41964 (79%)]\tLoss: 0.199283\n",
      "Train Epoch: 11 [33920/41964 (81%)]\tLoss: 0.232784\n",
      "Train Epoch: 11 [34560/41964 (82%)]\tLoss: 0.216389\n",
      "Train Epoch: 11 [35200/41964 (84%)]\tLoss: 0.203526\n",
      "Train Epoch: 11 [35840/41964 (85%)]\tLoss: 0.226476\n",
      "Train Epoch: 11 [36480/41964 (87%)]\tLoss: 0.169875\n",
      "Train Epoch: 11 [37120/41964 (88%)]\tLoss: 0.239666\n",
      "Train Epoch: 11 [37760/41964 (90%)]\tLoss: 0.285007\n",
      "Train Epoch: 11 [38400/41964 (91%)]\tLoss: 0.108099\n",
      "Train Epoch: 11 [39040/41964 (93%)]\tLoss: 0.145950\n",
      "Train Epoch: 11 [39680/41964 (95%)]\tLoss: 0.269962\n",
      "Train Epoch: 11 [40320/41964 (96%)]\tLoss: 0.351050\n",
      "Train Epoch: 11 [40960/41964 (98%)]\tLoss: 0.196843\n",
      "Train Epoch: 11 [41600/41964 (99%)]\tLoss: 0.413245\n",
      "\n",
      "Test set: Avg. loss: 0.0678, Accuracy: 9791/10000 (97%)\n",
      "\n",
      "Train Epoch: 12 [0/41964 (0%)]\tLoss: 0.604845\n",
      "Train Epoch: 12 [640/41964 (2%)]\tLoss: 0.140697\n",
      "Train Epoch: 12 [1280/41964 (3%)]\tLoss: 0.123541\n",
      "Train Epoch: 12 [1920/41964 (5%)]\tLoss: 0.123086\n",
      "Train Epoch: 12 [2560/41964 (6%)]\tLoss: 0.135372\n",
      "Train Epoch: 12 [3200/41964 (8%)]\tLoss: 0.189562\n",
      "Train Epoch: 12 [3840/41964 (9%)]\tLoss: 0.123947\n",
      "Train Epoch: 12 [4480/41964 (11%)]\tLoss: 0.224517\n",
      "Train Epoch: 12 [5120/41964 (12%)]\tLoss: 0.360735\n",
      "Train Epoch: 12 [5760/41964 (14%)]\tLoss: 0.223301\n",
      "Train Epoch: 12 [6400/41964 (15%)]\tLoss: 0.203522\n",
      "Train Epoch: 12 [7040/41964 (17%)]\tLoss: 0.405569\n",
      "Train Epoch: 12 [7680/41964 (18%)]\tLoss: 0.381130\n",
      "Train Epoch: 12 [8320/41964 (20%)]\tLoss: 0.431678\n",
      "Train Epoch: 12 [8960/41964 (21%)]\tLoss: 0.181727\n",
      "Train Epoch: 12 [9600/41964 (23%)]\tLoss: 0.145169\n",
      "Train Epoch: 12 [10240/41964 (24%)]\tLoss: 0.082756\n",
      "Train Epoch: 12 [10880/41964 (26%)]\tLoss: 0.146576\n",
      "Train Epoch: 12 [11520/41964 (27%)]\tLoss: 0.368603\n",
      "Train Epoch: 12 [12160/41964 (29%)]\tLoss: 0.165618\n",
      "Train Epoch: 12 [12800/41964 (30%)]\tLoss: 0.205274\n",
      "Train Epoch: 12 [13440/41964 (32%)]\tLoss: 0.198852\n",
      "Train Epoch: 12 [14080/41964 (34%)]\tLoss: 0.256723\n",
      "Train Epoch: 12 [14720/41964 (35%)]\tLoss: 0.137566\n",
      "Train Epoch: 12 [15360/41964 (37%)]\tLoss: 0.448953\n",
      "Train Epoch: 12 [16000/41964 (38%)]\tLoss: 0.227025\n",
      "Train Epoch: 12 [16640/41964 (40%)]\tLoss: 0.222514\n",
      "Train Epoch: 12 [17280/41964 (41%)]\tLoss: 0.191127\n",
      "Train Epoch: 12 [17920/41964 (43%)]\tLoss: 0.191172\n",
      "Train Epoch: 12 [18560/41964 (44%)]\tLoss: 0.205442\n",
      "Train Epoch: 12 [19200/41964 (46%)]\tLoss: 0.199562\n",
      "Train Epoch: 12 [19840/41964 (47%)]\tLoss: 0.076001\n",
      "Train Epoch: 12 [20480/41964 (49%)]\tLoss: 0.172120\n",
      "Train Epoch: 12 [21120/41964 (50%)]\tLoss: 0.251811\n",
      "Train Epoch: 12 [21760/41964 (52%)]\tLoss: 0.215170\n",
      "Train Epoch: 12 [22400/41964 (53%)]\tLoss: 0.171150\n",
      "Train Epoch: 12 [23040/41964 (55%)]\tLoss: 0.153246\n",
      "Train Epoch: 12 [23680/41964 (56%)]\tLoss: 0.294876\n",
      "Train Epoch: 12 [24320/41964 (58%)]\tLoss: 0.218809\n",
      "Train Epoch: 12 [24960/41964 (59%)]\tLoss: 0.216574\n",
      "Train Epoch: 12 [25600/41964 (61%)]\tLoss: 0.214794\n",
      "Train Epoch: 12 [26240/41964 (62%)]\tLoss: 0.183620\n",
      "Train Epoch: 12 [26880/41964 (64%)]\tLoss: 0.497137\n",
      "Train Epoch: 12 [27520/41964 (66%)]\tLoss: 0.079489\n",
      "Train Epoch: 12 [28160/41964 (67%)]\tLoss: 0.209013\n",
      "Train Epoch: 12 [28800/41964 (69%)]\tLoss: 0.250137\n",
      "Train Epoch: 12 [29440/41964 (70%)]\tLoss: 0.252225\n",
      "Train Epoch: 12 [30080/41964 (72%)]\tLoss: 0.201803\n",
      "Train Epoch: 12 [30720/41964 (73%)]\tLoss: 0.147650\n",
      "Train Epoch: 12 [31360/41964 (75%)]\tLoss: 0.090230\n",
      "Train Epoch: 12 [32000/41964 (76%)]\tLoss: 0.165104\n",
      "Train Epoch: 12 [32640/41964 (78%)]\tLoss: 0.194217\n",
      "Train Epoch: 12 [33280/41964 (79%)]\tLoss: 0.177323\n",
      "Train Epoch: 12 [33920/41964 (81%)]\tLoss: 0.232240\n",
      "Train Epoch: 12 [34560/41964 (82%)]\tLoss: 0.317388\n",
      "Train Epoch: 12 [35200/41964 (84%)]\tLoss: 0.293184\n",
      "Train Epoch: 12 [35840/41964 (85%)]\tLoss: 0.144863\n",
      "Train Epoch: 12 [36480/41964 (87%)]\tLoss: 0.190607\n",
      "Train Epoch: 12 [37120/41964 (88%)]\tLoss: 0.180644\n",
      "Train Epoch: 12 [37760/41964 (90%)]\tLoss: 0.286042\n",
      "Train Epoch: 12 [38400/41964 (91%)]\tLoss: 0.176168\n",
      "Train Epoch: 12 [39040/41964 (93%)]\tLoss: 0.522292\n",
      "Train Epoch: 12 [39680/41964 (95%)]\tLoss: 0.138878\n",
      "Train Epoch: 12 [40320/41964 (96%)]\tLoss: 0.374122\n",
      "Train Epoch: 12 [40960/41964 (98%)]\tLoss: 0.298493\n",
      "Train Epoch: 12 [41600/41964 (99%)]\tLoss: 0.250932\n",
      "\n",
      "Test set: Avg. loss: 0.0646, Accuracy: 9801/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/41964 (0%)]\tLoss: 0.304586\n",
      "Train Epoch: 13 [640/41964 (2%)]\tLoss: 0.203476\n",
      "Train Epoch: 13 [1280/41964 (3%)]\tLoss: 0.085213\n",
      "Train Epoch: 13 [1920/41964 (5%)]\tLoss: 0.379797\n",
      "Train Epoch: 13 [2560/41964 (6%)]\tLoss: 0.291590\n",
      "Train Epoch: 13 [3200/41964 (8%)]\tLoss: 0.204012\n",
      "Train Epoch: 13 [3840/41964 (9%)]\tLoss: 0.164222\n",
      "Train Epoch: 13 [4480/41964 (11%)]\tLoss: 0.267110\n",
      "Train Epoch: 13 [5120/41964 (12%)]\tLoss: 0.237777\n",
      "Train Epoch: 13 [5760/41964 (14%)]\tLoss: 0.247237\n",
      "Train Epoch: 13 [6400/41964 (15%)]\tLoss: 0.189761\n",
      "Train Epoch: 13 [7040/41964 (17%)]\tLoss: 0.357392\n",
      "Train Epoch: 13 [7680/41964 (18%)]\tLoss: 0.348583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [8320/41964 (20%)]\tLoss: 0.172870\n",
      "Train Epoch: 13 [8960/41964 (21%)]\tLoss: 0.156747\n",
      "Train Epoch: 13 [9600/41964 (23%)]\tLoss: 0.344187\n",
      "Train Epoch: 13 [10240/41964 (24%)]\tLoss: 0.155724\n",
      "Train Epoch: 13 [10880/41964 (26%)]\tLoss: 0.106611\n",
      "Train Epoch: 13 [11520/41964 (27%)]\tLoss: 0.201126\n",
      "Train Epoch: 13 [12160/41964 (29%)]\tLoss: 0.132729\n",
      "Train Epoch: 13 [12800/41964 (30%)]\tLoss: 0.238697\n",
      "Train Epoch: 13 [13440/41964 (32%)]\tLoss: 0.370330\n",
      "Train Epoch: 13 [14080/41964 (34%)]\tLoss: 0.306336\n",
      "Train Epoch: 13 [14720/41964 (35%)]\tLoss: 0.266329\n",
      "Train Epoch: 13 [15360/41964 (37%)]\tLoss: 0.155820\n",
      "Train Epoch: 13 [16000/41964 (38%)]\tLoss: 0.186302\n",
      "Train Epoch: 13 [16640/41964 (40%)]\tLoss: 0.242960\n",
      "Train Epoch: 13 [17280/41964 (41%)]\tLoss: 0.448268\n",
      "Train Epoch: 13 [17920/41964 (43%)]\tLoss: 0.108449\n",
      "Train Epoch: 13 [18560/41964 (44%)]\tLoss: 0.204668\n",
      "Train Epoch: 13 [19200/41964 (46%)]\tLoss: 0.131398\n",
      "Train Epoch: 13 [19840/41964 (47%)]\tLoss: 0.311937\n",
      "Train Epoch: 13 [20480/41964 (49%)]\tLoss: 0.114613\n",
      "Train Epoch: 13 [21120/41964 (50%)]\tLoss: 0.217104\n",
      "Train Epoch: 13 [21760/41964 (52%)]\tLoss: 0.141841\n",
      "Train Epoch: 13 [22400/41964 (53%)]\tLoss: 0.314508\n",
      "Train Epoch: 13 [23040/41964 (55%)]\tLoss: 0.344091\n",
      "Train Epoch: 13 [23680/41964 (56%)]\tLoss: 0.412902\n",
      "Train Epoch: 13 [24320/41964 (58%)]\tLoss: 0.180748\n",
      "Train Epoch: 13 [24960/41964 (59%)]\tLoss: 0.146142\n",
      "Train Epoch: 13 [25600/41964 (61%)]\tLoss: 0.154265\n",
      "Train Epoch: 13 [26240/41964 (62%)]\tLoss: 0.189238\n",
      "Train Epoch: 13 [26880/41964 (64%)]\tLoss: 0.157110\n",
      "Train Epoch: 13 [27520/41964 (66%)]\tLoss: 0.084644\n",
      "Train Epoch: 13 [28160/41964 (67%)]\tLoss: 0.186473\n",
      "Train Epoch: 13 [28800/41964 (69%)]\tLoss: 0.130576\n",
      "Train Epoch: 13 [29440/41964 (70%)]\tLoss: 0.397121\n",
      "Train Epoch: 13 [30080/41964 (72%)]\tLoss: 0.371817\n",
      "Train Epoch: 13 [30720/41964 (73%)]\tLoss: 0.353262\n",
      "Train Epoch: 13 [31360/41964 (75%)]\tLoss: 0.140924\n",
      "Train Epoch: 13 [32000/41964 (76%)]\tLoss: 0.262815\n",
      "Train Epoch: 13 [32640/41964 (78%)]\tLoss: 0.114705\n",
      "Train Epoch: 13 [33280/41964 (79%)]\tLoss: 0.177835\n",
      "Train Epoch: 13 [33920/41964 (81%)]\tLoss: 0.386085\n",
      "Train Epoch: 13 [34560/41964 (82%)]\tLoss: 0.209937\n",
      "Train Epoch: 13 [35200/41964 (84%)]\tLoss: 0.523522\n",
      "Train Epoch: 13 [35840/41964 (85%)]\tLoss: 0.463760\n",
      "Train Epoch: 13 [36480/41964 (87%)]\tLoss: 0.314413\n",
      "Train Epoch: 13 [37120/41964 (88%)]\tLoss: 0.115101\n",
      "Train Epoch: 13 [37760/41964 (90%)]\tLoss: 0.180886\n",
      "Train Epoch: 13 [38400/41964 (91%)]\tLoss: 0.176590\n",
      "Train Epoch: 13 [39040/41964 (93%)]\tLoss: 0.187672\n",
      "Train Epoch: 13 [39680/41964 (95%)]\tLoss: 0.168830\n",
      "Train Epoch: 13 [40320/41964 (96%)]\tLoss: 0.177708\n",
      "Train Epoch: 13 [40960/41964 (98%)]\tLoss: 0.218048\n",
      "Train Epoch: 13 [41600/41964 (99%)]\tLoss: 0.108157\n",
      "\n",
      "Test set: Avg. loss: 0.0635, Accuracy: 9803/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/41964 (0%)]\tLoss: 0.210242\n",
      "Train Epoch: 14 [640/41964 (2%)]\tLoss: 0.280726\n",
      "Train Epoch: 14 [1280/41964 (3%)]\tLoss: 0.085166\n",
      "Train Epoch: 14 [1920/41964 (5%)]\tLoss: 0.272170\n",
      "Train Epoch: 14 [2560/41964 (6%)]\tLoss: 0.237801\n",
      "Train Epoch: 14 [3200/41964 (8%)]\tLoss: 0.146867\n",
      "Train Epoch: 14 [3840/41964 (9%)]\tLoss: 0.305428\n",
      "Train Epoch: 14 [4480/41964 (11%)]\tLoss: 0.100590\n",
      "Train Epoch: 14 [5120/41964 (12%)]\tLoss: 0.110175\n",
      "Train Epoch: 14 [5760/41964 (14%)]\tLoss: 0.102920\n",
      "Train Epoch: 14 [6400/41964 (15%)]\tLoss: 0.062734\n",
      "Train Epoch: 14 [7040/41964 (17%)]\tLoss: 0.113608\n",
      "Train Epoch: 14 [7680/41964 (18%)]\tLoss: 0.263427\n",
      "Train Epoch: 14 [8320/41964 (20%)]\tLoss: 0.068106\n",
      "Train Epoch: 14 [8960/41964 (21%)]\tLoss: 0.080719\n",
      "Train Epoch: 14 [9600/41964 (23%)]\tLoss: 0.267570\n",
      "Train Epoch: 14 [10240/41964 (24%)]\tLoss: 0.071024\n",
      "Train Epoch: 14 [10880/41964 (26%)]\tLoss: 0.212252\n",
      "Train Epoch: 14 [11520/41964 (27%)]\tLoss: 0.263556\n",
      "Train Epoch: 14 [12160/41964 (29%)]\tLoss: 0.142419\n",
      "Train Epoch: 14 [12800/41964 (30%)]\tLoss: 0.278483\n",
      "Train Epoch: 14 [13440/41964 (32%)]\tLoss: 0.094427\n",
      "Train Epoch: 14 [14080/41964 (34%)]\tLoss: 0.131913\n",
      "Train Epoch: 14 [14720/41964 (35%)]\tLoss: 0.169196\n",
      "Train Epoch: 14 [15360/41964 (37%)]\tLoss: 0.200686\n",
      "Train Epoch: 14 [16000/41964 (38%)]\tLoss: 0.206492\n",
      "Train Epoch: 14 [16640/41964 (40%)]\tLoss: 0.362287\n",
      "Train Epoch: 14 [17280/41964 (41%)]\tLoss: 0.305217\n",
      "Train Epoch: 14 [17920/41964 (43%)]\tLoss: 0.092162\n",
      "Train Epoch: 14 [18560/41964 (44%)]\tLoss: 0.249574\n",
      "Train Epoch: 14 [19200/41964 (46%)]\tLoss: 0.241081\n",
      "Train Epoch: 14 [19840/41964 (47%)]\tLoss: 0.241636\n",
      "Train Epoch: 14 [20480/41964 (49%)]\tLoss: 0.172702\n",
      "Train Epoch: 14 [21120/41964 (50%)]\tLoss: 0.145731\n",
      "Train Epoch: 14 [21760/41964 (52%)]\tLoss: 0.220424\n",
      "Train Epoch: 14 [22400/41964 (53%)]\tLoss: 0.148619\n",
      "Train Epoch: 14 [23040/41964 (55%)]\tLoss: 0.095576\n",
      "Train Epoch: 14 [23680/41964 (56%)]\tLoss: 0.265917\n",
      "Train Epoch: 14 [24320/41964 (58%)]\tLoss: 0.286322\n",
      "Train Epoch: 14 [24960/41964 (59%)]\tLoss: 0.110226\n",
      "Train Epoch: 14 [25600/41964 (61%)]\tLoss: 0.116645\n",
      "Train Epoch: 14 [26240/41964 (62%)]\tLoss: 0.162958\n",
      "Train Epoch: 14 [26880/41964 (64%)]\tLoss: 0.190597\n",
      "Train Epoch: 14 [27520/41964 (66%)]\tLoss: 0.092111\n",
      "Train Epoch: 14 [28160/41964 (67%)]\tLoss: 0.183373\n",
      "Train Epoch: 14 [28800/41964 (69%)]\tLoss: 0.170959\n",
      "Train Epoch: 14 [29440/41964 (70%)]\tLoss: 0.327884\n",
      "Train Epoch: 14 [30080/41964 (72%)]\tLoss: 0.366678\n",
      "Train Epoch: 14 [30720/41964 (73%)]\tLoss: 0.115654\n",
      "Train Epoch: 14 [31360/41964 (75%)]\tLoss: 0.278175\n",
      "Train Epoch: 14 [32000/41964 (76%)]\tLoss: 0.151347\n",
      "Train Epoch: 14 [32640/41964 (78%)]\tLoss: 0.112417\n",
      "Train Epoch: 14 [33280/41964 (79%)]\tLoss: 0.232348\n",
      "Train Epoch: 14 [33920/41964 (81%)]\tLoss: 0.541267\n",
      "Train Epoch: 14 [34560/41964 (82%)]\tLoss: 0.225284\n",
      "Train Epoch: 14 [35200/41964 (84%)]\tLoss: 0.125645\n",
      "Train Epoch: 14 [35840/41964 (85%)]\tLoss: 0.229921\n",
      "Train Epoch: 14 [36480/41964 (87%)]\tLoss: 0.202402\n",
      "Train Epoch: 14 [37120/41964 (88%)]\tLoss: 0.154816\n",
      "Train Epoch: 14 [37760/41964 (90%)]\tLoss: 0.200175\n",
      "Train Epoch: 14 [38400/41964 (91%)]\tLoss: 0.296140\n",
      "Train Epoch: 14 [39040/41964 (93%)]\tLoss: 0.381233\n",
      "Train Epoch: 14 [39680/41964 (95%)]\tLoss: 0.300781\n",
      "Train Epoch: 14 [40320/41964 (96%)]\tLoss: 0.338696\n",
      "Train Epoch: 14 [40960/41964 (98%)]\tLoss: 0.350343\n",
      "Train Epoch: 14 [41600/41964 (99%)]\tLoss: 0.178156\n",
      "\n",
      "Test set: Avg. loss: 0.0607, Accuracy: 9814/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/41964 (0%)]\tLoss: 0.150457\n",
      "Train Epoch: 15 [640/41964 (2%)]\tLoss: 0.292124\n",
      "Train Epoch: 15 [1280/41964 (3%)]\tLoss: 0.131840\n",
      "Train Epoch: 15 [1920/41964 (5%)]\tLoss: 0.168464\n",
      "Train Epoch: 15 [2560/41964 (6%)]\tLoss: 0.263477\n",
      "Train Epoch: 15 [3200/41964 (8%)]\tLoss: 0.264119\n",
      "Train Epoch: 15 [3840/41964 (9%)]\tLoss: 0.187646\n",
      "Train Epoch: 15 [4480/41964 (11%)]\tLoss: 0.080889\n",
      "Train Epoch: 15 [5120/41964 (12%)]\tLoss: 0.223098\n",
      "Train Epoch: 15 [5760/41964 (14%)]\tLoss: 0.205525\n",
      "Train Epoch: 15 [6400/41964 (15%)]\tLoss: 0.138870\n",
      "Train Epoch: 15 [7040/41964 (17%)]\tLoss: 0.116198\n",
      "Train Epoch: 15 [7680/41964 (18%)]\tLoss: 0.113895\n",
      "Train Epoch: 15 [8320/41964 (20%)]\tLoss: 0.177086\n",
      "Train Epoch: 15 [8960/41964 (21%)]\tLoss: 0.285804\n",
      "Train Epoch: 15 [9600/41964 (23%)]\tLoss: 0.150277\n",
      "Train Epoch: 15 [10240/41964 (24%)]\tLoss: 0.201456\n",
      "Train Epoch: 15 [10880/41964 (26%)]\tLoss: 0.158664\n",
      "Train Epoch: 15 [11520/41964 (27%)]\tLoss: 0.368488\n",
      "Train Epoch: 15 [12160/41964 (29%)]\tLoss: 0.216001\n",
      "Train Epoch: 15 [12800/41964 (30%)]\tLoss: 0.161329\n",
      "Train Epoch: 15 [13440/41964 (32%)]\tLoss: 0.293298\n",
      "Train Epoch: 15 [14080/41964 (34%)]\tLoss: 0.297312\n",
      "Train Epoch: 15 [14720/41964 (35%)]\tLoss: 0.141988\n",
      "Train Epoch: 15 [15360/41964 (37%)]\tLoss: 0.220946\n",
      "Train Epoch: 15 [16000/41964 (38%)]\tLoss: 0.495006\n",
      "Train Epoch: 15 [16640/41964 (40%)]\tLoss: 0.185051\n",
      "Train Epoch: 15 [17280/41964 (41%)]\tLoss: 0.455756\n",
      "Train Epoch: 15 [17920/41964 (43%)]\tLoss: 0.329742\n",
      "Train Epoch: 15 [18560/41964 (44%)]\tLoss: 0.457443\n",
      "Train Epoch: 15 [19200/41964 (46%)]\tLoss: 0.273410\n",
      "Train Epoch: 15 [19840/41964 (47%)]\tLoss: 0.174352\n",
      "Train Epoch: 15 [20480/41964 (49%)]\tLoss: 0.232309\n",
      "Train Epoch: 15 [21120/41964 (50%)]\tLoss: 0.111324\n",
      "Train Epoch: 15 [21760/41964 (52%)]\tLoss: 0.171496\n",
      "Train Epoch: 15 [22400/41964 (53%)]\tLoss: 0.324387\n",
      "Train Epoch: 15 [23040/41964 (55%)]\tLoss: 0.283756\n",
      "Train Epoch: 15 [23680/41964 (56%)]\tLoss: 0.164742\n",
      "Train Epoch: 15 [24320/41964 (58%)]\tLoss: 0.399407\n",
      "Train Epoch: 15 [24960/41964 (59%)]\tLoss: 0.224132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [25600/41964 (61%)]\tLoss: 0.077132\n",
      "Train Epoch: 15 [26240/41964 (62%)]\tLoss: 0.290858\n",
      "Train Epoch: 15 [26880/41964 (64%)]\tLoss: 0.156550\n",
      "Train Epoch: 15 [27520/41964 (66%)]\tLoss: 0.217701\n",
      "Train Epoch: 15 [28160/41964 (67%)]\tLoss: 0.137225\n",
      "Train Epoch: 15 [28800/41964 (69%)]\tLoss: 0.388660\n",
      "Train Epoch: 15 [29440/41964 (70%)]\tLoss: 0.197750\n",
      "Train Epoch: 15 [30080/41964 (72%)]\tLoss: 0.382512\n",
      "Train Epoch: 15 [30720/41964 (73%)]\tLoss: 0.058871\n",
      "Train Epoch: 15 [31360/41964 (75%)]\tLoss: 0.304551\n",
      "Train Epoch: 15 [32000/41964 (76%)]\tLoss: 0.286268\n",
      "Train Epoch: 15 [32640/41964 (78%)]\tLoss: 0.377875\n",
      "Train Epoch: 15 [33280/41964 (79%)]\tLoss: 0.149874\n",
      "Train Epoch: 15 [33920/41964 (81%)]\tLoss: 0.293274\n",
      "Train Epoch: 15 [34560/41964 (82%)]\tLoss: 0.177095\n",
      "Train Epoch: 15 [35200/41964 (84%)]\tLoss: 0.159617\n",
      "Train Epoch: 15 [35840/41964 (85%)]\tLoss: 0.179791\n",
      "Train Epoch: 15 [36480/41964 (87%)]\tLoss: 0.263543\n",
      "Train Epoch: 15 [37120/41964 (88%)]\tLoss: 0.244834\n",
      "Train Epoch: 15 [37760/41964 (90%)]\tLoss: 0.141328\n",
      "Train Epoch: 15 [38400/41964 (91%)]\tLoss: 0.243904\n",
      "Train Epoch: 15 [39040/41964 (93%)]\tLoss: 0.228082\n",
      "Train Epoch: 15 [39680/41964 (95%)]\tLoss: 0.202902\n",
      "Train Epoch: 15 [40320/41964 (96%)]\tLoss: 0.161389\n",
      "Train Epoch: 15 [40960/41964 (98%)]\tLoss: 0.355684\n",
      "Train Epoch: 15 [41600/41964 (99%)]\tLoss: 0.186964\n",
      "\n",
      "Test set: Avg. loss: 0.0627, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/41964 (0%)]\tLoss: 0.120773\n",
      "Train Epoch: 16 [640/41964 (2%)]\tLoss: 0.264861\n",
      "Train Epoch: 16 [1280/41964 (3%)]\tLoss: 0.127176\n",
      "Train Epoch: 16 [1920/41964 (5%)]\tLoss: 0.230772\n",
      "Train Epoch: 16 [2560/41964 (6%)]\tLoss: 0.220594\n",
      "Train Epoch: 16 [3200/41964 (8%)]\tLoss: 0.122756\n",
      "Train Epoch: 16 [3840/41964 (9%)]\tLoss: 0.075438\n",
      "Train Epoch: 16 [4480/41964 (11%)]\tLoss: 0.134026\n",
      "Train Epoch: 16 [5120/41964 (12%)]\tLoss: 0.158662\n",
      "Train Epoch: 16 [5760/41964 (14%)]\tLoss: 0.166461\n",
      "Train Epoch: 16 [6400/41964 (15%)]\tLoss: 0.165803\n",
      "Train Epoch: 16 [7040/41964 (17%)]\tLoss: 0.165013\n",
      "Train Epoch: 16 [7680/41964 (18%)]\tLoss: 0.092793\n",
      "Train Epoch: 16 [8320/41964 (20%)]\tLoss: 0.181961\n",
      "Train Epoch: 16 [8960/41964 (21%)]\tLoss: 0.339312\n",
      "Train Epoch: 16 [9600/41964 (23%)]\tLoss: 0.306130\n",
      "Train Epoch: 16 [10240/41964 (24%)]\tLoss: 0.212232\n",
      "Train Epoch: 16 [10880/41964 (26%)]\tLoss: 0.287942\n",
      "Train Epoch: 16 [11520/41964 (27%)]\tLoss: 0.112109\n",
      "Train Epoch: 16 [12160/41964 (29%)]\tLoss: 0.210703\n",
      "Train Epoch: 16 [12800/41964 (30%)]\tLoss: 0.139954\n",
      "Train Epoch: 16 [13440/41964 (32%)]\tLoss: 0.183299\n",
      "Train Epoch: 16 [14080/41964 (34%)]\tLoss: 0.096659\n",
      "Train Epoch: 16 [14720/41964 (35%)]\tLoss: 0.212458\n",
      "Train Epoch: 16 [15360/41964 (37%)]\tLoss: 0.297958\n",
      "Train Epoch: 16 [16000/41964 (38%)]\tLoss: 0.281462\n",
      "Train Epoch: 16 [16640/41964 (40%)]\tLoss: 0.116265\n",
      "Train Epoch: 16 [17280/41964 (41%)]\tLoss: 0.148480\n",
      "Train Epoch: 16 [17920/41964 (43%)]\tLoss: 0.175131\n",
      "Train Epoch: 16 [18560/41964 (44%)]\tLoss: 0.190471\n",
      "Train Epoch: 16 [19200/41964 (46%)]\tLoss: 0.197774\n",
      "Train Epoch: 16 [19840/41964 (47%)]\tLoss: 0.195715\n",
      "Train Epoch: 16 [20480/41964 (49%)]\tLoss: 0.118817\n",
      "Train Epoch: 16 [21120/41964 (50%)]\tLoss: 0.372819\n",
      "Train Epoch: 16 [21760/41964 (52%)]\tLoss: 0.138981\n",
      "Train Epoch: 16 [22400/41964 (53%)]\tLoss: 0.186779\n",
      "Train Epoch: 16 [23040/41964 (55%)]\tLoss: 0.136675\n",
      "Train Epoch: 16 [23680/41964 (56%)]\tLoss: 0.312188\n",
      "Train Epoch: 16 [24320/41964 (58%)]\tLoss: 0.078787\n",
      "Train Epoch: 16 [24960/41964 (59%)]\tLoss: 0.214017\n",
      "Train Epoch: 16 [25600/41964 (61%)]\tLoss: 0.032284\n",
      "Train Epoch: 16 [26240/41964 (62%)]\tLoss: 0.105039\n",
      "Train Epoch: 16 [26880/41964 (64%)]\tLoss: 0.153242\n",
      "Train Epoch: 16 [27520/41964 (66%)]\tLoss: 0.435714\n",
      "Train Epoch: 16 [28160/41964 (67%)]\tLoss: 0.216378\n",
      "Train Epoch: 16 [28800/41964 (69%)]\tLoss: 0.185645\n",
      "Train Epoch: 16 [29440/41964 (70%)]\tLoss: 0.153033\n",
      "Train Epoch: 16 [30080/41964 (72%)]\tLoss: 0.160328\n",
      "Train Epoch: 16 [30720/41964 (73%)]\tLoss: 0.213642\n",
      "Train Epoch: 16 [31360/41964 (75%)]\tLoss: 0.159231\n",
      "Train Epoch: 16 [32000/41964 (76%)]\tLoss: 0.257934\n",
      "Train Epoch: 16 [32640/41964 (78%)]\tLoss: 0.147653\n",
      "Train Epoch: 16 [33280/41964 (79%)]\tLoss: 0.270265\n",
      "Train Epoch: 16 [33920/41964 (81%)]\tLoss: 0.215844\n",
      "Train Epoch: 16 [34560/41964 (82%)]\tLoss: 0.099157\n",
      "Train Epoch: 16 [35200/41964 (84%)]\tLoss: 0.173316\n",
      "Train Epoch: 16 [35840/41964 (85%)]\tLoss: 0.225330\n",
      "Train Epoch: 16 [36480/41964 (87%)]\tLoss: 0.323888\n",
      "Train Epoch: 16 [37120/41964 (88%)]\tLoss: 0.175023\n",
      "Train Epoch: 16 [37760/41964 (90%)]\tLoss: 0.350161\n",
      "Train Epoch: 16 [38400/41964 (91%)]\tLoss: 0.153468\n",
      "Train Epoch: 16 [39040/41964 (93%)]\tLoss: 0.163868\n",
      "Train Epoch: 16 [39680/41964 (95%)]\tLoss: 0.145976\n",
      "Train Epoch: 16 [40320/41964 (96%)]\tLoss: 0.135855\n",
      "Train Epoch: 16 [40960/41964 (98%)]\tLoss: 0.177112\n",
      "Train Epoch: 16 [41600/41964 (99%)]\tLoss: 0.205455\n",
      "\n",
      "Test set: Avg. loss: 0.0569, Accuracy: 9824/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/41964 (0%)]\tLoss: 0.126806\n",
      "Train Epoch: 17 [640/41964 (2%)]\tLoss: 0.204167\n",
      "Train Epoch: 17 [1280/41964 (3%)]\tLoss: 0.239877\n",
      "Train Epoch: 17 [1920/41964 (5%)]\tLoss: 0.266550\n",
      "Train Epoch: 17 [2560/41964 (6%)]\tLoss: 0.192868\n",
      "Train Epoch: 17 [3200/41964 (8%)]\tLoss: 0.221630\n",
      "Train Epoch: 17 [3840/41964 (9%)]\tLoss: 0.212427\n",
      "Train Epoch: 17 [4480/41964 (11%)]\tLoss: 0.156927\n",
      "Train Epoch: 17 [5120/41964 (12%)]\tLoss: 0.147934\n",
      "Train Epoch: 17 [5760/41964 (14%)]\tLoss: 0.239687\n",
      "Train Epoch: 17 [6400/41964 (15%)]\tLoss: 0.140646\n",
      "Train Epoch: 17 [7040/41964 (17%)]\tLoss: 0.252741\n",
      "Train Epoch: 17 [7680/41964 (18%)]\tLoss: 0.162878\n",
      "Train Epoch: 17 [8320/41964 (20%)]\tLoss: 0.244597\n",
      "Train Epoch: 17 [8960/41964 (21%)]\tLoss: 0.204524\n",
      "Train Epoch: 17 [9600/41964 (23%)]\tLoss: 0.241563\n",
      "Train Epoch: 17 [10240/41964 (24%)]\tLoss: 0.106707\n",
      "Train Epoch: 17 [10880/41964 (26%)]\tLoss: 0.281489\n",
      "Train Epoch: 17 [11520/41964 (27%)]\tLoss: 0.162738\n",
      "Train Epoch: 17 [12160/41964 (29%)]\tLoss: 0.277849\n",
      "Train Epoch: 17 [12800/41964 (30%)]\tLoss: 0.229725\n",
      "Train Epoch: 17 [13440/41964 (32%)]\tLoss: 0.279336\n",
      "Train Epoch: 17 [14080/41964 (34%)]\tLoss: 0.146182\n",
      "Train Epoch: 17 [14720/41964 (35%)]\tLoss: 0.191142\n",
      "Train Epoch: 17 [15360/41964 (37%)]\tLoss: 0.237937\n",
      "Train Epoch: 17 [16000/41964 (38%)]\tLoss: 0.278494\n",
      "Train Epoch: 17 [16640/41964 (40%)]\tLoss: 0.081376\n",
      "Train Epoch: 17 [17280/41964 (41%)]\tLoss: 0.396309\n",
      "Train Epoch: 17 [17920/41964 (43%)]\tLoss: 0.106004\n",
      "Train Epoch: 17 [18560/41964 (44%)]\tLoss: 0.087811\n",
      "Train Epoch: 17 [19200/41964 (46%)]\tLoss: 0.143406\n",
      "Train Epoch: 17 [19840/41964 (47%)]\tLoss: 0.343268\n",
      "Train Epoch: 17 [20480/41964 (49%)]\tLoss: 0.268926\n",
      "Train Epoch: 17 [21120/41964 (50%)]\tLoss: 0.322467\n",
      "Train Epoch: 17 [21760/41964 (52%)]\tLoss: 0.269151\n",
      "Train Epoch: 17 [22400/41964 (53%)]\tLoss: 0.152641\n",
      "Train Epoch: 17 [23040/41964 (55%)]\tLoss: 0.214440\n",
      "Train Epoch: 17 [23680/41964 (56%)]\tLoss: 0.165074\n",
      "Train Epoch: 17 [24320/41964 (58%)]\tLoss: 0.140936\n",
      "Train Epoch: 17 [24960/41964 (59%)]\tLoss: 0.184190\n",
      "Train Epoch: 17 [25600/41964 (61%)]\tLoss: 0.173745\n",
      "Train Epoch: 17 [26240/41964 (62%)]\tLoss: 0.097087\n",
      "Train Epoch: 17 [26880/41964 (64%)]\tLoss: 0.199649\n",
      "Train Epoch: 17 [27520/41964 (66%)]\tLoss: 0.182451\n",
      "Train Epoch: 17 [28160/41964 (67%)]\tLoss: 0.081734\n",
      "Train Epoch: 17 [28800/41964 (69%)]\tLoss: 0.216015\n",
      "Train Epoch: 17 [29440/41964 (70%)]\tLoss: 0.386607\n",
      "Train Epoch: 17 [30080/41964 (72%)]\tLoss: 0.351568\n",
      "Train Epoch: 17 [30720/41964 (73%)]\tLoss: 0.152586\n",
      "Train Epoch: 17 [31360/41964 (75%)]\tLoss: 0.087781\n",
      "Train Epoch: 17 [32000/41964 (76%)]\tLoss: 0.232776\n",
      "Train Epoch: 17 [32640/41964 (78%)]\tLoss: 0.194948\n",
      "Train Epoch: 17 [33280/41964 (79%)]\tLoss: 0.165987\n",
      "Train Epoch: 17 [33920/41964 (81%)]\tLoss: 0.339891\n",
      "Train Epoch: 17 [34560/41964 (82%)]\tLoss: 0.244610\n",
      "Train Epoch: 17 [35200/41964 (84%)]\tLoss: 0.223220\n",
      "Train Epoch: 17 [35840/41964 (85%)]\tLoss: 0.188031\n",
      "Train Epoch: 17 [36480/41964 (87%)]\tLoss: 0.106629\n",
      "Train Epoch: 17 [37120/41964 (88%)]\tLoss: 0.215955\n",
      "Train Epoch: 17 [37760/41964 (90%)]\tLoss: 0.172843\n",
      "Train Epoch: 17 [38400/41964 (91%)]\tLoss: 0.127252\n",
      "Train Epoch: 17 [39040/41964 (93%)]\tLoss: 0.165798\n",
      "Train Epoch: 17 [39680/41964 (95%)]\tLoss: 0.133173\n",
      "Train Epoch: 17 [40320/41964 (96%)]\tLoss: 0.171687\n",
      "Train Epoch: 17 [40960/41964 (98%)]\tLoss: 0.440130\n",
      "Train Epoch: 17 [41600/41964 (99%)]\tLoss: 0.290036\n",
      "\n",
      "Test set: Avg. loss: 0.0580, Accuracy: 9814/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [0/41964 (0%)]\tLoss: 0.238729\n",
      "Train Epoch: 18 [640/41964 (2%)]\tLoss: 0.133963\n",
      "Train Epoch: 18 [1280/41964 (3%)]\tLoss: 0.078140\n",
      "Train Epoch: 18 [1920/41964 (5%)]\tLoss: 0.267953\n",
      "Train Epoch: 18 [2560/41964 (6%)]\tLoss: 0.124366\n",
      "Train Epoch: 18 [3200/41964 (8%)]\tLoss: 0.103496\n",
      "Train Epoch: 18 [3840/41964 (9%)]\tLoss: 0.160060\n",
      "Train Epoch: 18 [4480/41964 (11%)]\tLoss: 0.165553\n",
      "Train Epoch: 18 [5120/41964 (12%)]\tLoss: 0.370803\n",
      "Train Epoch: 18 [5760/41964 (14%)]\tLoss: 0.150300\n",
      "Train Epoch: 18 [6400/41964 (15%)]\tLoss: 0.234845\n",
      "Train Epoch: 18 [7040/41964 (17%)]\tLoss: 0.224151\n",
      "Train Epoch: 18 [7680/41964 (18%)]\tLoss: 0.198001\n",
      "Train Epoch: 18 [8320/41964 (20%)]\tLoss: 0.184356\n",
      "Train Epoch: 18 [8960/41964 (21%)]\tLoss: 0.106399\n",
      "Train Epoch: 18 [9600/41964 (23%)]\tLoss: 0.106918\n",
      "Train Epoch: 18 [10240/41964 (24%)]\tLoss: 0.181243\n",
      "Train Epoch: 18 [10880/41964 (26%)]\tLoss: 0.100459\n",
      "Train Epoch: 18 [11520/41964 (27%)]\tLoss: 0.130611\n",
      "Train Epoch: 18 [12160/41964 (29%)]\tLoss: 0.234366\n",
      "Train Epoch: 18 [12800/41964 (30%)]\tLoss: 0.088368\n",
      "Train Epoch: 18 [13440/41964 (32%)]\tLoss: 0.253113\n",
      "Train Epoch: 18 [14080/41964 (34%)]\tLoss: 0.060383\n",
      "Train Epoch: 18 [14720/41964 (35%)]\tLoss: 0.185458\n",
      "Train Epoch: 18 [15360/41964 (37%)]\tLoss: 0.123810\n",
      "Train Epoch: 18 [16000/41964 (38%)]\tLoss: 0.081172\n",
      "Train Epoch: 18 [16640/41964 (40%)]\tLoss: 0.110813\n",
      "Train Epoch: 18 [17280/41964 (41%)]\tLoss: 0.116075\n",
      "Train Epoch: 18 [17920/41964 (43%)]\tLoss: 0.301438\n",
      "Train Epoch: 18 [18560/41964 (44%)]\tLoss: 0.075446\n",
      "Train Epoch: 18 [19200/41964 (46%)]\tLoss: 0.222890\n",
      "Train Epoch: 18 [19840/41964 (47%)]\tLoss: 0.189224\n",
      "Train Epoch: 18 [20480/41964 (49%)]\tLoss: 0.289380\n",
      "Train Epoch: 18 [21120/41964 (50%)]\tLoss: 0.215543\n",
      "Train Epoch: 18 [21760/41964 (52%)]\tLoss: 0.118097\n",
      "Train Epoch: 18 [22400/41964 (53%)]\tLoss: 0.156379\n",
      "Train Epoch: 18 [23040/41964 (55%)]\tLoss: 0.303109\n",
      "Train Epoch: 18 [23680/41964 (56%)]\tLoss: 0.135958\n",
      "Train Epoch: 18 [24320/41964 (58%)]\tLoss: 0.100157\n",
      "Train Epoch: 18 [24960/41964 (59%)]\tLoss: 0.051884\n",
      "Train Epoch: 18 [25600/41964 (61%)]\tLoss: 0.224248\n",
      "Train Epoch: 18 [26240/41964 (62%)]\tLoss: 0.168984\n",
      "Train Epoch: 18 [26880/41964 (64%)]\tLoss: 0.082869\n",
      "Train Epoch: 18 [27520/41964 (66%)]\tLoss: 0.199856\n",
      "Train Epoch: 18 [28160/41964 (67%)]\tLoss: 0.116725\n",
      "Train Epoch: 18 [28800/41964 (69%)]\tLoss: 0.119461\n",
      "Train Epoch: 18 [29440/41964 (70%)]\tLoss: 0.161240\n",
      "Train Epoch: 18 [30080/41964 (72%)]\tLoss: 0.079188\n",
      "Train Epoch: 18 [30720/41964 (73%)]\tLoss: 0.271003\n",
      "Train Epoch: 18 [31360/41964 (75%)]\tLoss: 0.221220\n",
      "Train Epoch: 18 [32000/41964 (76%)]\tLoss: 0.090894\n",
      "Train Epoch: 18 [32640/41964 (78%)]\tLoss: 0.246497\n",
      "Train Epoch: 18 [33280/41964 (79%)]\tLoss: 0.156079\n",
      "Train Epoch: 18 [33920/41964 (81%)]\tLoss: 0.142115\n",
      "Train Epoch: 18 [34560/41964 (82%)]\tLoss: 0.077251\n",
      "Train Epoch: 18 [35200/41964 (84%)]\tLoss: 0.190666\n",
      "Train Epoch: 18 [35840/41964 (85%)]\tLoss: 0.162060\n",
      "Train Epoch: 18 [36480/41964 (87%)]\tLoss: 0.131893\n",
      "Train Epoch: 18 [37120/41964 (88%)]\tLoss: 0.294679\n",
      "Train Epoch: 18 [37760/41964 (90%)]\tLoss: 0.219122\n",
      "Train Epoch: 18 [38400/41964 (91%)]\tLoss: 0.177783\n",
      "Train Epoch: 18 [39040/41964 (93%)]\tLoss: 0.074442\n",
      "Train Epoch: 18 [39680/41964 (95%)]\tLoss: 0.126715\n",
      "Train Epoch: 18 [40320/41964 (96%)]\tLoss: 0.298420\n",
      "Train Epoch: 18 [40960/41964 (98%)]\tLoss: 0.155038\n",
      "Train Epoch: 18 [41600/41964 (99%)]\tLoss: 0.204171\n",
      "\n",
      "Test set: Avg. loss: 0.0530, Accuracy: 9833/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/41964 (0%)]\tLoss: 0.107915\n",
      "Train Epoch: 19 [640/41964 (2%)]\tLoss: 0.093598\n",
      "Train Epoch: 19 [1280/41964 (3%)]\tLoss: 0.231858\n",
      "Train Epoch: 19 [1920/41964 (5%)]\tLoss: 0.231661\n",
      "Train Epoch: 19 [2560/41964 (6%)]\tLoss: 0.177045\n",
      "Train Epoch: 19 [3200/41964 (8%)]\tLoss: 0.182748\n",
      "Train Epoch: 19 [3840/41964 (9%)]\tLoss: 0.247457\n",
      "Train Epoch: 19 [4480/41964 (11%)]\tLoss: 0.337925\n",
      "Train Epoch: 19 [5120/41964 (12%)]\tLoss: 0.176311\n",
      "Train Epoch: 19 [5760/41964 (14%)]\tLoss: 0.224365\n",
      "Train Epoch: 19 [6400/41964 (15%)]\tLoss: 0.233730\n",
      "Train Epoch: 19 [7040/41964 (17%)]\tLoss: 0.233647\n",
      "Train Epoch: 19 [7680/41964 (18%)]\tLoss: 0.172603\n",
      "Train Epoch: 19 [8320/41964 (20%)]\tLoss: 0.104805\n",
      "Train Epoch: 19 [8960/41964 (21%)]\tLoss: 0.223457\n",
      "Train Epoch: 19 [9600/41964 (23%)]\tLoss: 0.229577\n",
      "Train Epoch: 19 [10240/41964 (24%)]\tLoss: 0.290149\n",
      "Train Epoch: 19 [10880/41964 (26%)]\tLoss: 0.186558\n",
      "Train Epoch: 19 [11520/41964 (27%)]\tLoss: 0.120982\n",
      "Train Epoch: 19 [12160/41964 (29%)]\tLoss: 0.186368\n",
      "Train Epoch: 19 [12800/41964 (30%)]\tLoss: 0.138881\n",
      "Train Epoch: 19 [13440/41964 (32%)]\tLoss: 0.301518\n",
      "Train Epoch: 19 [14080/41964 (34%)]\tLoss: 0.225857\n",
      "Train Epoch: 19 [14720/41964 (35%)]\tLoss: 0.199520\n",
      "Train Epoch: 19 [15360/41964 (37%)]\tLoss: 0.128103\n",
      "Train Epoch: 19 [16000/41964 (38%)]\tLoss: 0.206765\n",
      "Train Epoch: 19 [16640/41964 (40%)]\tLoss: 0.259223\n",
      "Train Epoch: 19 [17280/41964 (41%)]\tLoss: 0.120418\n",
      "Train Epoch: 19 [17920/41964 (43%)]\tLoss: 0.229078\n",
      "Train Epoch: 19 [18560/41964 (44%)]\tLoss: 0.177968\n",
      "Train Epoch: 19 [19200/41964 (46%)]\tLoss: 0.109703\n",
      "Train Epoch: 19 [19840/41964 (47%)]\tLoss: 0.150529\n",
      "Train Epoch: 19 [20480/41964 (49%)]\tLoss: 0.229945\n",
      "Train Epoch: 19 [21120/41964 (50%)]\tLoss: 0.168399\n",
      "Train Epoch: 19 [21760/41964 (52%)]\tLoss: 0.165504\n",
      "Train Epoch: 19 [22400/41964 (53%)]\tLoss: 0.162729\n",
      "Train Epoch: 19 [23040/41964 (55%)]\tLoss: 0.130274\n",
      "Train Epoch: 19 [23680/41964 (56%)]\tLoss: 0.108996\n",
      "Train Epoch: 19 [24320/41964 (58%)]\tLoss: 0.429251\n",
      "Train Epoch: 19 [24960/41964 (59%)]\tLoss: 0.131252\n",
      "Train Epoch: 19 [25600/41964 (61%)]\tLoss: 0.485318\n",
      "Train Epoch: 19 [26240/41964 (62%)]\tLoss: 0.168356\n",
      "Train Epoch: 19 [26880/41964 (64%)]\tLoss: 0.203091\n",
      "Train Epoch: 19 [27520/41964 (66%)]\tLoss: 0.142560\n",
      "Train Epoch: 19 [28160/41964 (67%)]\tLoss: 0.156106\n",
      "Train Epoch: 19 [28800/41964 (69%)]\tLoss: 0.217603\n",
      "Train Epoch: 19 [29440/41964 (70%)]\tLoss: 0.156774\n",
      "Train Epoch: 19 [30080/41964 (72%)]\tLoss: 0.097566\n",
      "Train Epoch: 19 [30720/41964 (73%)]\tLoss: 0.135331\n",
      "Train Epoch: 19 [31360/41964 (75%)]\tLoss: 0.088165\n",
      "Train Epoch: 19 [32000/41964 (76%)]\tLoss: 0.220121\n",
      "Train Epoch: 19 [32640/41964 (78%)]\tLoss: 0.342658\n",
      "Train Epoch: 19 [33280/41964 (79%)]\tLoss: 0.083939\n",
      "Train Epoch: 19 [33920/41964 (81%)]\tLoss: 0.086938\n",
      "Train Epoch: 19 [34560/41964 (82%)]\tLoss: 0.146395\n",
      "Train Epoch: 19 [35200/41964 (84%)]\tLoss: 0.198842\n",
      "Train Epoch: 19 [35840/41964 (85%)]\tLoss: 0.049953\n",
      "Train Epoch: 19 [36480/41964 (87%)]\tLoss: 0.158926\n",
      "Train Epoch: 19 [37120/41964 (88%)]\tLoss: 0.110085\n",
      "Train Epoch: 19 [37760/41964 (90%)]\tLoss: 0.320268\n",
      "Train Epoch: 19 [38400/41964 (91%)]\tLoss: 0.106921\n",
      "Train Epoch: 19 [39040/41964 (93%)]\tLoss: 0.391077\n",
      "Train Epoch: 19 [39680/41964 (95%)]\tLoss: 0.049868\n",
      "Train Epoch: 19 [40320/41964 (96%)]\tLoss: 0.248812\n",
      "Train Epoch: 19 [40960/41964 (98%)]\tLoss: 0.159351\n",
      "Train Epoch: 19 [41600/41964 (99%)]\tLoss: 0.092468\n",
      "\n",
      "Test set: Avg. loss: 0.0560, Accuracy: 9824/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/41964 (0%)]\tLoss: 0.187455\n",
      "Train Epoch: 20 [640/41964 (2%)]\tLoss: 0.243020\n",
      "Train Epoch: 20 [1280/41964 (3%)]\tLoss: 0.133283\n",
      "Train Epoch: 20 [1920/41964 (5%)]\tLoss: 0.086070\n",
      "Train Epoch: 20 [2560/41964 (6%)]\tLoss: 0.144872\n",
      "Train Epoch: 20 [3200/41964 (8%)]\tLoss: 0.138425\n",
      "Train Epoch: 20 [3840/41964 (9%)]\tLoss: 0.106553\n",
      "Train Epoch: 20 [4480/41964 (11%)]\tLoss: 0.245439\n",
      "Train Epoch: 20 [5120/41964 (12%)]\tLoss: 0.128769\n",
      "Train Epoch: 20 [5760/41964 (14%)]\tLoss: 0.143362\n",
      "Train Epoch: 20 [6400/41964 (15%)]\tLoss: 0.112395\n",
      "Train Epoch: 20 [7040/41964 (17%)]\tLoss: 0.234193\n",
      "Train Epoch: 20 [7680/41964 (18%)]\tLoss: 0.322012\n",
      "Train Epoch: 20 [8320/41964 (20%)]\tLoss: 0.202797\n",
      "Train Epoch: 20 [8960/41964 (21%)]\tLoss: 0.080738\n",
      "Train Epoch: 20 [9600/41964 (23%)]\tLoss: 0.121580\n",
      "Train Epoch: 20 [10240/41964 (24%)]\tLoss: 0.316859\n",
      "Train Epoch: 20 [10880/41964 (26%)]\tLoss: 0.254021\n",
      "Train Epoch: 20 [11520/41964 (27%)]\tLoss: 0.126009\n",
      "Train Epoch: 20 [12160/41964 (29%)]\tLoss: 0.282099\n",
      "Train Epoch: 20 [12800/41964 (30%)]\tLoss: 0.084873\n",
      "Train Epoch: 20 [13440/41964 (32%)]\tLoss: 0.098092\n",
      "Train Epoch: 20 [14080/41964 (34%)]\tLoss: 0.113636\n",
      "Train Epoch: 20 [14720/41964 (35%)]\tLoss: 0.125217\n",
      "Train Epoch: 20 [15360/41964 (37%)]\tLoss: 0.267519\n",
      "Train Epoch: 20 [16000/41964 (38%)]\tLoss: 0.136464\n",
      "Train Epoch: 20 [16640/41964 (40%)]\tLoss: 0.269820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [17280/41964 (41%)]\tLoss: 0.176811\n",
      "Train Epoch: 20 [17920/41964 (43%)]\tLoss: 0.282984\n",
      "Train Epoch: 20 [18560/41964 (44%)]\tLoss: 0.240074\n",
      "Train Epoch: 20 [19200/41964 (46%)]\tLoss: 0.263255\n",
      "Train Epoch: 20 [19840/41964 (47%)]\tLoss: 0.166844\n",
      "Train Epoch: 20 [20480/41964 (49%)]\tLoss: 0.109661\n",
      "Train Epoch: 20 [21120/41964 (50%)]\tLoss: 0.145351\n",
      "Train Epoch: 20 [21760/41964 (52%)]\tLoss: 0.263272\n",
      "Train Epoch: 20 [22400/41964 (53%)]\tLoss: 0.218504\n",
      "Train Epoch: 20 [23040/41964 (55%)]\tLoss: 0.104239\n",
      "Train Epoch: 20 [23680/41964 (56%)]\tLoss: 0.166803\n",
      "Train Epoch: 20 [24320/41964 (58%)]\tLoss: 0.233019\n",
      "Train Epoch: 20 [24960/41964 (59%)]\tLoss: 0.279466\n",
      "Train Epoch: 20 [25600/41964 (61%)]\tLoss: 0.125563\n",
      "Train Epoch: 20 [26240/41964 (62%)]\tLoss: 0.106808\n",
      "Train Epoch: 20 [26880/41964 (64%)]\tLoss: 0.064227\n",
      "Train Epoch: 20 [27520/41964 (66%)]\tLoss: 0.235719\n",
      "Train Epoch: 20 [28160/41964 (67%)]\tLoss: 0.092290\n",
      "Train Epoch: 20 [28800/41964 (69%)]\tLoss: 0.191332\n",
      "Train Epoch: 20 [29440/41964 (70%)]\tLoss: 0.170690\n",
      "Train Epoch: 20 [30080/41964 (72%)]\tLoss: 0.254000\n",
      "Train Epoch: 20 [30720/41964 (73%)]\tLoss: 0.152926\n",
      "Train Epoch: 20 [31360/41964 (75%)]\tLoss: 0.199010\n",
      "Train Epoch: 20 [32000/41964 (76%)]\tLoss: 0.273446\n",
      "Train Epoch: 20 [32640/41964 (78%)]\tLoss: 0.118689\n",
      "Train Epoch: 20 [33280/41964 (79%)]\tLoss: 0.125159\n",
      "Train Epoch: 20 [33920/41964 (81%)]\tLoss: 0.117750\n",
      "Train Epoch: 20 [34560/41964 (82%)]\tLoss: 0.203299\n",
      "Train Epoch: 20 [35200/41964 (84%)]\tLoss: 0.210805\n",
      "Train Epoch: 20 [35840/41964 (85%)]\tLoss: 0.304581\n",
      "Train Epoch: 20 [36480/41964 (87%)]\tLoss: 0.497325\n",
      "Train Epoch: 20 [37120/41964 (88%)]\tLoss: 0.130579\n",
      "Train Epoch: 20 [37760/41964 (90%)]\tLoss: 0.224022\n",
      "Train Epoch: 20 [38400/41964 (91%)]\tLoss: 0.245341\n",
      "Train Epoch: 20 [39040/41964 (93%)]\tLoss: 0.170272\n",
      "Train Epoch: 20 [39680/41964 (95%)]\tLoss: 0.217764\n",
      "Train Epoch: 20 [40320/41964 (96%)]\tLoss: 0.052997\n",
      "Train Epoch: 20 [40960/41964 (98%)]\tLoss: 0.084361\n",
      "Train Epoch: 20 [41600/41964 (99%)]\tLoss: 0.257795\n",
      "\n",
      "Test set: Avg. loss: 0.0534, Accuracy: 9831/10000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/41964 (0%)]\tLoss: 0.026957\n",
      "Train Epoch: 21 [640/41964 (2%)]\tLoss: 0.136389\n",
      "Train Epoch: 21 [1280/41964 (3%)]\tLoss: 0.218057\n",
      "Train Epoch: 21 [1920/41964 (5%)]\tLoss: 0.100009\n",
      "Train Epoch: 21 [2560/41964 (6%)]\tLoss: 0.082372\n",
      "Train Epoch: 21 [3200/41964 (8%)]\tLoss: 0.096855\n",
      "Train Epoch: 21 [3840/41964 (9%)]\tLoss: 0.185846\n",
      "Train Epoch: 21 [4480/41964 (11%)]\tLoss: 0.216693\n",
      "Train Epoch: 21 [5120/41964 (12%)]\tLoss: 0.262145\n",
      "Train Epoch: 21 [5760/41964 (14%)]\tLoss: 0.210787\n",
      "Train Epoch: 21 [6400/41964 (15%)]\tLoss: 0.180408\n",
      "Train Epoch: 21 [7040/41964 (17%)]\tLoss: 0.147197\n",
      "Train Epoch: 21 [7680/41964 (18%)]\tLoss: 0.341027\n",
      "Train Epoch: 21 [8320/41964 (20%)]\tLoss: 0.236931\n",
      "Train Epoch: 21 [8960/41964 (21%)]\tLoss: 0.128144\n",
      "Train Epoch: 21 [9600/41964 (23%)]\tLoss: 0.324513\n",
      "Train Epoch: 21 [10240/41964 (24%)]\tLoss: 0.382686\n",
      "Train Epoch: 21 [10880/41964 (26%)]\tLoss: 0.377688\n",
      "Train Epoch: 21 [11520/41964 (27%)]\tLoss: 0.130500\n",
      "Train Epoch: 21 [12160/41964 (29%)]\tLoss: 0.159733\n",
      "Train Epoch: 21 [12800/41964 (30%)]\tLoss: 0.124306\n",
      "Train Epoch: 21 [13440/41964 (32%)]\tLoss: 0.231661\n",
      "Train Epoch: 21 [14080/41964 (34%)]\tLoss: 0.218833\n",
      "Train Epoch: 21 [14720/41964 (35%)]\tLoss: 0.084653\n",
      "Train Epoch: 21 [15360/41964 (37%)]\tLoss: 0.107033\n",
      "Train Epoch: 21 [16000/41964 (38%)]\tLoss: 0.061640\n",
      "Train Epoch: 21 [16640/41964 (40%)]\tLoss: 0.092796\n",
      "Train Epoch: 21 [17280/41964 (41%)]\tLoss: 0.166964\n",
      "Train Epoch: 21 [17920/41964 (43%)]\tLoss: 0.164264\n",
      "Train Epoch: 21 [18560/41964 (44%)]\tLoss: 0.224762\n",
      "Train Epoch: 21 [19200/41964 (46%)]\tLoss: 0.138529\n",
      "Train Epoch: 21 [19840/41964 (47%)]\tLoss: 0.135135\n",
      "Train Epoch: 21 [20480/41964 (49%)]\tLoss: 0.251135\n",
      "Train Epoch: 21 [21120/41964 (50%)]\tLoss: 0.044082\n",
      "Train Epoch: 21 [21760/41964 (52%)]\tLoss: 0.189293\n",
      "Train Epoch: 21 [22400/41964 (53%)]\tLoss: 0.062172\n",
      "Train Epoch: 21 [23040/41964 (55%)]\tLoss: 0.127880\n",
      "Train Epoch: 21 [23680/41964 (56%)]\tLoss: 0.358920\n",
      "Train Epoch: 21 [24320/41964 (58%)]\tLoss: 0.238375\n",
      "Train Epoch: 21 [24960/41964 (59%)]\tLoss: 0.098173\n",
      "Train Epoch: 21 [25600/41964 (61%)]\tLoss: 0.227935\n",
      "Train Epoch: 21 [26240/41964 (62%)]\tLoss: 0.088497\n",
      "Train Epoch: 21 [26880/41964 (64%)]\tLoss: 0.253738\n",
      "Train Epoch: 21 [27520/41964 (66%)]\tLoss: 0.461895\n",
      "Train Epoch: 21 [28160/41964 (67%)]\tLoss: 0.646043\n",
      "Train Epoch: 21 [28800/41964 (69%)]\tLoss: 0.167694\n",
      "Train Epoch: 21 [29440/41964 (70%)]\tLoss: 0.158532\n",
      "Train Epoch: 21 [30080/41964 (72%)]\tLoss: 0.107879\n",
      "Train Epoch: 21 [30720/41964 (73%)]\tLoss: 0.119495\n",
      "Train Epoch: 21 [31360/41964 (75%)]\tLoss: 0.284718\n",
      "Train Epoch: 21 [32000/41964 (76%)]\tLoss: 0.176907\n",
      "Train Epoch: 21 [32640/41964 (78%)]\tLoss: 0.185524\n",
      "Train Epoch: 21 [33280/41964 (79%)]\tLoss: 0.140357\n",
      "Train Epoch: 21 [33920/41964 (81%)]\tLoss: 0.230134\n",
      "Train Epoch: 21 [34560/41964 (82%)]\tLoss: 0.074402\n",
      "Train Epoch: 21 [35200/41964 (84%)]\tLoss: 0.155529\n",
      "Train Epoch: 21 [35840/41964 (85%)]\tLoss: 0.054228\n",
      "Train Epoch: 21 [36480/41964 (87%)]\tLoss: 0.087183\n",
      "Train Epoch: 21 [37120/41964 (88%)]\tLoss: 0.231324\n",
      "Train Epoch: 21 [37760/41964 (90%)]\tLoss: 0.223640\n",
      "Train Epoch: 21 [38400/41964 (91%)]\tLoss: 0.226852\n",
      "Train Epoch: 21 [39040/41964 (93%)]\tLoss: 0.142514\n",
      "Train Epoch: 21 [39680/41964 (95%)]\tLoss: 0.205400\n",
      "Train Epoch: 21 [40320/41964 (96%)]\tLoss: 0.110054\n",
      "Train Epoch: 21 [40960/41964 (98%)]\tLoss: 0.409587\n",
      "Train Epoch: 21 [41600/41964 (99%)]\tLoss: 0.245926\n",
      "\n",
      "Test set: Avg. loss: 0.0498, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/41964 (0%)]\tLoss: 0.177014\n",
      "Train Epoch: 22 [640/41964 (2%)]\tLoss: 0.151144\n",
      "Train Epoch: 22 [1280/41964 (3%)]\tLoss: 0.112145\n",
      "Train Epoch: 22 [1920/41964 (5%)]\tLoss: 0.128306\n",
      "Train Epoch: 22 [2560/41964 (6%)]\tLoss: 0.050420\n",
      "Train Epoch: 22 [3200/41964 (8%)]\tLoss: 0.197771\n",
      "Train Epoch: 22 [3840/41964 (9%)]\tLoss: 0.531712\n",
      "Train Epoch: 22 [4480/41964 (11%)]\tLoss: 0.150465\n",
      "Train Epoch: 22 [5120/41964 (12%)]\tLoss: 0.122737\n",
      "Train Epoch: 22 [5760/41964 (14%)]\tLoss: 0.159367\n",
      "Train Epoch: 22 [6400/41964 (15%)]\tLoss: 0.143809\n",
      "Train Epoch: 22 [7040/41964 (17%)]\tLoss: 0.172304\n",
      "Train Epoch: 22 [7680/41964 (18%)]\tLoss: 0.088858\n",
      "Train Epoch: 22 [8320/41964 (20%)]\tLoss: 0.299247\n",
      "Train Epoch: 22 [8960/41964 (21%)]\tLoss: 0.101226\n",
      "Train Epoch: 22 [9600/41964 (23%)]\tLoss: 0.084079\n",
      "Train Epoch: 22 [10240/41964 (24%)]\tLoss: 0.132968\n",
      "Train Epoch: 22 [10880/41964 (26%)]\tLoss: 0.140421\n",
      "Train Epoch: 22 [11520/41964 (27%)]\tLoss: 0.134446\n",
      "Train Epoch: 22 [12160/41964 (29%)]\tLoss: 0.162660\n",
      "Train Epoch: 22 [12800/41964 (30%)]\tLoss: 0.115106\n",
      "Train Epoch: 22 [13440/41964 (32%)]\tLoss: 0.260247\n",
      "Train Epoch: 22 [14080/41964 (34%)]\tLoss: 0.090006\n",
      "Train Epoch: 22 [14720/41964 (35%)]\tLoss: 0.142368\n",
      "Train Epoch: 22 [15360/41964 (37%)]\tLoss: 0.165401\n",
      "Train Epoch: 22 [16000/41964 (38%)]\tLoss: 0.174320\n",
      "Train Epoch: 22 [16640/41964 (40%)]\tLoss: 0.163060\n",
      "Train Epoch: 22 [17280/41964 (41%)]\tLoss: 0.130630\n",
      "Train Epoch: 22 [17920/41964 (43%)]\tLoss: 0.201583\n",
      "Train Epoch: 22 [18560/41964 (44%)]\tLoss: 0.285615\n",
      "Train Epoch: 22 [19200/41964 (46%)]\tLoss: 0.212663\n",
      "Train Epoch: 22 [19840/41964 (47%)]\tLoss: 0.295254\n",
      "Train Epoch: 22 [20480/41964 (49%)]\tLoss: 0.213485\n",
      "Train Epoch: 22 [21120/41964 (50%)]\tLoss: 0.089429\n",
      "Train Epoch: 22 [21760/41964 (52%)]\tLoss: 0.185379\n",
      "Train Epoch: 22 [22400/41964 (53%)]\tLoss: 0.255537\n",
      "Train Epoch: 22 [23040/41964 (55%)]\tLoss: 0.175851\n",
      "Train Epoch: 22 [23680/41964 (56%)]\tLoss: 0.139517\n",
      "Train Epoch: 22 [24320/41964 (58%)]\tLoss: 0.136130\n",
      "Train Epoch: 22 [24960/41964 (59%)]\tLoss: 0.110359\n",
      "Train Epoch: 22 [25600/41964 (61%)]\tLoss: 0.380828\n",
      "Train Epoch: 22 [26240/41964 (62%)]\tLoss: 0.153619\n",
      "Train Epoch: 22 [26880/41964 (64%)]\tLoss: 0.117023\n",
      "Train Epoch: 22 [27520/41964 (66%)]\tLoss: 0.255896\n",
      "Train Epoch: 22 [28160/41964 (67%)]\tLoss: 0.138018\n",
      "Train Epoch: 22 [28800/41964 (69%)]\tLoss: 0.169634\n",
      "Train Epoch: 22 [29440/41964 (70%)]\tLoss: 0.149016\n",
      "Train Epoch: 22 [30080/41964 (72%)]\tLoss: 0.132910\n",
      "Train Epoch: 22 [30720/41964 (73%)]\tLoss: 0.420834\n",
      "Train Epoch: 22 [31360/41964 (75%)]\tLoss: 0.059536\n",
      "Train Epoch: 22 [32000/41964 (76%)]\tLoss: 0.151276\n",
      "Train Epoch: 22 [32640/41964 (78%)]\tLoss: 0.187152\n",
      "Train Epoch: 22 [33280/41964 (79%)]\tLoss: 0.151922\n",
      "Train Epoch: 22 [33920/41964 (81%)]\tLoss: 0.260431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [34560/41964 (82%)]\tLoss: 0.172318\n",
      "Train Epoch: 22 [35200/41964 (84%)]\tLoss: 0.132223\n",
      "Train Epoch: 22 [35840/41964 (85%)]\tLoss: 0.084669\n",
      "Train Epoch: 22 [36480/41964 (87%)]\tLoss: 0.021561\n",
      "Train Epoch: 22 [37120/41964 (88%)]\tLoss: 0.187013\n",
      "Train Epoch: 22 [37760/41964 (90%)]\tLoss: 0.214076\n",
      "Train Epoch: 22 [38400/41964 (91%)]\tLoss: 0.056559\n",
      "Train Epoch: 22 [39040/41964 (93%)]\tLoss: 0.120314\n",
      "Train Epoch: 22 [39680/41964 (95%)]\tLoss: 0.113818\n",
      "Train Epoch: 22 [40320/41964 (96%)]\tLoss: 0.075099\n",
      "Train Epoch: 22 [40960/41964 (98%)]\tLoss: 0.052549\n",
      "Train Epoch: 22 [41600/41964 (99%)]\tLoss: 0.130008\n",
      "\n",
      "Test set: Avg. loss: 0.0504, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/41964 (0%)]\tLoss: 0.208566\n",
      "Train Epoch: 23 [640/41964 (2%)]\tLoss: 0.120657\n",
      "Train Epoch: 23 [1280/41964 (3%)]\tLoss: 0.104459\n",
      "Train Epoch: 23 [1920/41964 (5%)]\tLoss: 0.119493\n",
      "Train Epoch: 23 [2560/41964 (6%)]\tLoss: 0.243926\n",
      "Train Epoch: 23 [3200/41964 (8%)]\tLoss: 0.182833\n",
      "Train Epoch: 23 [3840/41964 (9%)]\tLoss: 0.146209\n",
      "Train Epoch: 23 [4480/41964 (11%)]\tLoss: 0.265501\n",
      "Train Epoch: 23 [5120/41964 (12%)]\tLoss: 0.179739\n",
      "Train Epoch: 23 [5760/41964 (14%)]\tLoss: 0.086565\n",
      "Train Epoch: 23 [6400/41964 (15%)]\tLoss: 0.111104\n",
      "Train Epoch: 23 [7040/41964 (17%)]\tLoss: 0.334974\n",
      "Train Epoch: 23 [7680/41964 (18%)]\tLoss: 0.208574\n",
      "Train Epoch: 23 [8320/41964 (20%)]\tLoss: 0.073677\n",
      "Train Epoch: 23 [8960/41964 (21%)]\tLoss: 0.283154\n",
      "Train Epoch: 23 [9600/41964 (23%)]\tLoss: 0.163344\n",
      "Train Epoch: 23 [10240/41964 (24%)]\tLoss: 0.139233\n",
      "Train Epoch: 23 [10880/41964 (26%)]\tLoss: 0.085690\n",
      "Train Epoch: 23 [11520/41964 (27%)]\tLoss: 0.182370\n",
      "Train Epoch: 23 [12160/41964 (29%)]\tLoss: 0.157192\n",
      "Train Epoch: 23 [12800/41964 (30%)]\tLoss: 0.221090\n",
      "Train Epoch: 23 [13440/41964 (32%)]\tLoss: 0.250274\n",
      "Train Epoch: 23 [14080/41964 (34%)]\tLoss: 0.275596\n",
      "Train Epoch: 23 [14720/41964 (35%)]\tLoss: 0.075965\n",
      "Train Epoch: 23 [15360/41964 (37%)]\tLoss: 0.159591\n",
      "Train Epoch: 23 [16000/41964 (38%)]\tLoss: 0.099715\n",
      "Train Epoch: 23 [16640/41964 (40%)]\tLoss: 0.282840\n",
      "Train Epoch: 23 [17280/41964 (41%)]\tLoss: 0.108181\n",
      "Train Epoch: 23 [17920/41964 (43%)]\tLoss: 0.154609\n",
      "Train Epoch: 23 [18560/41964 (44%)]\tLoss: 0.283754\n",
      "Train Epoch: 23 [19200/41964 (46%)]\tLoss: 0.224517\n",
      "Train Epoch: 23 [19840/41964 (47%)]\tLoss: 0.253163\n",
      "Train Epoch: 23 [20480/41964 (49%)]\tLoss: 0.087602\n",
      "Train Epoch: 23 [21120/41964 (50%)]\tLoss: 0.100188\n",
      "Train Epoch: 23 [21760/41964 (52%)]\tLoss: 0.185596\n",
      "Train Epoch: 23 [22400/41964 (53%)]\tLoss: 0.091791\n",
      "Train Epoch: 23 [23040/41964 (55%)]\tLoss: 0.154511\n",
      "Train Epoch: 23 [23680/41964 (56%)]\tLoss: 0.401699\n",
      "Train Epoch: 23 [24320/41964 (58%)]\tLoss: 0.212296\n",
      "Train Epoch: 23 [24960/41964 (59%)]\tLoss: 0.072718\n",
      "Train Epoch: 23 [25600/41964 (61%)]\tLoss: 0.291289\n",
      "Train Epoch: 23 [26240/41964 (62%)]\tLoss: 0.119803\n",
      "Train Epoch: 23 [26880/41964 (64%)]\tLoss: 0.095265\n",
      "Train Epoch: 23 [27520/41964 (66%)]\tLoss: 0.088117\n",
      "Train Epoch: 23 [28160/41964 (67%)]\tLoss: 0.178587\n",
      "Train Epoch: 23 [28800/41964 (69%)]\tLoss: 0.157565\n",
      "Train Epoch: 23 [29440/41964 (70%)]\tLoss: 0.203412\n",
      "Train Epoch: 23 [30080/41964 (72%)]\tLoss: 0.177031\n",
      "Train Epoch: 23 [30720/41964 (73%)]\tLoss: 0.165584\n",
      "Train Epoch: 23 [31360/41964 (75%)]\tLoss: 0.143225\n",
      "Train Epoch: 23 [32000/41964 (76%)]\tLoss: 0.155960\n",
      "Train Epoch: 23 [32640/41964 (78%)]\tLoss: 0.115547\n",
      "Train Epoch: 23 [33280/41964 (79%)]\tLoss: 0.048459\n",
      "Train Epoch: 23 [33920/41964 (81%)]\tLoss: 0.105609\n",
      "Train Epoch: 23 [34560/41964 (82%)]\tLoss: 0.074604\n",
      "Train Epoch: 23 [35200/41964 (84%)]\tLoss: 0.187290\n",
      "Train Epoch: 23 [35840/41964 (85%)]\tLoss: 0.086522\n",
      "Train Epoch: 23 [36480/41964 (87%)]\tLoss: 0.179164\n",
      "Train Epoch: 23 [37120/41964 (88%)]\tLoss: 0.186319\n",
      "Train Epoch: 23 [37760/41964 (90%)]\tLoss: 0.199783\n",
      "Train Epoch: 23 [38400/41964 (91%)]\tLoss: 0.085563\n",
      "Train Epoch: 23 [39040/41964 (93%)]\tLoss: 0.134977\n",
      "Train Epoch: 23 [39680/41964 (95%)]\tLoss: 0.060414\n",
      "Train Epoch: 23 [40320/41964 (96%)]\tLoss: 0.111755\n",
      "Train Epoch: 23 [40960/41964 (98%)]\tLoss: 0.269167\n",
      "Train Epoch: 23 [41600/41964 (99%)]\tLoss: 0.195228\n",
      "\n",
      "Test set: Avg. loss: 0.0514, Accuracy: 9842/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/41964 (0%)]\tLoss: 0.046033\n",
      "Train Epoch: 24 [640/41964 (2%)]\tLoss: 0.152049\n",
      "Train Epoch: 24 [1280/41964 (3%)]\tLoss: 0.063441\n",
      "Train Epoch: 24 [1920/41964 (5%)]\tLoss: 0.092906\n",
      "Train Epoch: 24 [2560/41964 (6%)]\tLoss: 0.171353\n",
      "Train Epoch: 24 [3200/41964 (8%)]\tLoss: 0.165034\n",
      "Train Epoch: 24 [3840/41964 (9%)]\tLoss: 0.232728\n",
      "Train Epoch: 24 [4480/41964 (11%)]\tLoss: 0.140864\n",
      "Train Epoch: 24 [5120/41964 (12%)]\tLoss: 0.054661\n",
      "Train Epoch: 24 [5760/41964 (14%)]\tLoss: 0.115906\n",
      "Train Epoch: 24 [6400/41964 (15%)]\tLoss: 0.149035\n",
      "Train Epoch: 24 [7040/41964 (17%)]\tLoss: 0.237855\n",
      "Train Epoch: 24 [7680/41964 (18%)]\tLoss: 0.105632\n",
      "Train Epoch: 24 [8320/41964 (20%)]\tLoss: 0.060087\n",
      "Train Epoch: 24 [8960/41964 (21%)]\tLoss: 0.173791\n",
      "Train Epoch: 24 [9600/41964 (23%)]\tLoss: 0.231171\n",
      "Train Epoch: 24 [10240/41964 (24%)]\tLoss: 0.081516\n",
      "Train Epoch: 24 [10880/41964 (26%)]\tLoss: 0.047072\n",
      "Train Epoch: 24 [11520/41964 (27%)]\tLoss: 0.172324\n",
      "Train Epoch: 24 [12160/41964 (29%)]\tLoss: 0.166736\n",
      "Train Epoch: 24 [12800/41964 (30%)]\tLoss: 0.224526\n",
      "Train Epoch: 24 [13440/41964 (32%)]\tLoss: 0.091708\n",
      "Train Epoch: 24 [14080/41964 (34%)]\tLoss: 0.175752\n",
      "Train Epoch: 24 [14720/41964 (35%)]\tLoss: 0.185796\n",
      "Train Epoch: 24 [15360/41964 (37%)]\tLoss: 0.146907\n",
      "Train Epoch: 24 [16000/41964 (38%)]\tLoss: 0.103309\n",
      "Train Epoch: 24 [16640/41964 (40%)]\tLoss: 0.245336\n",
      "Train Epoch: 24 [17280/41964 (41%)]\tLoss: 0.090283\n",
      "Train Epoch: 24 [17920/41964 (43%)]\tLoss: 0.236020\n",
      "Train Epoch: 24 [18560/41964 (44%)]\tLoss: 0.141641\n",
      "Train Epoch: 24 [19200/41964 (46%)]\tLoss: 0.105797\n",
      "Train Epoch: 24 [19840/41964 (47%)]\tLoss: 0.131725\n",
      "Train Epoch: 24 [20480/41964 (49%)]\tLoss: 0.135981\n",
      "Train Epoch: 24 [21120/41964 (50%)]\tLoss: 0.336659\n",
      "Train Epoch: 24 [21760/41964 (52%)]\tLoss: 0.090553\n",
      "Train Epoch: 24 [22400/41964 (53%)]\tLoss: 0.077366\n",
      "Train Epoch: 24 [23040/41964 (55%)]\tLoss: 0.052560\n",
      "Train Epoch: 24 [23680/41964 (56%)]\tLoss: 0.152252\n",
      "Train Epoch: 24 [24320/41964 (58%)]\tLoss: 0.343820\n",
      "Train Epoch: 24 [24960/41964 (59%)]\tLoss: 0.061283\n",
      "Train Epoch: 24 [25600/41964 (61%)]\tLoss: 0.145052\n",
      "Train Epoch: 24 [26240/41964 (62%)]\tLoss: 0.077509\n",
      "Train Epoch: 24 [26880/41964 (64%)]\tLoss: 0.151439\n",
      "Train Epoch: 24 [27520/41964 (66%)]\tLoss: 0.130077\n",
      "Train Epoch: 24 [28160/41964 (67%)]\tLoss: 0.178639\n",
      "Train Epoch: 24 [28800/41964 (69%)]\tLoss: 0.241690\n",
      "Train Epoch: 24 [29440/41964 (70%)]\tLoss: 0.191677\n",
      "Train Epoch: 24 [30080/41964 (72%)]\tLoss: 0.252464\n",
      "Train Epoch: 24 [30720/41964 (73%)]\tLoss: 0.152602\n",
      "Train Epoch: 24 [31360/41964 (75%)]\tLoss: 0.150253\n",
      "Train Epoch: 24 [32000/41964 (76%)]\tLoss: 0.312180\n",
      "Train Epoch: 24 [32640/41964 (78%)]\tLoss: 0.123282\n",
      "Train Epoch: 24 [33280/41964 (79%)]\tLoss: 0.314706\n",
      "Train Epoch: 24 [33920/41964 (81%)]\tLoss: 0.305910\n",
      "Train Epoch: 24 [34560/41964 (82%)]\tLoss: 0.075900\n",
      "Train Epoch: 24 [35200/41964 (84%)]\tLoss: 0.106804\n",
      "Train Epoch: 24 [35840/41964 (85%)]\tLoss: 0.240026\n",
      "Train Epoch: 24 [36480/41964 (87%)]\tLoss: 0.074166\n",
      "Train Epoch: 24 [37120/41964 (88%)]\tLoss: 0.201708\n",
      "Train Epoch: 24 [37760/41964 (90%)]\tLoss: 0.096448\n",
      "Train Epoch: 24 [38400/41964 (91%)]\tLoss: 0.271535\n",
      "Train Epoch: 24 [39040/41964 (93%)]\tLoss: 0.105207\n",
      "Train Epoch: 24 [39680/41964 (95%)]\tLoss: 0.102304\n",
      "Train Epoch: 24 [40320/41964 (96%)]\tLoss: 0.191958\n",
      "Train Epoch: 24 [40960/41964 (98%)]\tLoss: 0.153342\n",
      "Train Epoch: 24 [41600/41964 (99%)]\tLoss: 0.102127\n",
      "\n",
      "Test set: Avg. loss: 0.0498, Accuracy: 9836/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/41964 (0%)]\tLoss: 0.383293\n",
      "Train Epoch: 25 [640/41964 (2%)]\tLoss: 0.055216\n",
      "Train Epoch: 25 [1280/41964 (3%)]\tLoss: 0.208307\n",
      "Train Epoch: 25 [1920/41964 (5%)]\tLoss: 0.261181\n",
      "Train Epoch: 25 [2560/41964 (6%)]\tLoss: 0.124622\n",
      "Train Epoch: 25 [3200/41964 (8%)]\tLoss: 0.102343\n",
      "Train Epoch: 25 [3840/41964 (9%)]\tLoss: 0.232907\n",
      "Train Epoch: 25 [4480/41964 (11%)]\tLoss: 0.084231\n",
      "Train Epoch: 25 [5120/41964 (12%)]\tLoss: 0.239696\n",
      "Train Epoch: 25 [5760/41964 (14%)]\tLoss: 0.075584\n",
      "Train Epoch: 25 [6400/41964 (15%)]\tLoss: 0.273715\n",
      "Train Epoch: 25 [7040/41964 (17%)]\tLoss: 0.338868\n",
      "Train Epoch: 25 [7680/41964 (18%)]\tLoss: 0.129960\n",
      "Train Epoch: 25 [8320/41964 (20%)]\tLoss: 0.293857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [8960/41964 (21%)]\tLoss: 0.064642\n",
      "Train Epoch: 25 [9600/41964 (23%)]\tLoss: 0.107187\n",
      "Train Epoch: 25 [10240/41964 (24%)]\tLoss: 0.262961\n",
      "Train Epoch: 25 [10880/41964 (26%)]\tLoss: 0.222839\n",
      "Train Epoch: 25 [11520/41964 (27%)]\tLoss: 0.237436\n",
      "Train Epoch: 25 [12160/41964 (29%)]\tLoss: 0.231805\n",
      "Train Epoch: 25 [12800/41964 (30%)]\tLoss: 0.188491\n",
      "Train Epoch: 25 [13440/41964 (32%)]\tLoss: 0.220252\n",
      "Train Epoch: 25 [14080/41964 (34%)]\tLoss: 0.227819\n",
      "Train Epoch: 25 [14720/41964 (35%)]\tLoss: 0.164027\n",
      "Train Epoch: 25 [15360/41964 (37%)]\tLoss: 0.269662\n",
      "Train Epoch: 25 [16000/41964 (38%)]\tLoss: 0.066166\n",
      "Train Epoch: 25 [16640/41964 (40%)]\tLoss: 0.273509\n",
      "Train Epoch: 25 [17280/41964 (41%)]\tLoss: 0.159596\n",
      "Train Epoch: 25 [17920/41964 (43%)]\tLoss: 0.237173\n",
      "Train Epoch: 25 [18560/41964 (44%)]\tLoss: 0.190682\n",
      "Train Epoch: 25 [19200/41964 (46%)]\tLoss: 0.222364\n",
      "Train Epoch: 25 [19840/41964 (47%)]\tLoss: 0.165764\n",
      "Train Epoch: 25 [20480/41964 (49%)]\tLoss: 0.136408\n",
      "Train Epoch: 25 [21120/41964 (50%)]\tLoss: 0.187560\n",
      "Train Epoch: 25 [21760/41964 (52%)]\tLoss: 0.076438\n",
      "Train Epoch: 25 [22400/41964 (53%)]\tLoss: 0.075998\n",
      "Train Epoch: 25 [23040/41964 (55%)]\tLoss: 0.247484\n",
      "Train Epoch: 25 [23680/41964 (56%)]\tLoss: 0.287009\n",
      "Train Epoch: 25 [24320/41964 (58%)]\tLoss: 0.091194\n",
      "Train Epoch: 25 [24960/41964 (59%)]\tLoss: 0.280564\n",
      "Train Epoch: 25 [25600/41964 (61%)]\tLoss: 0.079492\n",
      "Train Epoch: 25 [26240/41964 (62%)]\tLoss: 0.106869\n",
      "Train Epoch: 25 [26880/41964 (64%)]\tLoss: 0.230574\n",
      "Train Epoch: 25 [27520/41964 (66%)]\tLoss: 0.267155\n",
      "Train Epoch: 25 [28160/41964 (67%)]\tLoss: 0.166258\n",
      "Train Epoch: 25 [28800/41964 (69%)]\tLoss: 0.090900\n",
      "Train Epoch: 25 [29440/41964 (70%)]\tLoss: 0.233280\n",
      "Train Epoch: 25 [30080/41964 (72%)]\tLoss: 0.186807\n",
      "Train Epoch: 25 [30720/41964 (73%)]\tLoss: 0.118086\n",
      "Train Epoch: 25 [31360/41964 (75%)]\tLoss: 0.116652\n",
      "Train Epoch: 25 [32000/41964 (76%)]\tLoss: 0.121180\n",
      "Train Epoch: 25 [32640/41964 (78%)]\tLoss: 0.288739\n",
      "Train Epoch: 25 [33280/41964 (79%)]\tLoss: 0.111970\n",
      "Train Epoch: 25 [33920/41964 (81%)]\tLoss: 0.096071\n",
      "Train Epoch: 25 [34560/41964 (82%)]\tLoss: 0.430550\n",
      "Train Epoch: 25 [35200/41964 (84%)]\tLoss: 0.168680\n",
      "Train Epoch: 25 [35840/41964 (85%)]\tLoss: 0.094823\n",
      "Train Epoch: 25 [36480/41964 (87%)]\tLoss: 0.260743\n",
      "Train Epoch: 25 [37120/41964 (88%)]\tLoss: 0.256456\n",
      "Train Epoch: 25 [37760/41964 (90%)]\tLoss: 0.136168\n",
      "Train Epoch: 25 [38400/41964 (91%)]\tLoss: 0.076480\n",
      "Train Epoch: 25 [39040/41964 (93%)]\tLoss: 0.104794\n",
      "Train Epoch: 25 [39680/41964 (95%)]\tLoss: 0.360832\n",
      "Train Epoch: 25 [40320/41964 (96%)]\tLoss: 0.235116\n",
      "Train Epoch: 25 [40960/41964 (98%)]\tLoss: 0.117829\n",
      "Train Epoch: 25 [41600/41964 (99%)]\tLoss: 0.066690\n",
      "\n",
      "Test set: Avg. loss: 0.0477, Accuracy: 9851/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network_step = CNN()\n",
    "optimizer_step = optim.SGD(network_step.parameters(), lr=args.learning_rate, momentum=args.momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i * len(imbalanced_step_train_loader) for i in range(args.n_epochs + 1)]\n",
    "\n",
    "test(network_step)\n",
    "for epoch in range(1, args.n_epochs + 1):\n",
    "    train(epoch, imbalanced_step_train_loader, network_step, optimizer_step)\n",
    "    test(network_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3121, Accuracy: 1289/10000 (12%)\n",
      "\n",
      "Train Epoch: 1 [0/37879 (0%)]\tLoss: 2.346985\n",
      "Train Epoch: 1 [640/37879 (1%)]\tLoss: 2.294845\n",
      "Train Epoch: 1 [1280/37879 (3%)]\tLoss: 2.331121\n",
      "Train Epoch: 1 [1920/37879 (4%)]\tLoss: 2.283385\n",
      "Train Epoch: 1 [2560/37879 (5%)]\tLoss: 2.276864\n",
      "Train Epoch: 1 [3200/37879 (6%)]\tLoss: 2.279913\n",
      "Train Epoch: 1 [3840/37879 (8%)]\tLoss: 2.269794\n",
      "Train Epoch: 1 [4480/37879 (9%)]\tLoss: 2.191928\n",
      "Train Epoch: 1 [5120/37879 (10%)]\tLoss: 2.180579\n",
      "Train Epoch: 1 [5760/37879 (12%)]\tLoss: 2.229791\n",
      "Train Epoch: 1 [6400/37879 (13%)]\tLoss: 2.052692\n",
      "Train Epoch: 1 [7040/37879 (14%)]\tLoss: 2.088785\n",
      "Train Epoch: 1 [7680/37879 (15%)]\tLoss: 1.934912\n",
      "Train Epoch: 1 [8320/37879 (17%)]\tLoss: 1.892515\n",
      "Train Epoch: 1 [8960/37879 (18%)]\tLoss: 1.807242\n",
      "Train Epoch: 1 [9600/37879 (19%)]\tLoss: 1.595693\n",
      "Train Epoch: 1 [10240/37879 (20%)]\tLoss: 1.638608\n",
      "Train Epoch: 1 [10880/37879 (22%)]\tLoss: 1.672789\n",
      "Train Epoch: 1 [11520/37879 (23%)]\tLoss: 1.482107\n",
      "Train Epoch: 1 [12160/37879 (24%)]\tLoss: 1.362137\n",
      "Train Epoch: 1 [12800/37879 (26%)]\tLoss: 1.485894\n",
      "Train Epoch: 1 [13440/37879 (27%)]\tLoss: 1.169037\n",
      "Train Epoch: 1 [14080/37879 (28%)]\tLoss: 1.318603\n",
      "Train Epoch: 1 [14720/37879 (29%)]\tLoss: 1.114813\n",
      "Train Epoch: 1 [15360/37879 (31%)]\tLoss: 1.223288\n",
      "Train Epoch: 1 [16000/37879 (32%)]\tLoss: 1.134201\n",
      "Train Epoch: 1 [16640/37879 (33%)]\tLoss: 1.063822\n",
      "Train Epoch: 1 [17280/37879 (35%)]\tLoss: 1.065980\n",
      "Train Epoch: 1 [17920/37879 (36%)]\tLoss: 1.099423\n",
      "Train Epoch: 1 [18560/37879 (37%)]\tLoss: 1.106621\n",
      "Train Epoch: 1 [19200/37879 (38%)]\tLoss: 0.991457\n",
      "Train Epoch: 1 [19840/37879 (40%)]\tLoss: 0.946205\n",
      "Train Epoch: 1 [20480/37879 (41%)]\tLoss: 1.068928\n",
      "Train Epoch: 1 [21120/37879 (42%)]\tLoss: 0.678432\n",
      "Train Epoch: 1 [21760/37879 (43%)]\tLoss: 1.010294\n",
      "Train Epoch: 1 [22400/37879 (45%)]\tLoss: 0.723330\n",
      "Train Epoch: 1 [23040/37879 (46%)]\tLoss: 0.787065\n",
      "Train Epoch: 1 [23680/37879 (47%)]\tLoss: 0.890201\n",
      "Train Epoch: 1 [24320/37879 (49%)]\tLoss: 0.956491\n",
      "Train Epoch: 1 [24960/37879 (50%)]\tLoss: 1.055115\n",
      "Train Epoch: 1 [25600/37879 (51%)]\tLoss: 0.773693\n",
      "Train Epoch: 1 [26240/37879 (52%)]\tLoss: 0.757736\n",
      "Train Epoch: 1 [26880/37879 (54%)]\tLoss: 0.719183\n",
      "Train Epoch: 1 [27520/37879 (55%)]\tLoss: 0.471879\n",
      "Train Epoch: 1 [28160/37879 (56%)]\tLoss: 0.517420\n",
      "Train Epoch: 1 [28800/37879 (58%)]\tLoss: 0.584931\n",
      "Train Epoch: 1 [29440/37879 (59%)]\tLoss: 0.855680\n",
      "Train Epoch: 1 [30080/37879 (60%)]\tLoss: 0.770083\n",
      "Train Epoch: 1 [30720/37879 (61%)]\tLoss: 0.816876\n",
      "Train Epoch: 1 [31360/37879 (63%)]\tLoss: 0.700367\n",
      "Train Epoch: 1 [32000/37879 (64%)]\tLoss: 0.581695\n",
      "Train Epoch: 1 [32640/37879 (65%)]\tLoss: 0.702180\n",
      "Train Epoch: 1 [33280/37879 (66%)]\tLoss: 0.786428\n",
      "Train Epoch: 1 [33920/37879 (68%)]\tLoss: 0.544891\n",
      "Train Epoch: 1 [34560/37879 (69%)]\tLoss: 0.948941\n",
      "Train Epoch: 1 [35200/37879 (70%)]\tLoss: 0.826320\n",
      "Train Epoch: 1 [35840/37879 (72%)]\tLoss: 0.771828\n",
      "Train Epoch: 1 [36480/37879 (73%)]\tLoss: 0.729990\n",
      "Train Epoch: 1 [37120/37879 (74%)]\tLoss: 0.734240\n",
      "Train Epoch: 1 [37760/37879 (75%)]\tLoss: 0.715942\n",
      "Train Epoch: 1 [38400/37879 (77%)]\tLoss: 0.715543\n",
      "Train Epoch: 1 [39040/37879 (78%)]\tLoss: 0.784935\n",
      "Train Epoch: 1 [39680/37879 (79%)]\tLoss: 0.636654\n",
      "Train Epoch: 1 [40320/37879 (81%)]\tLoss: 0.767808\n",
      "Train Epoch: 1 [40960/37879 (82%)]\tLoss: 0.786474\n",
      "Train Epoch: 1 [41600/37879 (83%)]\tLoss: 0.647496\n",
      "Train Epoch: 1 [42240/37879 (84%)]\tLoss: 0.561431\n",
      "Train Epoch: 1 [42880/37879 (86%)]\tLoss: 0.496271\n",
      "Train Epoch: 1 [43520/37879 (87%)]\tLoss: 0.897074\n",
      "Train Epoch: 1 [44160/37879 (88%)]\tLoss: 0.713895\n",
      "Train Epoch: 1 [44800/37879 (90%)]\tLoss: 0.667167\n",
      "Train Epoch: 1 [45440/37879 (91%)]\tLoss: 0.731012\n",
      "Train Epoch: 1 [46080/37879 (92%)]\tLoss: 0.602712\n",
      "Train Epoch: 1 [46720/37879 (93%)]\tLoss: 0.534369\n",
      "Train Epoch: 1 [47360/37879 (95%)]\tLoss: 0.630887\n",
      "Train Epoch: 1 [48000/37879 (96%)]\tLoss: 0.547598\n",
      "Train Epoch: 1 [48640/37879 (97%)]\tLoss: 0.392036\n",
      "Train Epoch: 1 [49280/37879 (98%)]\tLoss: 0.396625\n",
      "Train Epoch: 1 [49920/37879 (100%)]\tLoss: 0.629325\n",
      "\n",
      "Test set: Avg. loss: 0.2225, Accuracy: 9351/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/37879 (0%)]\tLoss: 0.586038\n",
      "Train Epoch: 2 [640/37879 (1%)]\tLoss: 0.438002\n",
      "Train Epoch: 2 [1280/37879 (3%)]\tLoss: 0.645766\n",
      "Train Epoch: 2 [1920/37879 (4%)]\tLoss: 0.410775\n",
      "Train Epoch: 2 [2560/37879 (5%)]\tLoss: 0.452357\n",
      "Train Epoch: 2 [3200/37879 (6%)]\tLoss: 0.709767\n",
      "Train Epoch: 2 [3840/37879 (8%)]\tLoss: 0.472699\n",
      "Train Epoch: 2 [4480/37879 (9%)]\tLoss: 0.586488\n",
      "Train Epoch: 2 [5120/37879 (10%)]\tLoss: 0.820969\n",
      "Train Epoch: 2 [5760/37879 (12%)]\tLoss: 0.709759\n",
      "Train Epoch: 2 [6400/37879 (13%)]\tLoss: 0.358325\n",
      "Train Epoch: 2 [7040/37879 (14%)]\tLoss: 0.378610\n",
      "Train Epoch: 2 [7680/37879 (15%)]\tLoss: 0.537311\n",
      "Train Epoch: 2 [8320/37879 (17%)]\tLoss: 0.535257\n",
      "Train Epoch: 2 [8960/37879 (18%)]\tLoss: 0.772925\n",
      "Train Epoch: 2 [9600/37879 (19%)]\tLoss: 0.565566\n",
      "Train Epoch: 2 [10240/37879 (20%)]\tLoss: 0.567620\n",
      "Train Epoch: 2 [10880/37879 (22%)]\tLoss: 0.543999\n",
      "Train Epoch: 2 [11520/37879 (23%)]\tLoss: 0.459036\n",
      "Train Epoch: 2 [12160/37879 (24%)]\tLoss: 0.498363\n",
      "Train Epoch: 2 [12800/37879 (26%)]\tLoss: 0.608343\n",
      "Train Epoch: 2 [13440/37879 (27%)]\tLoss: 0.767208\n",
      "Train Epoch: 2 [14080/37879 (28%)]\tLoss: 0.395945\n",
      "Train Epoch: 2 [14720/37879 (29%)]\tLoss: 0.519823\n",
      "Train Epoch: 2 [15360/37879 (31%)]\tLoss: 0.622935\n",
      "Train Epoch: 2 [16000/37879 (32%)]\tLoss: 0.481898\n",
      "Train Epoch: 2 [16640/37879 (33%)]\tLoss: 0.487982\n",
      "Train Epoch: 2 [17280/37879 (35%)]\tLoss: 0.527276\n",
      "Train Epoch: 2 [17920/37879 (36%)]\tLoss: 0.799108\n",
      "Train Epoch: 2 [18560/37879 (37%)]\tLoss: 0.385204\n",
      "Train Epoch: 2 [19200/37879 (38%)]\tLoss: 0.516974\n",
      "Train Epoch: 2 [19840/37879 (40%)]\tLoss: 0.561712\n",
      "Train Epoch: 2 [20480/37879 (41%)]\tLoss: 0.516687\n",
      "Train Epoch: 2 [21120/37879 (42%)]\tLoss: 0.428563\n",
      "Train Epoch: 2 [21760/37879 (43%)]\tLoss: 0.501122\n",
      "Train Epoch: 2 [22400/37879 (45%)]\tLoss: 0.401754\n",
      "Train Epoch: 2 [23040/37879 (46%)]\tLoss: 0.476589\n",
      "Train Epoch: 2 [23680/37879 (47%)]\tLoss: 0.405809\n",
      "Train Epoch: 2 [24320/37879 (49%)]\tLoss: 0.520647\n",
      "Train Epoch: 2 [24960/37879 (50%)]\tLoss: 0.539697\n",
      "Train Epoch: 2 [25600/37879 (51%)]\tLoss: 0.584773\n",
      "Train Epoch: 2 [26240/37879 (52%)]\tLoss: 0.450438\n",
      "Train Epoch: 2 [26880/37879 (54%)]\tLoss: 0.347383\n",
      "Train Epoch: 2 [27520/37879 (55%)]\tLoss: 0.382194\n",
      "Train Epoch: 2 [28160/37879 (56%)]\tLoss: 0.565693\n",
      "Train Epoch: 2 [28800/37879 (58%)]\tLoss: 0.383553\n",
      "Train Epoch: 2 [29440/37879 (59%)]\tLoss: 0.492027\n",
      "Train Epoch: 2 [30080/37879 (60%)]\tLoss: 0.368549\n",
      "Train Epoch: 2 [30720/37879 (61%)]\tLoss: 0.339815\n",
      "Train Epoch: 2 [31360/37879 (63%)]\tLoss: 0.526248\n",
      "Train Epoch: 2 [32000/37879 (64%)]\tLoss: 0.478111\n",
      "Train Epoch: 2 [32640/37879 (65%)]\tLoss: 0.490675\n",
      "Train Epoch: 2 [33280/37879 (66%)]\tLoss: 0.484191\n",
      "Train Epoch: 2 [33920/37879 (68%)]\tLoss: 0.409290\n",
      "Train Epoch: 2 [34560/37879 (69%)]\tLoss: 0.344564\n",
      "Train Epoch: 2 [35200/37879 (70%)]\tLoss: 0.383785\n",
      "Train Epoch: 2 [35840/37879 (72%)]\tLoss: 0.696662\n",
      "Train Epoch: 2 [36480/37879 (73%)]\tLoss: 0.431229\n",
      "Train Epoch: 2 [37120/37879 (74%)]\tLoss: 0.396233\n",
      "Train Epoch: 2 [37760/37879 (75%)]\tLoss: 0.449904\n",
      "Train Epoch: 2 [38400/37879 (77%)]\tLoss: 0.420048\n",
      "Train Epoch: 2 [39040/37879 (78%)]\tLoss: 0.418364\n",
      "Train Epoch: 2 [39680/37879 (79%)]\tLoss: 0.565911\n",
      "Train Epoch: 2 [40320/37879 (81%)]\tLoss: 0.307275\n",
      "Train Epoch: 2 [40960/37879 (82%)]\tLoss: 0.531066\n",
      "Train Epoch: 2 [41600/37879 (83%)]\tLoss: 0.386126\n",
      "Train Epoch: 2 [42240/37879 (84%)]\tLoss: 0.354762\n",
      "Train Epoch: 2 [42880/37879 (86%)]\tLoss: 0.445683\n",
      "Train Epoch: 2 [43520/37879 (87%)]\tLoss: 0.502372\n",
      "Train Epoch: 2 [44160/37879 (88%)]\tLoss: 0.410040\n",
      "Train Epoch: 2 [44800/37879 (90%)]\tLoss: 0.310212\n",
      "Train Epoch: 2 [45440/37879 (91%)]\tLoss: 0.313778\n",
      "Train Epoch: 2 [46080/37879 (92%)]\tLoss: 0.522513\n",
      "Train Epoch: 2 [46720/37879 (93%)]\tLoss: 0.381728\n",
      "Train Epoch: 2 [47360/37879 (95%)]\tLoss: 0.475563\n",
      "Train Epoch: 2 [48000/37879 (96%)]\tLoss: 0.334099\n",
      "Train Epoch: 2 [48640/37879 (97%)]\tLoss: 0.400065\n",
      "Train Epoch: 2 [49280/37879 (98%)]\tLoss: 0.292617\n",
      "Train Epoch: 2 [49920/37879 (100%)]\tLoss: 0.555085\n",
      "\n",
      "Test set: Avg. loss: 0.1358, Accuracy: 9580/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/37879 (0%)]\tLoss: 0.508999\n",
      "Train Epoch: 3 [640/37879 (1%)]\tLoss: 0.512891\n",
      "Train Epoch: 3 [1280/37879 (3%)]\tLoss: 0.357574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [1920/37879 (4%)]\tLoss: 0.367047\n",
      "Train Epoch: 3 [2560/37879 (5%)]\tLoss: 0.595592\n",
      "Train Epoch: 3 [3200/37879 (6%)]\tLoss: 0.337922\n",
      "Train Epoch: 3 [3840/37879 (8%)]\tLoss: 0.478347\n",
      "Train Epoch: 3 [4480/37879 (9%)]\tLoss: 0.625845\n",
      "Train Epoch: 3 [5120/37879 (10%)]\tLoss: 0.437738\n",
      "Train Epoch: 3 [5760/37879 (12%)]\tLoss: 0.478077\n",
      "Train Epoch: 3 [6400/37879 (13%)]\tLoss: 0.350850\n",
      "Train Epoch: 3 [7040/37879 (14%)]\tLoss: 0.385447\n",
      "Train Epoch: 3 [7680/37879 (15%)]\tLoss: 0.224056\n",
      "Train Epoch: 3 [8320/37879 (17%)]\tLoss: 0.300122\n",
      "Train Epoch: 3 [8960/37879 (18%)]\tLoss: 0.452803\n",
      "Train Epoch: 3 [9600/37879 (19%)]\tLoss: 0.510868\n",
      "Train Epoch: 3 [10240/37879 (20%)]\tLoss: 0.307067\n",
      "Train Epoch: 3 [10880/37879 (22%)]\tLoss: 0.526432\n",
      "Train Epoch: 3 [11520/37879 (23%)]\tLoss: 0.284303\n",
      "Train Epoch: 3 [12160/37879 (24%)]\tLoss: 0.649078\n",
      "Train Epoch: 3 [12800/37879 (26%)]\tLoss: 0.543617\n",
      "Train Epoch: 3 [13440/37879 (27%)]\tLoss: 0.275886\n",
      "Train Epoch: 3 [14080/37879 (28%)]\tLoss: 0.361558\n",
      "Train Epoch: 3 [14720/37879 (29%)]\tLoss: 0.230930\n",
      "Train Epoch: 3 [15360/37879 (31%)]\tLoss: 0.352659\n",
      "Train Epoch: 3 [16000/37879 (32%)]\tLoss: 0.388071\n",
      "Train Epoch: 3 [16640/37879 (33%)]\tLoss: 0.395827\n",
      "Train Epoch: 3 [17280/37879 (35%)]\tLoss: 0.320785\n",
      "Train Epoch: 3 [17920/37879 (36%)]\tLoss: 0.546771\n",
      "Train Epoch: 3 [18560/37879 (37%)]\tLoss: 0.463731\n",
      "Train Epoch: 3 [19200/37879 (38%)]\tLoss: 0.293572\n",
      "Train Epoch: 3 [19840/37879 (40%)]\tLoss: 0.454495\n",
      "Train Epoch: 3 [20480/37879 (41%)]\tLoss: 0.549944\n",
      "Train Epoch: 3 [21120/37879 (42%)]\tLoss: 0.502702\n",
      "Train Epoch: 3 [21760/37879 (43%)]\tLoss: 0.394242\n",
      "Train Epoch: 3 [22400/37879 (45%)]\tLoss: 0.231101\n",
      "Train Epoch: 3 [23040/37879 (46%)]\tLoss: 0.204451\n",
      "Train Epoch: 3 [23680/37879 (47%)]\tLoss: 0.350826\n",
      "Train Epoch: 3 [24320/37879 (49%)]\tLoss: 0.179050\n",
      "Train Epoch: 3 [24960/37879 (50%)]\tLoss: 0.247950\n",
      "Train Epoch: 3 [25600/37879 (51%)]\tLoss: 0.179109\n",
      "Train Epoch: 3 [26240/37879 (52%)]\tLoss: 0.394663\n",
      "Train Epoch: 3 [26880/37879 (54%)]\tLoss: 0.491022\n",
      "Train Epoch: 3 [27520/37879 (55%)]\tLoss: 0.546909\n",
      "Train Epoch: 3 [28160/37879 (56%)]\tLoss: 0.233915\n",
      "Train Epoch: 3 [28800/37879 (58%)]\tLoss: 0.399919\n",
      "Train Epoch: 3 [29440/37879 (59%)]\tLoss: 0.221630\n",
      "Train Epoch: 3 [30080/37879 (60%)]\tLoss: 0.481077\n",
      "Train Epoch: 3 [30720/37879 (61%)]\tLoss: 0.576617\n",
      "Train Epoch: 3 [31360/37879 (63%)]\tLoss: 0.315577\n",
      "Train Epoch: 3 [32000/37879 (64%)]\tLoss: 0.374277\n",
      "Train Epoch: 3 [32640/37879 (65%)]\tLoss: 0.582629\n",
      "Train Epoch: 3 [33280/37879 (66%)]\tLoss: 0.283021\n",
      "Train Epoch: 3 [33920/37879 (68%)]\tLoss: 0.267433\n",
      "Train Epoch: 3 [34560/37879 (69%)]\tLoss: 0.498977\n",
      "Train Epoch: 3 [35200/37879 (70%)]\tLoss: 0.433383\n",
      "Train Epoch: 3 [35840/37879 (72%)]\tLoss: 0.395696\n",
      "Train Epoch: 3 [36480/37879 (73%)]\tLoss: 0.475032\n",
      "Train Epoch: 3 [37120/37879 (74%)]\tLoss: 0.395280\n",
      "Train Epoch: 3 [37760/37879 (75%)]\tLoss: 0.479569\n",
      "Train Epoch: 3 [38400/37879 (77%)]\tLoss: 0.248686\n",
      "Train Epoch: 3 [39040/37879 (78%)]\tLoss: 0.348924\n",
      "Train Epoch: 3 [39680/37879 (79%)]\tLoss: 0.389261\n",
      "Train Epoch: 3 [40320/37879 (81%)]\tLoss: 0.221189\n",
      "Train Epoch: 3 [40960/37879 (82%)]\tLoss: 0.529504\n",
      "Train Epoch: 3 [41600/37879 (83%)]\tLoss: 0.484101\n",
      "Train Epoch: 3 [42240/37879 (84%)]\tLoss: 0.337726\n",
      "Train Epoch: 3 [42880/37879 (86%)]\tLoss: 0.496662\n",
      "Train Epoch: 3 [43520/37879 (87%)]\tLoss: 0.479629\n",
      "Train Epoch: 3 [44160/37879 (88%)]\tLoss: 0.458456\n",
      "Train Epoch: 3 [44800/37879 (90%)]\tLoss: 0.358391\n",
      "Train Epoch: 3 [45440/37879 (91%)]\tLoss: 0.459820\n",
      "Train Epoch: 3 [46080/37879 (92%)]\tLoss: 0.449209\n",
      "Train Epoch: 3 [46720/37879 (93%)]\tLoss: 0.235252\n",
      "Train Epoch: 3 [47360/37879 (95%)]\tLoss: 0.489835\n",
      "Train Epoch: 3 [48000/37879 (96%)]\tLoss: 0.254092\n",
      "Train Epoch: 3 [48640/37879 (97%)]\tLoss: 0.334301\n",
      "Train Epoch: 3 [49280/37879 (98%)]\tLoss: 0.292996\n",
      "Train Epoch: 3 [49920/37879 (100%)]\tLoss: 0.376653\n",
      "\n",
      "Test set: Avg. loss: 0.1196, Accuracy: 9647/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/37879 (0%)]\tLoss: 0.428508\n",
      "Train Epoch: 4 [640/37879 (1%)]\tLoss: 0.228846\n",
      "Train Epoch: 4 [1280/37879 (3%)]\tLoss: 0.362666\n",
      "Train Epoch: 4 [1920/37879 (4%)]\tLoss: 0.352089\n",
      "Train Epoch: 4 [2560/37879 (5%)]\tLoss: 0.468737\n",
      "Train Epoch: 4 [3200/37879 (6%)]\tLoss: 0.376354\n",
      "Train Epoch: 4 [3840/37879 (8%)]\tLoss: 0.214243\n",
      "Train Epoch: 4 [4480/37879 (9%)]\tLoss: 0.455512\n",
      "Train Epoch: 4 [5120/37879 (10%)]\tLoss: 0.308011\n",
      "Train Epoch: 4 [5760/37879 (12%)]\tLoss: 0.678254\n",
      "Train Epoch: 4 [6400/37879 (13%)]\tLoss: 0.416435\n",
      "Train Epoch: 4 [7040/37879 (14%)]\tLoss: 0.452731\n",
      "Train Epoch: 4 [7680/37879 (15%)]\tLoss: 0.473092\n",
      "Train Epoch: 4 [8320/37879 (17%)]\tLoss: 0.239127\n",
      "Train Epoch: 4 [8960/37879 (18%)]\tLoss: 0.505737\n",
      "Train Epoch: 4 [9600/37879 (19%)]\tLoss: 0.354998\n",
      "Train Epoch: 4 [10240/37879 (20%)]\tLoss: 0.192839\n",
      "Train Epoch: 4 [10880/37879 (22%)]\tLoss: 0.212640\n",
      "Train Epoch: 4 [11520/37879 (23%)]\tLoss: 0.380760\n",
      "Train Epoch: 4 [12160/37879 (24%)]\tLoss: 0.246650\n",
      "Train Epoch: 4 [12800/37879 (26%)]\tLoss: 0.290762\n",
      "Train Epoch: 4 [13440/37879 (27%)]\tLoss: 0.334519\n",
      "Train Epoch: 4 [14080/37879 (28%)]\tLoss: 0.506108\n",
      "Train Epoch: 4 [14720/37879 (29%)]\tLoss: 0.306377\n",
      "Train Epoch: 4 [15360/37879 (31%)]\tLoss: 0.295861\n",
      "Train Epoch: 4 [16000/37879 (32%)]\tLoss: 0.335596\n",
      "Train Epoch: 4 [16640/37879 (33%)]\tLoss: 0.417165\n",
      "Train Epoch: 4 [17280/37879 (35%)]\tLoss: 0.302938\n",
      "Train Epoch: 4 [17920/37879 (36%)]\tLoss: 0.404408\n",
      "Train Epoch: 4 [18560/37879 (37%)]\tLoss: 0.331940\n",
      "Train Epoch: 4 [19200/37879 (38%)]\tLoss: 0.250852\n",
      "Train Epoch: 4 [19840/37879 (40%)]\tLoss: 0.411766\n",
      "Train Epoch: 4 [20480/37879 (41%)]\tLoss: 0.283793\n",
      "Train Epoch: 4 [21120/37879 (42%)]\tLoss: 0.409569\n",
      "Train Epoch: 4 [21760/37879 (43%)]\tLoss: 0.338693\n",
      "Train Epoch: 4 [22400/37879 (45%)]\tLoss: 0.214592\n",
      "Train Epoch: 4 [23040/37879 (46%)]\tLoss: 0.446236\n",
      "Train Epoch: 4 [23680/37879 (47%)]\tLoss: 0.599141\n",
      "Train Epoch: 4 [24320/37879 (49%)]\tLoss: 0.309439\n",
      "Train Epoch: 4 [24960/37879 (50%)]\tLoss: 0.255226\n",
      "Train Epoch: 4 [25600/37879 (51%)]\tLoss: 0.369993\n",
      "Train Epoch: 4 [26240/37879 (52%)]\tLoss: 0.352997\n",
      "Train Epoch: 4 [26880/37879 (54%)]\tLoss: 0.402699\n",
      "Train Epoch: 4 [27520/37879 (55%)]\tLoss: 0.176683\n",
      "Train Epoch: 4 [28160/37879 (56%)]\tLoss: 0.104693\n",
      "Train Epoch: 4 [28800/37879 (58%)]\tLoss: 0.501165\n",
      "Train Epoch: 4 [29440/37879 (59%)]\tLoss: 0.323609\n",
      "Train Epoch: 4 [30080/37879 (60%)]\tLoss: 0.453926\n",
      "Train Epoch: 4 [30720/37879 (61%)]\tLoss: 0.549529\n",
      "Train Epoch: 4 [31360/37879 (63%)]\tLoss: 0.150792\n",
      "Train Epoch: 4 [32000/37879 (64%)]\tLoss: 0.417384\n",
      "Train Epoch: 4 [32640/37879 (65%)]\tLoss: 0.414665\n",
      "Train Epoch: 4 [33280/37879 (66%)]\tLoss: 0.208604\n",
      "Train Epoch: 4 [33920/37879 (68%)]\tLoss: 0.375642\n",
      "Train Epoch: 4 [34560/37879 (69%)]\tLoss: 0.444940\n",
      "Train Epoch: 4 [35200/37879 (70%)]\tLoss: 0.218437\n",
      "Train Epoch: 4 [35840/37879 (72%)]\tLoss: 0.254519\n",
      "Train Epoch: 4 [36480/37879 (73%)]\tLoss: 0.270914\n",
      "Train Epoch: 4 [37120/37879 (74%)]\tLoss: 0.210856\n",
      "Train Epoch: 4 [37760/37879 (75%)]\tLoss: 0.380138\n",
      "Train Epoch: 4 [38400/37879 (77%)]\tLoss: 0.191969\n",
      "Train Epoch: 4 [39040/37879 (78%)]\tLoss: 0.444129\n",
      "Train Epoch: 4 [39680/37879 (79%)]\tLoss: 0.425850\n",
      "Train Epoch: 4 [40320/37879 (81%)]\tLoss: 0.330578\n",
      "Train Epoch: 4 [40960/37879 (82%)]\tLoss: 0.280268\n",
      "Train Epoch: 4 [41600/37879 (83%)]\tLoss: 0.248967\n",
      "Train Epoch: 4 [42240/37879 (84%)]\tLoss: 0.388708\n",
      "Train Epoch: 4 [42880/37879 (86%)]\tLoss: 0.375584\n",
      "Train Epoch: 4 [43520/37879 (87%)]\tLoss: 0.500671\n",
      "Train Epoch: 4 [44160/37879 (88%)]\tLoss: 0.259192\n",
      "Train Epoch: 4 [44800/37879 (90%)]\tLoss: 0.249919\n",
      "Train Epoch: 4 [45440/37879 (91%)]\tLoss: 0.342505\n",
      "Train Epoch: 4 [46080/37879 (92%)]\tLoss: 0.383875\n",
      "Train Epoch: 4 [46720/37879 (93%)]\tLoss: 0.257792\n",
      "Train Epoch: 4 [47360/37879 (95%)]\tLoss: 0.222100\n",
      "Train Epoch: 4 [48000/37879 (96%)]\tLoss: 0.504817\n",
      "Train Epoch: 4 [48640/37879 (97%)]\tLoss: 0.276329\n",
      "Train Epoch: 4 [49280/37879 (98%)]\tLoss: 0.450767\n",
      "Train Epoch: 4 [49920/37879 (100%)]\tLoss: 0.235672\n",
      "\n",
      "Test set: Avg. loss: 0.0897, Accuracy: 9716/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/37879 (0%)]\tLoss: 0.217686\n",
      "Train Epoch: 5 [640/37879 (1%)]\tLoss: 0.104508\n",
      "Train Epoch: 5 [1280/37879 (3%)]\tLoss: 0.180935\n",
      "Train Epoch: 5 [1920/37879 (4%)]\tLoss: 0.259197\n",
      "Train Epoch: 5 [2560/37879 (5%)]\tLoss: 0.382103\n",
      "Train Epoch: 5 [3200/37879 (6%)]\tLoss: 0.328396\n",
      "Train Epoch: 5 [3840/37879 (8%)]\tLoss: 0.296489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [4480/37879 (9%)]\tLoss: 0.456869\n",
      "Train Epoch: 5 [5120/37879 (10%)]\tLoss: 0.269395\n",
      "Train Epoch: 5 [5760/37879 (12%)]\tLoss: 0.214313\n",
      "Train Epoch: 5 [6400/37879 (13%)]\tLoss: 0.480869\n",
      "Train Epoch: 5 [7040/37879 (14%)]\tLoss: 0.245320\n",
      "Train Epoch: 5 [7680/37879 (15%)]\tLoss: 0.564368\n",
      "Train Epoch: 5 [8320/37879 (17%)]\tLoss: 0.209896\n",
      "Train Epoch: 5 [8960/37879 (18%)]\tLoss: 0.353347\n",
      "Train Epoch: 5 [9600/37879 (19%)]\tLoss: 0.259509\n",
      "Train Epoch: 5 [10240/37879 (20%)]\tLoss: 0.105767\n",
      "Train Epoch: 5 [10880/37879 (22%)]\tLoss: 0.462111\n",
      "Train Epoch: 5 [11520/37879 (23%)]\tLoss: 0.391994\n",
      "Train Epoch: 5 [12160/37879 (24%)]\tLoss: 0.324591\n",
      "Train Epoch: 5 [12800/37879 (26%)]\tLoss: 0.394388\n",
      "Train Epoch: 5 [13440/37879 (27%)]\tLoss: 0.387710\n",
      "Train Epoch: 5 [14080/37879 (28%)]\tLoss: 0.321305\n",
      "Train Epoch: 5 [14720/37879 (29%)]\tLoss: 0.265294\n",
      "Train Epoch: 5 [15360/37879 (31%)]\tLoss: 0.230603\n",
      "Train Epoch: 5 [16000/37879 (32%)]\tLoss: 0.417626\n",
      "Train Epoch: 5 [16640/37879 (33%)]\tLoss: 0.363234\n",
      "Train Epoch: 5 [17280/37879 (35%)]\tLoss: 0.430423\n",
      "Train Epoch: 5 [17920/37879 (36%)]\tLoss: 0.358952\n",
      "Train Epoch: 5 [18560/37879 (37%)]\tLoss: 0.235842\n",
      "Train Epoch: 5 [19200/37879 (38%)]\tLoss: 0.429037\n",
      "Train Epoch: 5 [19840/37879 (40%)]\tLoss: 0.316755\n",
      "Train Epoch: 5 [20480/37879 (41%)]\tLoss: 0.311849\n",
      "Train Epoch: 5 [21120/37879 (42%)]\tLoss: 0.253864\n",
      "Train Epoch: 5 [21760/37879 (43%)]\tLoss: 0.353683\n",
      "Train Epoch: 5 [22400/37879 (45%)]\tLoss: 0.238422\n",
      "Train Epoch: 5 [23040/37879 (46%)]\tLoss: 0.298355\n",
      "Train Epoch: 5 [23680/37879 (47%)]\tLoss: 0.255940\n",
      "Train Epoch: 5 [24320/37879 (49%)]\tLoss: 0.220550\n",
      "Train Epoch: 5 [24960/37879 (50%)]\tLoss: 0.404136\n",
      "Train Epoch: 5 [25600/37879 (51%)]\tLoss: 0.564480\n",
      "Train Epoch: 5 [26240/37879 (52%)]\tLoss: 0.335382\n",
      "Train Epoch: 5 [26880/37879 (54%)]\tLoss: 0.367077\n",
      "Train Epoch: 5 [27520/37879 (55%)]\tLoss: 0.213132\n",
      "Train Epoch: 5 [28160/37879 (56%)]\tLoss: 0.150187\n",
      "Train Epoch: 5 [28800/37879 (58%)]\tLoss: 0.212370\n",
      "Train Epoch: 5 [29440/37879 (59%)]\tLoss: 0.252178\n",
      "Train Epoch: 5 [30080/37879 (60%)]\tLoss: 0.212603\n",
      "Train Epoch: 5 [30720/37879 (61%)]\tLoss: 0.396587\n",
      "Train Epoch: 5 [31360/37879 (63%)]\tLoss: 0.277145\n",
      "Train Epoch: 5 [32000/37879 (64%)]\tLoss: 0.249402\n",
      "Train Epoch: 5 [32640/37879 (65%)]\tLoss: 0.213036\n",
      "Train Epoch: 5 [33280/37879 (66%)]\tLoss: 0.322981\n",
      "Train Epoch: 5 [33920/37879 (68%)]\tLoss: 0.165379\n",
      "Train Epoch: 5 [34560/37879 (69%)]\tLoss: 0.252934\n",
      "Train Epoch: 5 [35200/37879 (70%)]\tLoss: 0.362918\n",
      "Train Epoch: 5 [35840/37879 (72%)]\tLoss: 0.188799\n",
      "Train Epoch: 5 [36480/37879 (73%)]\tLoss: 0.161588\n",
      "Train Epoch: 5 [37120/37879 (74%)]\tLoss: 0.181451\n",
      "Train Epoch: 5 [37760/37879 (75%)]\tLoss: 0.323191\n",
      "Train Epoch: 5 [38400/37879 (77%)]\tLoss: 0.240718\n",
      "Train Epoch: 5 [39040/37879 (78%)]\tLoss: 0.296273\n",
      "Train Epoch: 5 [39680/37879 (79%)]\tLoss: 0.200006\n",
      "Train Epoch: 5 [40320/37879 (81%)]\tLoss: 0.372903\n",
      "Train Epoch: 5 [40960/37879 (82%)]\tLoss: 0.187076\n",
      "Train Epoch: 5 [41600/37879 (83%)]\tLoss: 0.366833\n",
      "Train Epoch: 5 [42240/37879 (84%)]\tLoss: 0.229051\n",
      "Train Epoch: 5 [42880/37879 (86%)]\tLoss: 0.325494\n",
      "Train Epoch: 5 [43520/37879 (87%)]\tLoss: 0.277273\n",
      "Train Epoch: 5 [44160/37879 (88%)]\tLoss: 0.203606\n",
      "Train Epoch: 5 [44800/37879 (90%)]\tLoss: 0.395475\n",
      "Train Epoch: 5 [45440/37879 (91%)]\tLoss: 0.297687\n",
      "Train Epoch: 5 [46080/37879 (92%)]\tLoss: 0.322024\n",
      "Train Epoch: 5 [46720/37879 (93%)]\tLoss: 0.315601\n",
      "Train Epoch: 5 [47360/37879 (95%)]\tLoss: 0.163961\n",
      "Train Epoch: 5 [48000/37879 (96%)]\tLoss: 0.174768\n",
      "Train Epoch: 5 [48640/37879 (97%)]\tLoss: 0.174296\n",
      "Train Epoch: 5 [49280/37879 (98%)]\tLoss: 0.233916\n",
      "Train Epoch: 5 [49920/37879 (100%)]\tLoss: 0.166055\n",
      "\n",
      "Test set: Avg. loss: 0.0815, Accuracy: 9729/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/37879 (0%)]\tLoss: 0.186659\n",
      "Train Epoch: 6 [640/37879 (1%)]\tLoss: 0.187724\n",
      "Train Epoch: 6 [1280/37879 (3%)]\tLoss: 0.149635\n",
      "Train Epoch: 6 [1920/37879 (4%)]\tLoss: 0.377696\n",
      "Train Epoch: 6 [2560/37879 (5%)]\tLoss: 0.097357\n",
      "Train Epoch: 6 [3200/37879 (6%)]\tLoss: 0.186822\n",
      "Train Epoch: 6 [3840/37879 (8%)]\tLoss: 0.166933\n",
      "Train Epoch: 6 [4480/37879 (9%)]\tLoss: 0.193374\n",
      "Train Epoch: 6 [5120/37879 (10%)]\tLoss: 0.202513\n",
      "Train Epoch: 6 [5760/37879 (12%)]\tLoss: 0.474500\n",
      "Train Epoch: 6 [6400/37879 (13%)]\tLoss: 0.202574\n",
      "Train Epoch: 6 [7040/37879 (14%)]\tLoss: 0.189266\n",
      "Train Epoch: 6 [7680/37879 (15%)]\tLoss: 0.151767\n",
      "Train Epoch: 6 [8320/37879 (17%)]\tLoss: 0.486465\n",
      "Train Epoch: 6 [8960/37879 (18%)]\tLoss: 0.361094\n",
      "Train Epoch: 6 [9600/37879 (19%)]\tLoss: 0.236756\n",
      "Train Epoch: 6 [10240/37879 (20%)]\tLoss: 0.068774\n",
      "Train Epoch: 6 [10880/37879 (22%)]\tLoss: 0.388467\n",
      "Train Epoch: 6 [11520/37879 (23%)]\tLoss: 0.415673\n",
      "Train Epoch: 6 [12160/37879 (24%)]\tLoss: 0.230884\n",
      "Train Epoch: 6 [12800/37879 (26%)]\tLoss: 0.209424\n",
      "Train Epoch: 6 [13440/37879 (27%)]\tLoss: 0.438846\n",
      "Train Epoch: 6 [14080/37879 (28%)]\tLoss: 0.317425\n",
      "Train Epoch: 6 [14720/37879 (29%)]\tLoss: 0.236605\n",
      "Train Epoch: 6 [15360/37879 (31%)]\tLoss: 0.617771\n",
      "Train Epoch: 6 [16000/37879 (32%)]\tLoss: 0.359517\n",
      "Train Epoch: 6 [16640/37879 (33%)]\tLoss: 0.266359\n",
      "Train Epoch: 6 [17280/37879 (35%)]\tLoss: 0.200073\n",
      "Train Epoch: 6 [17920/37879 (36%)]\tLoss: 0.297917\n",
      "Train Epoch: 6 [18560/37879 (37%)]\tLoss: 0.300609\n",
      "Train Epoch: 6 [19200/37879 (38%)]\tLoss: 0.283271\n",
      "Train Epoch: 6 [19840/37879 (40%)]\tLoss: 0.453878\n",
      "Train Epoch: 6 [20480/37879 (41%)]\tLoss: 0.383739\n",
      "Train Epoch: 6 [21120/37879 (42%)]\tLoss: 0.144598\n",
      "Train Epoch: 6 [21760/37879 (43%)]\tLoss: 0.312308\n",
      "Train Epoch: 6 [22400/37879 (45%)]\tLoss: 0.590198\n",
      "Train Epoch: 6 [23040/37879 (46%)]\tLoss: 0.232221\n",
      "Train Epoch: 6 [23680/37879 (47%)]\tLoss: 0.248069\n",
      "Train Epoch: 6 [24320/37879 (49%)]\tLoss: 0.205056\n",
      "Train Epoch: 6 [24960/37879 (50%)]\tLoss: 0.329687\n",
      "Train Epoch: 6 [25600/37879 (51%)]\tLoss: 0.215292\n",
      "Train Epoch: 6 [26240/37879 (52%)]\tLoss: 0.228103\n",
      "Train Epoch: 6 [26880/37879 (54%)]\tLoss: 0.256680\n",
      "Train Epoch: 6 [27520/37879 (55%)]\tLoss: 0.341413\n",
      "Train Epoch: 6 [28160/37879 (56%)]\tLoss: 0.449495\n",
      "Train Epoch: 6 [28800/37879 (58%)]\tLoss: 0.233367\n",
      "Train Epoch: 6 [29440/37879 (59%)]\tLoss: 0.314338\n",
      "Train Epoch: 6 [30080/37879 (60%)]\tLoss: 0.211264\n",
      "Train Epoch: 6 [30720/37879 (61%)]\tLoss: 0.272679\n",
      "Train Epoch: 6 [31360/37879 (63%)]\tLoss: 0.295726\n",
      "Train Epoch: 6 [32000/37879 (64%)]\tLoss: 0.217127\n",
      "Train Epoch: 6 [32640/37879 (65%)]\tLoss: 0.172786\n",
      "Train Epoch: 6 [33280/37879 (66%)]\tLoss: 0.211672\n",
      "Train Epoch: 6 [33920/37879 (68%)]\tLoss: 0.355072\n",
      "Train Epoch: 6 [34560/37879 (69%)]\tLoss: 0.245666\n",
      "Train Epoch: 6 [35200/37879 (70%)]\tLoss: 0.268642\n",
      "Train Epoch: 6 [35840/37879 (72%)]\tLoss: 0.261449\n",
      "Train Epoch: 6 [36480/37879 (73%)]\tLoss: 0.341486\n",
      "Train Epoch: 6 [37120/37879 (74%)]\tLoss: 0.186388\n",
      "Train Epoch: 6 [37760/37879 (75%)]\tLoss: 0.450651\n",
      "Train Epoch: 6 [38400/37879 (77%)]\tLoss: 0.561247\n",
      "Train Epoch: 6 [39040/37879 (78%)]\tLoss: 0.398876\n",
      "Train Epoch: 6 [39680/37879 (79%)]\tLoss: 0.412657\n",
      "Train Epoch: 6 [40320/37879 (81%)]\tLoss: 0.573483\n",
      "Train Epoch: 6 [40960/37879 (82%)]\tLoss: 0.261952\n",
      "Train Epoch: 6 [41600/37879 (83%)]\tLoss: 0.262952\n",
      "Train Epoch: 6 [42240/37879 (84%)]\tLoss: 0.167682\n",
      "Train Epoch: 6 [42880/37879 (86%)]\tLoss: 0.300909\n",
      "Train Epoch: 6 [43520/37879 (87%)]\tLoss: 0.489120\n",
      "Train Epoch: 6 [44160/37879 (88%)]\tLoss: 0.252671\n",
      "Train Epoch: 6 [44800/37879 (90%)]\tLoss: 0.332739\n",
      "Train Epoch: 6 [45440/37879 (91%)]\tLoss: 0.213267\n",
      "Train Epoch: 6 [46080/37879 (92%)]\tLoss: 0.136275\n",
      "Train Epoch: 6 [46720/37879 (93%)]\tLoss: 0.315456\n",
      "Train Epoch: 6 [47360/37879 (95%)]\tLoss: 0.220558\n",
      "Train Epoch: 6 [48000/37879 (96%)]\tLoss: 0.265156\n",
      "Train Epoch: 6 [48640/37879 (97%)]\tLoss: 0.585876\n",
      "Train Epoch: 6 [49280/37879 (98%)]\tLoss: 0.122990\n",
      "Train Epoch: 6 [49920/37879 (100%)]\tLoss: 0.196629\n",
      "\n",
      "Test set: Avg. loss: 0.0759, Accuracy: 9755/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/37879 (0%)]\tLoss: 0.342157\n",
      "Train Epoch: 7 [640/37879 (1%)]\tLoss: 0.485044\n",
      "Train Epoch: 7 [1280/37879 (3%)]\tLoss: 0.267606\n",
      "Train Epoch: 7 [1920/37879 (4%)]\tLoss: 0.328119\n",
      "Train Epoch: 7 [2560/37879 (5%)]\tLoss: 0.468428\n",
      "Train Epoch: 7 [3200/37879 (6%)]\tLoss: 0.282324\n",
      "Train Epoch: 7 [3840/37879 (8%)]\tLoss: 0.319075\n",
      "Train Epoch: 7 [4480/37879 (9%)]\tLoss: 0.091157\n",
      "Train Epoch: 7 [5120/37879 (10%)]\tLoss: 0.169897\n",
      "Train Epoch: 7 [5760/37879 (12%)]\tLoss: 0.214954\n",
      "Train Epoch: 7 [6400/37879 (13%)]\tLoss: 0.381069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [7040/37879 (14%)]\tLoss: 0.273446\n",
      "Train Epoch: 7 [7680/37879 (15%)]\tLoss: 0.206114\n",
      "Train Epoch: 7 [8320/37879 (17%)]\tLoss: 0.297069\n",
      "Train Epoch: 7 [8960/37879 (18%)]\tLoss: 0.366327\n",
      "Train Epoch: 7 [9600/37879 (19%)]\tLoss: 0.273525\n",
      "Train Epoch: 7 [10240/37879 (20%)]\tLoss: 0.298552\n",
      "Train Epoch: 7 [10880/37879 (22%)]\tLoss: 0.282013\n",
      "Train Epoch: 7 [11520/37879 (23%)]\tLoss: 0.233892\n",
      "Train Epoch: 7 [12160/37879 (24%)]\tLoss: 0.345556\n",
      "Train Epoch: 7 [12800/37879 (26%)]\tLoss: 0.332070\n",
      "Train Epoch: 7 [13440/37879 (27%)]\tLoss: 0.176920\n",
      "Train Epoch: 7 [14080/37879 (28%)]\tLoss: 0.360984\n",
      "Train Epoch: 7 [14720/37879 (29%)]\tLoss: 0.212483\n",
      "Train Epoch: 7 [15360/37879 (31%)]\tLoss: 0.438720\n",
      "Train Epoch: 7 [16000/37879 (32%)]\tLoss: 0.261073\n",
      "Train Epoch: 7 [16640/37879 (33%)]\tLoss: 0.133976\n",
      "Train Epoch: 7 [17280/37879 (35%)]\tLoss: 0.393345\n",
      "Train Epoch: 7 [17920/37879 (36%)]\tLoss: 0.299019\n",
      "Train Epoch: 7 [18560/37879 (37%)]\tLoss: 0.252671\n",
      "Train Epoch: 7 [19200/37879 (38%)]\tLoss: 0.142167\n",
      "Train Epoch: 7 [19840/37879 (40%)]\tLoss: 0.289246\n",
      "Train Epoch: 7 [20480/37879 (41%)]\tLoss: 0.199382\n",
      "Train Epoch: 7 [21120/37879 (42%)]\tLoss: 0.181296\n",
      "Train Epoch: 7 [21760/37879 (43%)]\tLoss: 0.451992\n",
      "Train Epoch: 7 [22400/37879 (45%)]\tLoss: 0.207571\n",
      "Train Epoch: 7 [23040/37879 (46%)]\tLoss: 0.290197\n",
      "Train Epoch: 7 [23680/37879 (47%)]\tLoss: 0.215936\n",
      "Train Epoch: 7 [24320/37879 (49%)]\tLoss: 0.267001\n",
      "Train Epoch: 7 [24960/37879 (50%)]\tLoss: 0.220646\n",
      "Train Epoch: 7 [25600/37879 (51%)]\tLoss: 0.151026\n",
      "Train Epoch: 7 [26240/37879 (52%)]\tLoss: 0.200358\n",
      "Train Epoch: 7 [26880/37879 (54%)]\tLoss: 0.256296\n",
      "Train Epoch: 7 [27520/37879 (55%)]\tLoss: 0.194985\n",
      "Train Epoch: 7 [28160/37879 (56%)]\tLoss: 0.251419\n",
      "Train Epoch: 7 [28800/37879 (58%)]\tLoss: 0.464643\n",
      "Train Epoch: 7 [29440/37879 (59%)]\tLoss: 0.233160\n",
      "Train Epoch: 7 [30080/37879 (60%)]\tLoss: 0.148266\n",
      "Train Epoch: 7 [30720/37879 (61%)]\tLoss: 0.182421\n",
      "Train Epoch: 7 [31360/37879 (63%)]\tLoss: 0.267462\n",
      "Train Epoch: 7 [32000/37879 (64%)]\tLoss: 0.285350\n",
      "Train Epoch: 7 [32640/37879 (65%)]\tLoss: 0.291567\n",
      "Train Epoch: 7 [33280/37879 (66%)]\tLoss: 0.396527\n",
      "Train Epoch: 7 [33920/37879 (68%)]\tLoss: 0.251562\n",
      "Train Epoch: 7 [34560/37879 (69%)]\tLoss: 0.412017\n",
      "Train Epoch: 7 [35200/37879 (70%)]\tLoss: 0.244512\n",
      "Train Epoch: 7 [35840/37879 (72%)]\tLoss: 0.087452\n",
      "Train Epoch: 7 [36480/37879 (73%)]\tLoss: 0.236501\n",
      "Train Epoch: 7 [37120/37879 (74%)]\tLoss: 0.332710\n",
      "Train Epoch: 7 [37760/37879 (75%)]\tLoss: 0.309964\n",
      "Train Epoch: 7 [38400/37879 (77%)]\tLoss: 0.273165\n",
      "Train Epoch: 7 [39040/37879 (78%)]\tLoss: 0.395464\n",
      "Train Epoch: 7 [39680/37879 (79%)]\tLoss: 0.217183\n",
      "Train Epoch: 7 [40320/37879 (81%)]\tLoss: 0.258123\n",
      "Train Epoch: 7 [40960/37879 (82%)]\tLoss: 0.307075\n",
      "Train Epoch: 7 [41600/37879 (83%)]\tLoss: 0.106872\n",
      "Train Epoch: 7 [42240/37879 (84%)]\tLoss: 0.274767\n",
      "Train Epoch: 7 [42880/37879 (86%)]\tLoss: 0.366723\n",
      "Train Epoch: 7 [43520/37879 (87%)]\tLoss: 0.324575\n",
      "Train Epoch: 7 [44160/37879 (88%)]\tLoss: 0.436524\n",
      "Train Epoch: 7 [44800/37879 (90%)]\tLoss: 0.364255\n",
      "Train Epoch: 7 [45440/37879 (91%)]\tLoss: 0.208777\n",
      "Train Epoch: 7 [46080/37879 (92%)]\tLoss: 0.209455\n",
      "Train Epoch: 7 [46720/37879 (93%)]\tLoss: 0.291643\n",
      "Train Epoch: 7 [47360/37879 (95%)]\tLoss: 0.286406\n",
      "Train Epoch: 7 [48000/37879 (96%)]\tLoss: 0.212963\n",
      "Train Epoch: 7 [48640/37879 (97%)]\tLoss: 0.235154\n",
      "Train Epoch: 7 [49280/37879 (98%)]\tLoss: 0.314399\n",
      "Train Epoch: 7 [49920/37879 (100%)]\tLoss: 0.394729\n",
      "\n",
      "Test set: Avg. loss: 0.0723, Accuracy: 9774/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/37879 (0%)]\tLoss: 0.159162\n",
      "Train Epoch: 8 [640/37879 (1%)]\tLoss: 0.310963\n",
      "Train Epoch: 8 [1280/37879 (3%)]\tLoss: 0.168784\n",
      "Train Epoch: 8 [1920/37879 (4%)]\tLoss: 0.183732\n",
      "Train Epoch: 8 [2560/37879 (5%)]\tLoss: 0.260958\n",
      "Train Epoch: 8 [3200/37879 (6%)]\tLoss: 0.109575\n",
      "Train Epoch: 8 [3840/37879 (8%)]\tLoss: 0.181470\n",
      "Train Epoch: 8 [4480/37879 (9%)]\tLoss: 0.354508\n",
      "Train Epoch: 8 [5120/37879 (10%)]\tLoss: 0.177992\n",
      "Train Epoch: 8 [5760/37879 (12%)]\tLoss: 0.249760\n",
      "Train Epoch: 8 [6400/37879 (13%)]\tLoss: 0.255915\n",
      "Train Epoch: 8 [7040/37879 (14%)]\tLoss: 0.140660\n",
      "Train Epoch: 8 [7680/37879 (15%)]\tLoss: 0.195804\n",
      "Train Epoch: 8 [8320/37879 (17%)]\tLoss: 0.154223\n",
      "Train Epoch: 8 [8960/37879 (18%)]\tLoss: 0.231650\n",
      "Train Epoch: 8 [9600/37879 (19%)]\tLoss: 0.286118\n",
      "Train Epoch: 8 [10240/37879 (20%)]\tLoss: 0.186852\n",
      "Train Epoch: 8 [10880/37879 (22%)]\tLoss: 0.306318\n",
      "Train Epoch: 8 [11520/37879 (23%)]\tLoss: 0.208957\n",
      "Train Epoch: 8 [12160/37879 (24%)]\tLoss: 0.165975\n",
      "Train Epoch: 8 [12800/37879 (26%)]\tLoss: 0.621968\n",
      "Train Epoch: 8 [13440/37879 (27%)]\tLoss: 0.370131\n",
      "Train Epoch: 8 [14080/37879 (28%)]\tLoss: 0.285536\n",
      "Train Epoch: 8 [14720/37879 (29%)]\tLoss: 0.200447\n",
      "Train Epoch: 8 [15360/37879 (31%)]\tLoss: 0.191822\n",
      "Train Epoch: 8 [16000/37879 (32%)]\tLoss: 0.082606\n",
      "Train Epoch: 8 [16640/37879 (33%)]\tLoss: 0.257207\n",
      "Train Epoch: 8 [17280/37879 (35%)]\tLoss: 0.371874\n",
      "Train Epoch: 8 [17920/37879 (36%)]\tLoss: 0.266910\n",
      "Train Epoch: 8 [18560/37879 (37%)]\tLoss: 0.138478\n",
      "Train Epoch: 8 [19200/37879 (38%)]\tLoss: 0.217701\n",
      "Train Epoch: 8 [19840/37879 (40%)]\tLoss: 0.078802\n",
      "Train Epoch: 8 [20480/37879 (41%)]\tLoss: 0.242343\n",
      "Train Epoch: 8 [21120/37879 (42%)]\tLoss: 0.053496\n",
      "Train Epoch: 8 [21760/37879 (43%)]\tLoss: 0.333536\n",
      "Train Epoch: 8 [22400/37879 (45%)]\tLoss: 0.221386\n",
      "Train Epoch: 8 [23040/37879 (46%)]\tLoss: 0.323018\n",
      "Train Epoch: 8 [23680/37879 (47%)]\tLoss: 0.181040\n",
      "Train Epoch: 8 [24320/37879 (49%)]\tLoss: 0.285501\n",
      "Train Epoch: 8 [24960/37879 (50%)]\tLoss: 0.195249\n",
      "Train Epoch: 8 [25600/37879 (51%)]\tLoss: 0.131946\n",
      "Train Epoch: 8 [26240/37879 (52%)]\tLoss: 0.329488\n",
      "Train Epoch: 8 [26880/37879 (54%)]\tLoss: 0.231315\n",
      "Train Epoch: 8 [27520/37879 (55%)]\tLoss: 0.127805\n",
      "Train Epoch: 8 [28160/37879 (56%)]\tLoss: 0.210157\n",
      "Train Epoch: 8 [28800/37879 (58%)]\tLoss: 0.101371\n",
      "Train Epoch: 8 [29440/37879 (59%)]\tLoss: 0.302751\n",
      "Train Epoch: 8 [30080/37879 (60%)]\tLoss: 0.350754\n",
      "Train Epoch: 8 [30720/37879 (61%)]\tLoss: 0.263495\n",
      "Train Epoch: 8 [31360/37879 (63%)]\tLoss: 0.147917\n",
      "Train Epoch: 8 [32000/37879 (64%)]\tLoss: 0.280873\n",
      "Train Epoch: 8 [32640/37879 (65%)]\tLoss: 0.186414\n",
      "Train Epoch: 8 [33280/37879 (66%)]\tLoss: 0.326223\n",
      "Train Epoch: 8 [33920/37879 (68%)]\tLoss: 0.189756\n",
      "Train Epoch: 8 [34560/37879 (69%)]\tLoss: 0.153974\n",
      "Train Epoch: 8 [35200/37879 (70%)]\tLoss: 0.405232\n",
      "Train Epoch: 8 [35840/37879 (72%)]\tLoss: 0.218204\n",
      "Train Epoch: 8 [36480/37879 (73%)]\tLoss: 0.375885\n",
      "Train Epoch: 8 [37120/37879 (74%)]\tLoss: 0.182138\n",
      "Train Epoch: 8 [37760/37879 (75%)]\tLoss: 0.302671\n",
      "Train Epoch: 8 [38400/37879 (77%)]\tLoss: 0.242721\n",
      "Train Epoch: 8 [39040/37879 (78%)]\tLoss: 0.487501\n",
      "Train Epoch: 8 [39680/37879 (79%)]\tLoss: 0.169562\n",
      "Train Epoch: 8 [40320/37879 (81%)]\tLoss: 0.180418\n",
      "Train Epoch: 8 [40960/37879 (82%)]\tLoss: 0.331241\n",
      "Train Epoch: 8 [41600/37879 (83%)]\tLoss: 0.369221\n",
      "Train Epoch: 8 [42240/37879 (84%)]\tLoss: 0.397742\n",
      "Train Epoch: 8 [42880/37879 (86%)]\tLoss: 0.232374\n",
      "Train Epoch: 8 [43520/37879 (87%)]\tLoss: 0.425106\n",
      "Train Epoch: 8 [44160/37879 (88%)]\tLoss: 0.204357\n",
      "Train Epoch: 8 [44800/37879 (90%)]\tLoss: 0.251350\n",
      "Train Epoch: 8 [45440/37879 (91%)]\tLoss: 0.270356\n",
      "Train Epoch: 8 [46080/37879 (92%)]\tLoss: 0.296317\n",
      "Train Epoch: 8 [46720/37879 (93%)]\tLoss: 0.338603\n",
      "Train Epoch: 8 [47360/37879 (95%)]\tLoss: 0.338829\n",
      "Train Epoch: 8 [48000/37879 (96%)]\tLoss: 0.360375\n",
      "Train Epoch: 8 [48640/37879 (97%)]\tLoss: 0.154288\n",
      "Train Epoch: 8 [49280/37879 (98%)]\tLoss: 0.139731\n",
      "Train Epoch: 8 [49920/37879 (100%)]\tLoss: 0.207867\n",
      "\n",
      "Test set: Avg. loss: 0.0673, Accuracy: 9803/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/37879 (0%)]\tLoss: 0.161818\n",
      "Train Epoch: 9 [640/37879 (1%)]\tLoss: 0.192957\n",
      "Train Epoch: 9 [1280/37879 (3%)]\tLoss: 0.226229\n",
      "Train Epoch: 9 [1920/37879 (4%)]\tLoss: 0.214302\n",
      "Train Epoch: 9 [2560/37879 (5%)]\tLoss: 0.195430\n",
      "Train Epoch: 9 [3200/37879 (6%)]\tLoss: 0.217171\n",
      "Train Epoch: 9 [3840/37879 (8%)]\tLoss: 0.335803\n",
      "Train Epoch: 9 [4480/37879 (9%)]\tLoss: 0.395681\n",
      "Train Epoch: 9 [5120/37879 (10%)]\tLoss: 0.334669\n",
      "Train Epoch: 9 [5760/37879 (12%)]\tLoss: 0.234138\n",
      "Train Epoch: 9 [6400/37879 (13%)]\tLoss: 0.278102\n",
      "Train Epoch: 9 [7040/37879 (14%)]\tLoss: 0.271092\n",
      "Train Epoch: 9 [7680/37879 (15%)]\tLoss: 0.227838\n",
      "Train Epoch: 9 [8320/37879 (17%)]\tLoss: 0.411600\n",
      "Train Epoch: 9 [8960/37879 (18%)]\tLoss: 0.187468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [9600/37879 (19%)]\tLoss: 0.142216\n",
      "Train Epoch: 9 [10240/37879 (20%)]\tLoss: 0.170447\n",
      "Train Epoch: 9 [10880/37879 (22%)]\tLoss: 0.246322\n",
      "Train Epoch: 9 [11520/37879 (23%)]\tLoss: 0.265262\n",
      "Train Epoch: 9 [12160/37879 (24%)]\tLoss: 0.241593\n",
      "Train Epoch: 9 [12800/37879 (26%)]\tLoss: 0.308497\n",
      "Train Epoch: 9 [13440/37879 (27%)]\tLoss: 0.281892\n",
      "Train Epoch: 9 [14080/37879 (28%)]\tLoss: 0.201982\n",
      "Train Epoch: 9 [14720/37879 (29%)]\tLoss: 0.263902\n",
      "Train Epoch: 9 [15360/37879 (31%)]\tLoss: 0.108632\n",
      "Train Epoch: 9 [16000/37879 (32%)]\tLoss: 0.256043\n",
      "Train Epoch: 9 [16640/37879 (33%)]\tLoss: 0.263911\n",
      "Train Epoch: 9 [17280/37879 (35%)]\tLoss: 0.279121\n",
      "Train Epoch: 9 [17920/37879 (36%)]\tLoss: 0.369184\n",
      "Train Epoch: 9 [18560/37879 (37%)]\tLoss: 0.134470\n",
      "Train Epoch: 9 [19200/37879 (38%)]\tLoss: 0.390465\n",
      "Train Epoch: 9 [19840/37879 (40%)]\tLoss: 0.131105\n",
      "Train Epoch: 9 [20480/37879 (41%)]\tLoss: 0.747433\n",
      "Train Epoch: 9 [21120/37879 (42%)]\tLoss: 0.269343\n",
      "Train Epoch: 9 [21760/37879 (43%)]\tLoss: 0.295773\n",
      "Train Epoch: 9 [22400/37879 (45%)]\tLoss: 0.222812\n",
      "Train Epoch: 9 [23040/37879 (46%)]\tLoss: 0.171239\n",
      "Train Epoch: 9 [23680/37879 (47%)]\tLoss: 0.131919\n",
      "Train Epoch: 9 [24320/37879 (49%)]\tLoss: 0.174032\n",
      "Train Epoch: 9 [24960/37879 (50%)]\tLoss: 0.223437\n",
      "Train Epoch: 9 [25600/37879 (51%)]\tLoss: 0.188985\n",
      "Train Epoch: 9 [26240/37879 (52%)]\tLoss: 0.204254\n",
      "Train Epoch: 9 [26880/37879 (54%)]\tLoss: 0.241900\n",
      "Train Epoch: 9 [27520/37879 (55%)]\tLoss: 0.496777\n",
      "Train Epoch: 9 [28160/37879 (56%)]\tLoss: 0.480712\n",
      "Train Epoch: 9 [28800/37879 (58%)]\tLoss: 0.211283\n",
      "Train Epoch: 9 [29440/37879 (59%)]\tLoss: 0.179228\n",
      "Train Epoch: 9 [30080/37879 (60%)]\tLoss: 0.119375\n",
      "Train Epoch: 9 [30720/37879 (61%)]\tLoss: 0.338616\n",
      "Train Epoch: 9 [31360/37879 (63%)]\tLoss: 0.172600\n",
      "Train Epoch: 9 [32000/37879 (64%)]\tLoss: 0.154518\n",
      "Train Epoch: 9 [32640/37879 (65%)]\tLoss: 0.245573\n",
      "Train Epoch: 9 [33280/37879 (66%)]\tLoss: 0.199010\n",
      "Train Epoch: 9 [33920/37879 (68%)]\tLoss: 0.244257\n",
      "Train Epoch: 9 [34560/37879 (69%)]\tLoss: 0.133300\n",
      "Train Epoch: 9 [35200/37879 (70%)]\tLoss: 0.250535\n",
      "Train Epoch: 9 [35840/37879 (72%)]\tLoss: 0.239443\n",
      "Train Epoch: 9 [36480/37879 (73%)]\tLoss: 0.446427\n",
      "Train Epoch: 9 [37120/37879 (74%)]\tLoss: 0.342064\n",
      "Train Epoch: 9 [37760/37879 (75%)]\tLoss: 0.104763\n",
      "Train Epoch: 9 [38400/37879 (77%)]\tLoss: 0.174825\n",
      "Train Epoch: 9 [39040/37879 (78%)]\tLoss: 0.138284\n",
      "Train Epoch: 9 [39680/37879 (79%)]\tLoss: 0.224021\n",
      "Train Epoch: 9 [40320/37879 (81%)]\tLoss: 0.413370\n",
      "Train Epoch: 9 [40960/37879 (82%)]\tLoss: 0.226973\n",
      "Train Epoch: 9 [41600/37879 (83%)]\tLoss: 0.229438\n",
      "Train Epoch: 9 [42240/37879 (84%)]\tLoss: 0.280357\n",
      "Train Epoch: 9 [42880/37879 (86%)]\tLoss: 0.211447\n",
      "Train Epoch: 9 [43520/37879 (87%)]\tLoss: 0.255766\n",
      "Train Epoch: 9 [44160/37879 (88%)]\tLoss: 0.262504\n",
      "Train Epoch: 9 [44800/37879 (90%)]\tLoss: 0.236787\n",
      "Train Epoch: 9 [45440/37879 (91%)]\tLoss: 0.207327\n",
      "Train Epoch: 9 [46080/37879 (92%)]\tLoss: 0.234947\n",
      "Train Epoch: 9 [46720/37879 (93%)]\tLoss: 0.168964\n",
      "Train Epoch: 9 [47360/37879 (95%)]\tLoss: 0.191700\n",
      "Train Epoch: 9 [48000/37879 (96%)]\tLoss: 0.111433\n",
      "Train Epoch: 9 [48640/37879 (97%)]\tLoss: 0.168584\n",
      "Train Epoch: 9 [49280/37879 (98%)]\tLoss: 0.500412\n",
      "Train Epoch: 9 [49920/37879 (100%)]\tLoss: 0.312008\n",
      "\n",
      "Test set: Avg. loss: 0.0631, Accuracy: 9786/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/37879 (0%)]\tLoss: 0.209478\n",
      "Train Epoch: 10 [640/37879 (1%)]\tLoss: 0.113655\n",
      "Train Epoch: 10 [1280/37879 (3%)]\tLoss: 0.187355\n",
      "Train Epoch: 10 [1920/37879 (4%)]\tLoss: 0.278399\n",
      "Train Epoch: 10 [2560/37879 (5%)]\tLoss: 0.159266\n",
      "Train Epoch: 10 [3200/37879 (6%)]\tLoss: 0.197548\n",
      "Train Epoch: 10 [3840/37879 (8%)]\tLoss: 0.160913\n",
      "Train Epoch: 10 [4480/37879 (9%)]\tLoss: 0.289032\n",
      "Train Epoch: 10 [5120/37879 (10%)]\tLoss: 0.207106\n",
      "Train Epoch: 10 [5760/37879 (12%)]\tLoss: 0.198765\n",
      "Train Epoch: 10 [6400/37879 (13%)]\tLoss: 0.179640\n",
      "Train Epoch: 10 [7040/37879 (14%)]\tLoss: 0.385854\n",
      "Train Epoch: 10 [7680/37879 (15%)]\tLoss: 0.261024\n",
      "Train Epoch: 10 [8320/37879 (17%)]\tLoss: 0.155858\n",
      "Train Epoch: 10 [8960/37879 (18%)]\tLoss: 0.058463\n",
      "Train Epoch: 10 [9600/37879 (19%)]\tLoss: 0.494134\n",
      "Train Epoch: 10 [10240/37879 (20%)]\tLoss: 0.174009\n",
      "Train Epoch: 10 [10880/37879 (22%)]\tLoss: 0.094626\n",
      "Train Epoch: 10 [11520/37879 (23%)]\tLoss: 0.263854\n",
      "Train Epoch: 10 [12160/37879 (24%)]\tLoss: 0.189717\n",
      "Train Epoch: 10 [12800/37879 (26%)]\tLoss: 0.233037\n",
      "Train Epoch: 10 [13440/37879 (27%)]\tLoss: 0.176477\n",
      "Train Epoch: 10 [14080/37879 (28%)]\tLoss: 0.256150\n",
      "Train Epoch: 10 [14720/37879 (29%)]\tLoss: 0.076469\n",
      "Train Epoch: 10 [15360/37879 (31%)]\tLoss: 0.472576\n",
      "Train Epoch: 10 [16000/37879 (32%)]\tLoss: 0.105411\n",
      "Train Epoch: 10 [16640/37879 (33%)]\tLoss: 0.165868\n",
      "Train Epoch: 10 [17280/37879 (35%)]\tLoss: 0.148102\n",
      "Train Epoch: 10 [17920/37879 (36%)]\tLoss: 0.139282\n",
      "Train Epoch: 10 [18560/37879 (37%)]\tLoss: 0.154922\n",
      "Train Epoch: 10 [19200/37879 (38%)]\tLoss: 0.114502\n",
      "Train Epoch: 10 [19840/37879 (40%)]\tLoss: 0.131754\n",
      "Train Epoch: 10 [20480/37879 (41%)]\tLoss: 0.327782\n",
      "Train Epoch: 10 [21120/37879 (42%)]\tLoss: 0.226110\n",
      "Train Epoch: 10 [21760/37879 (43%)]\tLoss: 0.171092\n",
      "Train Epoch: 10 [22400/37879 (45%)]\tLoss: 0.325729\n",
      "Train Epoch: 10 [23040/37879 (46%)]\tLoss: 0.258532\n",
      "Train Epoch: 10 [23680/37879 (47%)]\tLoss: 0.195802\n",
      "Train Epoch: 10 [24320/37879 (49%)]\tLoss: 0.302472\n",
      "Train Epoch: 10 [24960/37879 (50%)]\tLoss: 0.274480\n",
      "Train Epoch: 10 [25600/37879 (51%)]\tLoss: 0.237217\n",
      "Train Epoch: 10 [26240/37879 (52%)]\tLoss: 0.427126\n",
      "Train Epoch: 10 [26880/37879 (54%)]\tLoss: 0.209375\n",
      "Train Epoch: 10 [27520/37879 (55%)]\tLoss: 0.104312\n",
      "Train Epoch: 10 [28160/37879 (56%)]\tLoss: 0.343887\n",
      "Train Epoch: 10 [28800/37879 (58%)]\tLoss: 0.172997\n",
      "Train Epoch: 10 [29440/37879 (59%)]\tLoss: 0.180943\n",
      "Train Epoch: 10 [30080/37879 (60%)]\tLoss: 0.200507\n",
      "Train Epoch: 10 [30720/37879 (61%)]\tLoss: 0.196562\n",
      "Train Epoch: 10 [31360/37879 (63%)]\tLoss: 0.237851\n",
      "Train Epoch: 10 [32000/37879 (64%)]\tLoss: 0.139347\n",
      "Train Epoch: 10 [32640/37879 (65%)]\tLoss: 0.149771\n",
      "Train Epoch: 10 [33280/37879 (66%)]\tLoss: 0.204767\n",
      "Train Epoch: 10 [33920/37879 (68%)]\tLoss: 0.174299\n",
      "Train Epoch: 10 [34560/37879 (69%)]\tLoss: 0.146169\n",
      "Train Epoch: 10 [35200/37879 (70%)]\tLoss: 0.315200\n",
      "Train Epoch: 10 [35840/37879 (72%)]\tLoss: 0.165015\n",
      "Train Epoch: 10 [36480/37879 (73%)]\tLoss: 0.366085\n",
      "Train Epoch: 10 [37120/37879 (74%)]\tLoss: 0.085891\n",
      "Train Epoch: 10 [37760/37879 (75%)]\tLoss: 0.307016\n",
      "Train Epoch: 10 [38400/37879 (77%)]\tLoss: 0.291162\n",
      "Train Epoch: 10 [39040/37879 (78%)]\tLoss: 0.219557\n",
      "Train Epoch: 10 [39680/37879 (79%)]\tLoss: 0.123572\n",
      "Train Epoch: 10 [40320/37879 (81%)]\tLoss: 0.205221\n",
      "Train Epoch: 10 [40960/37879 (82%)]\tLoss: 0.167052\n",
      "Train Epoch: 10 [41600/37879 (83%)]\tLoss: 0.187343\n",
      "Train Epoch: 10 [42240/37879 (84%)]\tLoss: 0.138874\n",
      "Train Epoch: 10 [42880/37879 (86%)]\tLoss: 0.175996\n",
      "Train Epoch: 10 [43520/37879 (87%)]\tLoss: 0.219434\n",
      "Train Epoch: 10 [44160/37879 (88%)]\tLoss: 0.221173\n",
      "Train Epoch: 10 [44800/37879 (90%)]\tLoss: 0.102505\n",
      "Train Epoch: 10 [45440/37879 (91%)]\tLoss: 0.258094\n",
      "Train Epoch: 10 [46080/37879 (92%)]\tLoss: 0.222635\n",
      "Train Epoch: 10 [46720/37879 (93%)]\tLoss: 0.701630\n",
      "Train Epoch: 10 [47360/37879 (95%)]\tLoss: 0.271109\n",
      "Train Epoch: 10 [48000/37879 (96%)]\tLoss: 0.372965\n",
      "Train Epoch: 10 [48640/37879 (97%)]\tLoss: 0.284426\n",
      "Train Epoch: 10 [49280/37879 (98%)]\tLoss: 0.136171\n",
      "Train Epoch: 10 [49920/37879 (100%)]\tLoss: 0.116977\n",
      "\n",
      "Test set: Avg. loss: 0.0624, Accuracy: 9801/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/37879 (0%)]\tLoss: 0.101740\n",
      "Train Epoch: 11 [640/37879 (1%)]\tLoss: 0.344222\n",
      "Train Epoch: 11 [1280/37879 (3%)]\tLoss: 0.301678\n",
      "Train Epoch: 11 [1920/37879 (4%)]\tLoss: 0.206639\n",
      "Train Epoch: 11 [2560/37879 (5%)]\tLoss: 0.392214\n",
      "Train Epoch: 11 [3200/37879 (6%)]\tLoss: 0.365442\n",
      "Train Epoch: 11 [3840/37879 (8%)]\tLoss: 0.171387\n",
      "Train Epoch: 11 [4480/37879 (9%)]\tLoss: 0.114606\n",
      "Train Epoch: 11 [5120/37879 (10%)]\tLoss: 0.324075\n",
      "Train Epoch: 11 [5760/37879 (12%)]\tLoss: 0.355985\n",
      "Train Epoch: 11 [6400/37879 (13%)]\tLoss: 0.262514\n",
      "Train Epoch: 11 [7040/37879 (14%)]\tLoss: 0.215512\n",
      "Train Epoch: 11 [7680/37879 (15%)]\tLoss: 0.228918\n",
      "Train Epoch: 11 [8320/37879 (17%)]\tLoss: 0.191123\n",
      "Train Epoch: 11 [8960/37879 (18%)]\tLoss: 0.380096\n",
      "Train Epoch: 11 [9600/37879 (19%)]\tLoss: 0.269380\n",
      "Train Epoch: 11 [10240/37879 (20%)]\tLoss: 0.292712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [10880/37879 (22%)]\tLoss: 0.153597\n",
      "Train Epoch: 11 [11520/37879 (23%)]\tLoss: 0.161577\n",
      "Train Epoch: 11 [12160/37879 (24%)]\tLoss: 0.168565\n",
      "Train Epoch: 11 [12800/37879 (26%)]\tLoss: 0.400573\n",
      "Train Epoch: 11 [13440/37879 (27%)]\tLoss: 0.144722\n",
      "Train Epoch: 11 [14080/37879 (28%)]\tLoss: 0.270342\n",
      "Train Epoch: 11 [14720/37879 (29%)]\tLoss: 0.113295\n",
      "Train Epoch: 11 [15360/37879 (31%)]\tLoss: 0.316513\n",
      "Train Epoch: 11 [16000/37879 (32%)]\tLoss: 0.230440\n",
      "Train Epoch: 11 [16640/37879 (33%)]\tLoss: 0.236460\n",
      "Train Epoch: 11 [17280/37879 (35%)]\tLoss: 0.150815\n",
      "Train Epoch: 11 [17920/37879 (36%)]\tLoss: 0.168678\n",
      "Train Epoch: 11 [18560/37879 (37%)]\tLoss: 0.116978\n",
      "Train Epoch: 11 [19200/37879 (38%)]\tLoss: 0.277536\n",
      "Train Epoch: 11 [19840/37879 (40%)]\tLoss: 0.211166\n",
      "Train Epoch: 11 [20480/37879 (41%)]\tLoss: 0.144264\n",
      "Train Epoch: 11 [21120/37879 (42%)]\tLoss: 0.197294\n",
      "Train Epoch: 11 [21760/37879 (43%)]\tLoss: 0.392857\n",
      "Train Epoch: 11 [22400/37879 (45%)]\tLoss: 0.283004\n",
      "Train Epoch: 11 [23040/37879 (46%)]\tLoss: 0.133411\n",
      "Train Epoch: 11 [23680/37879 (47%)]\tLoss: 0.094328\n",
      "Train Epoch: 11 [24320/37879 (49%)]\tLoss: 0.211842\n",
      "Train Epoch: 11 [24960/37879 (50%)]\tLoss: 0.201640\n",
      "Train Epoch: 11 [25600/37879 (51%)]\tLoss: 0.069123\n",
      "Train Epoch: 11 [26240/37879 (52%)]\tLoss: 0.202740\n",
      "Train Epoch: 11 [26880/37879 (54%)]\tLoss: 0.145320\n",
      "Train Epoch: 11 [27520/37879 (55%)]\tLoss: 0.078313\n",
      "Train Epoch: 11 [28160/37879 (56%)]\tLoss: 0.172423\n",
      "Train Epoch: 11 [28800/37879 (58%)]\tLoss: 0.224029\n",
      "Train Epoch: 11 [29440/37879 (59%)]\tLoss: 0.445575\n",
      "Train Epoch: 11 [30080/37879 (60%)]\tLoss: 0.469362\n",
      "Train Epoch: 11 [30720/37879 (61%)]\tLoss: 0.202016\n",
      "Train Epoch: 11 [31360/37879 (63%)]\tLoss: 0.427092\n",
      "Train Epoch: 11 [32000/37879 (64%)]\tLoss: 0.399960\n",
      "Train Epoch: 11 [32640/37879 (65%)]\tLoss: 0.209690\n",
      "Train Epoch: 11 [33280/37879 (66%)]\tLoss: 0.440776\n",
      "Train Epoch: 11 [33920/37879 (68%)]\tLoss: 0.532231\n",
      "Train Epoch: 11 [34560/37879 (69%)]\tLoss: 0.263063\n",
      "Train Epoch: 11 [35200/37879 (70%)]\tLoss: 0.142816\n",
      "Train Epoch: 11 [35840/37879 (72%)]\tLoss: 0.135196\n",
      "Train Epoch: 11 [36480/37879 (73%)]\tLoss: 0.427355\n",
      "Train Epoch: 11 [37120/37879 (74%)]\tLoss: 0.275572\n",
      "Train Epoch: 11 [37760/37879 (75%)]\tLoss: 0.263865\n",
      "Train Epoch: 11 [38400/37879 (77%)]\tLoss: 0.226831\n",
      "Train Epoch: 11 [39040/37879 (78%)]\tLoss: 0.240125\n",
      "Train Epoch: 11 [39680/37879 (79%)]\tLoss: 0.338752\n",
      "Train Epoch: 11 [40320/37879 (81%)]\tLoss: 0.234722\n",
      "Train Epoch: 11 [40960/37879 (82%)]\tLoss: 0.214606\n",
      "Train Epoch: 11 [41600/37879 (83%)]\tLoss: 0.131525\n",
      "Train Epoch: 11 [42240/37879 (84%)]\tLoss: 0.249674\n",
      "Train Epoch: 11 [42880/37879 (86%)]\tLoss: 0.164757\n",
      "Train Epoch: 11 [43520/37879 (87%)]\tLoss: 0.161912\n",
      "Train Epoch: 11 [44160/37879 (88%)]\tLoss: 0.166118\n",
      "Train Epoch: 11 [44800/37879 (90%)]\tLoss: 0.282737\n",
      "Train Epoch: 11 [45440/37879 (91%)]\tLoss: 0.315789\n",
      "Train Epoch: 11 [46080/37879 (92%)]\tLoss: 0.158926\n",
      "Train Epoch: 11 [46720/37879 (93%)]\tLoss: 0.138420\n",
      "Train Epoch: 11 [47360/37879 (95%)]\tLoss: 0.281116\n",
      "Train Epoch: 11 [48000/37879 (96%)]\tLoss: 0.155906\n",
      "Train Epoch: 11 [48640/37879 (97%)]\tLoss: 0.257827\n",
      "Train Epoch: 11 [49280/37879 (98%)]\tLoss: 0.123024\n",
      "Train Epoch: 11 [49920/37879 (100%)]\tLoss: 0.154452\n",
      "\n",
      "Test set: Avg. loss: 0.0564, Accuracy: 9813/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/37879 (0%)]\tLoss: 0.220104\n",
      "Train Epoch: 12 [640/37879 (1%)]\tLoss: 0.143530\n",
      "Train Epoch: 12 [1280/37879 (3%)]\tLoss: 0.205962\n",
      "Train Epoch: 12 [1920/37879 (4%)]\tLoss: 0.172616\n",
      "Train Epoch: 12 [2560/37879 (5%)]\tLoss: 0.138840\n",
      "Train Epoch: 12 [3200/37879 (6%)]\tLoss: 0.340869\n",
      "Train Epoch: 12 [3840/37879 (8%)]\tLoss: 0.351179\n",
      "Train Epoch: 12 [4480/37879 (9%)]\tLoss: 0.216370\n",
      "Train Epoch: 12 [5120/37879 (10%)]\tLoss: 0.279520\n",
      "Train Epoch: 12 [5760/37879 (12%)]\tLoss: 0.168860\n",
      "Train Epoch: 12 [6400/37879 (13%)]\tLoss: 0.214416\n",
      "Train Epoch: 12 [7040/37879 (14%)]\tLoss: 0.154288\n",
      "Train Epoch: 12 [7680/37879 (15%)]\tLoss: 0.311977\n",
      "Train Epoch: 12 [8320/37879 (17%)]\tLoss: 0.352441\n",
      "Train Epoch: 12 [8960/37879 (18%)]\tLoss: 0.334327\n",
      "Train Epoch: 12 [9600/37879 (19%)]\tLoss: 0.172943\n",
      "Train Epoch: 12 [10240/37879 (20%)]\tLoss: 0.150629\n",
      "Train Epoch: 12 [10880/37879 (22%)]\tLoss: 0.318039\n",
      "Train Epoch: 12 [11520/37879 (23%)]\tLoss: 0.256263\n",
      "Train Epoch: 12 [12160/37879 (24%)]\tLoss: 0.176116\n",
      "Train Epoch: 12 [12800/37879 (26%)]\tLoss: 0.273088\n",
      "Train Epoch: 12 [13440/37879 (27%)]\tLoss: 0.155064\n",
      "Train Epoch: 12 [14080/37879 (28%)]\tLoss: 0.121143\n",
      "Train Epoch: 12 [14720/37879 (29%)]\tLoss: 0.108289\n",
      "Train Epoch: 12 [15360/37879 (31%)]\tLoss: 0.223665\n",
      "Train Epoch: 12 [16000/37879 (32%)]\tLoss: 0.081331\n",
      "Train Epoch: 12 [16640/37879 (33%)]\tLoss: 0.178557\n",
      "Train Epoch: 12 [17280/37879 (35%)]\tLoss: 0.233073\n",
      "Train Epoch: 12 [17920/37879 (36%)]\tLoss: 0.382220\n",
      "Train Epoch: 12 [18560/37879 (37%)]\tLoss: 0.207892\n",
      "Train Epoch: 12 [19200/37879 (38%)]\tLoss: 0.151621\n",
      "Train Epoch: 12 [19840/37879 (40%)]\tLoss: 0.330200\n",
      "Train Epoch: 12 [20480/37879 (41%)]\tLoss: 0.269035\n",
      "Train Epoch: 12 [21120/37879 (42%)]\tLoss: 0.209180\n",
      "Train Epoch: 12 [21760/37879 (43%)]\tLoss: 0.123402\n",
      "Train Epoch: 12 [22400/37879 (45%)]\tLoss: 0.228945\n",
      "Train Epoch: 12 [23040/37879 (46%)]\tLoss: 0.085137\n",
      "Train Epoch: 12 [23680/37879 (47%)]\tLoss: 0.251818\n",
      "Train Epoch: 12 [24320/37879 (49%)]\tLoss: 0.212787\n",
      "Train Epoch: 12 [24960/37879 (50%)]\tLoss: 0.195326\n",
      "Train Epoch: 12 [25600/37879 (51%)]\tLoss: 0.187260\n",
      "Train Epoch: 12 [26240/37879 (52%)]\tLoss: 0.266686\n",
      "Train Epoch: 12 [26880/37879 (54%)]\tLoss: 0.527370\n",
      "Train Epoch: 12 [27520/37879 (55%)]\tLoss: 0.215346\n",
      "Train Epoch: 12 [28160/37879 (56%)]\tLoss: 0.110665\n",
      "Train Epoch: 12 [28800/37879 (58%)]\tLoss: 0.441420\n",
      "Train Epoch: 12 [29440/37879 (59%)]\tLoss: 0.337193\n",
      "Train Epoch: 12 [30080/37879 (60%)]\tLoss: 0.235720\n",
      "Train Epoch: 12 [30720/37879 (61%)]\tLoss: 0.287736\n",
      "Train Epoch: 12 [31360/37879 (63%)]\tLoss: 0.165910\n",
      "Train Epoch: 12 [32000/37879 (64%)]\tLoss: 0.240271\n",
      "Train Epoch: 12 [32640/37879 (65%)]\tLoss: 0.208482\n",
      "Train Epoch: 12 [33280/37879 (66%)]\tLoss: 0.219018\n",
      "Train Epoch: 12 [33920/37879 (68%)]\tLoss: 0.219382\n",
      "Train Epoch: 12 [34560/37879 (69%)]\tLoss: 0.187132\n",
      "Train Epoch: 12 [35200/37879 (70%)]\tLoss: 0.199324\n",
      "Train Epoch: 12 [35840/37879 (72%)]\tLoss: 0.330297\n",
      "Train Epoch: 12 [36480/37879 (73%)]\tLoss: 0.266345\n",
      "Train Epoch: 12 [37120/37879 (74%)]\tLoss: 0.299264\n",
      "Train Epoch: 12 [37760/37879 (75%)]\tLoss: 0.188577\n",
      "Train Epoch: 12 [38400/37879 (77%)]\tLoss: 0.218407\n",
      "Train Epoch: 12 [39040/37879 (78%)]\tLoss: 0.175898\n",
      "Train Epoch: 12 [39680/37879 (79%)]\tLoss: 0.171710\n",
      "Train Epoch: 12 [40320/37879 (81%)]\tLoss: 0.140107\n",
      "Train Epoch: 12 [40960/37879 (82%)]\tLoss: 0.270309\n",
      "Train Epoch: 12 [41600/37879 (83%)]\tLoss: 0.302860\n",
      "Train Epoch: 12 [42240/37879 (84%)]\tLoss: 0.147112\n",
      "Train Epoch: 12 [42880/37879 (86%)]\tLoss: 0.195227\n",
      "Train Epoch: 12 [43520/37879 (87%)]\tLoss: 0.500871\n",
      "Train Epoch: 12 [44160/37879 (88%)]\tLoss: 0.230408\n",
      "Train Epoch: 12 [44800/37879 (90%)]\tLoss: 0.293319\n",
      "Train Epoch: 12 [45440/37879 (91%)]\tLoss: 0.219824\n",
      "Train Epoch: 12 [46080/37879 (92%)]\tLoss: 0.138736\n",
      "Train Epoch: 12 [46720/37879 (93%)]\tLoss: 0.344597\n",
      "Train Epoch: 12 [47360/37879 (95%)]\tLoss: 0.228182\n",
      "Train Epoch: 12 [48000/37879 (96%)]\tLoss: 0.309042\n",
      "Train Epoch: 12 [48640/37879 (97%)]\tLoss: 0.264037\n",
      "Train Epoch: 12 [49280/37879 (98%)]\tLoss: 0.443968\n",
      "Train Epoch: 12 [49920/37879 (100%)]\tLoss: 0.255579\n",
      "\n",
      "Test set: Avg. loss: 0.0572, Accuracy: 9809/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/37879 (0%)]\tLoss: 0.111426\n",
      "Train Epoch: 13 [640/37879 (1%)]\tLoss: 0.410547\n",
      "Train Epoch: 13 [1280/37879 (3%)]\tLoss: 0.187040\n",
      "Train Epoch: 13 [1920/37879 (4%)]\tLoss: 0.248458\n",
      "Train Epoch: 13 [2560/37879 (5%)]\tLoss: 0.323879\n",
      "Train Epoch: 13 [3200/37879 (6%)]\tLoss: 0.166300\n",
      "Train Epoch: 13 [3840/37879 (8%)]\tLoss: 0.049097\n",
      "Train Epoch: 13 [4480/37879 (9%)]\tLoss: 0.164814\n",
      "Train Epoch: 13 [5120/37879 (10%)]\tLoss: 0.267522\n",
      "Train Epoch: 13 [5760/37879 (12%)]\tLoss: 0.348345\n",
      "Train Epoch: 13 [6400/37879 (13%)]\tLoss: 0.125365\n",
      "Train Epoch: 13 [7040/37879 (14%)]\tLoss: 0.254398\n",
      "Train Epoch: 13 [7680/37879 (15%)]\tLoss: 0.122407\n",
      "Train Epoch: 13 [8320/37879 (17%)]\tLoss: 0.204851\n",
      "Train Epoch: 13 [8960/37879 (18%)]\tLoss: 0.150972\n",
      "Train Epoch: 13 [9600/37879 (19%)]\tLoss: 0.242858\n",
      "Train Epoch: 13 [10240/37879 (20%)]\tLoss: 0.191332\n",
      "Train Epoch: 13 [10880/37879 (22%)]\tLoss: 0.219474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [11520/37879 (23%)]\tLoss: 0.093392\n",
      "Train Epoch: 13 [12160/37879 (24%)]\tLoss: 0.181543\n",
      "Train Epoch: 13 [12800/37879 (26%)]\tLoss: 0.223915\n",
      "Train Epoch: 13 [13440/37879 (27%)]\tLoss: 0.311262\n",
      "Train Epoch: 13 [14080/37879 (28%)]\tLoss: 0.185559\n",
      "Train Epoch: 13 [14720/37879 (29%)]\tLoss: 0.209761\n",
      "Train Epoch: 13 [15360/37879 (31%)]\tLoss: 0.167039\n",
      "Train Epoch: 13 [16000/37879 (32%)]\tLoss: 0.103038\n",
      "Train Epoch: 13 [16640/37879 (33%)]\tLoss: 0.222976\n",
      "Train Epoch: 13 [17280/37879 (35%)]\tLoss: 0.345512\n",
      "Train Epoch: 13 [17920/37879 (36%)]\tLoss: 0.105224\n",
      "Train Epoch: 13 [18560/37879 (37%)]\tLoss: 0.228157\n",
      "Train Epoch: 13 [19200/37879 (38%)]\tLoss: 0.422972\n",
      "Train Epoch: 13 [19840/37879 (40%)]\tLoss: 0.176672\n",
      "Train Epoch: 13 [20480/37879 (41%)]\tLoss: 0.314181\n",
      "Train Epoch: 13 [21120/37879 (42%)]\tLoss: 0.213880\n",
      "Train Epoch: 13 [21760/37879 (43%)]\tLoss: 0.125816\n",
      "Train Epoch: 13 [22400/37879 (45%)]\tLoss: 0.143862\n",
      "Train Epoch: 13 [23040/37879 (46%)]\tLoss: 0.047761\n",
      "Train Epoch: 13 [23680/37879 (47%)]\tLoss: 0.087610\n",
      "Train Epoch: 13 [24320/37879 (49%)]\tLoss: 0.193789\n",
      "Train Epoch: 13 [24960/37879 (50%)]\tLoss: 0.260176\n",
      "Train Epoch: 13 [25600/37879 (51%)]\tLoss: 0.156042\n",
      "Train Epoch: 13 [26240/37879 (52%)]\tLoss: 0.271651\n",
      "Train Epoch: 13 [26880/37879 (54%)]\tLoss: 0.231517\n",
      "Train Epoch: 13 [27520/37879 (55%)]\tLoss: 0.205945\n",
      "Train Epoch: 13 [28160/37879 (56%)]\tLoss: 0.180954\n",
      "Train Epoch: 13 [28800/37879 (58%)]\tLoss: 0.096578\n",
      "Train Epoch: 13 [29440/37879 (59%)]\tLoss: 0.167631\n",
      "Train Epoch: 13 [30080/37879 (60%)]\tLoss: 0.186242\n",
      "Train Epoch: 13 [30720/37879 (61%)]\tLoss: 0.109238\n",
      "Train Epoch: 13 [31360/37879 (63%)]\tLoss: 0.235363\n",
      "Train Epoch: 13 [32000/37879 (64%)]\tLoss: 0.150134\n",
      "Train Epoch: 13 [32640/37879 (65%)]\tLoss: 0.206196\n",
      "Train Epoch: 13 [33280/37879 (66%)]\tLoss: 0.237068\n",
      "Train Epoch: 13 [33920/37879 (68%)]\tLoss: 0.229101\n",
      "Train Epoch: 13 [34560/37879 (69%)]\tLoss: 0.160122\n",
      "Train Epoch: 13 [35200/37879 (70%)]\tLoss: 0.178665\n",
      "Train Epoch: 13 [35840/37879 (72%)]\tLoss: 0.142355\n",
      "Train Epoch: 13 [36480/37879 (73%)]\tLoss: 0.478147\n",
      "Train Epoch: 13 [37120/37879 (74%)]\tLoss: 0.356398\n",
      "Train Epoch: 13 [37760/37879 (75%)]\tLoss: 0.314244\n",
      "Train Epoch: 13 [38400/37879 (77%)]\tLoss: 0.092968\n",
      "Train Epoch: 13 [39040/37879 (78%)]\tLoss: 0.129218\n",
      "Train Epoch: 13 [39680/37879 (79%)]\tLoss: 0.188489\n",
      "Train Epoch: 13 [40320/37879 (81%)]\tLoss: 0.224645\n",
      "Train Epoch: 13 [40960/37879 (82%)]\tLoss: 0.188168\n",
      "Train Epoch: 13 [41600/37879 (83%)]\tLoss: 0.169245\n",
      "Train Epoch: 13 [42240/37879 (84%)]\tLoss: 0.215049\n",
      "Train Epoch: 13 [42880/37879 (86%)]\tLoss: 0.259252\n",
      "Train Epoch: 13 [43520/37879 (87%)]\tLoss: 0.162288\n",
      "Train Epoch: 13 [44160/37879 (88%)]\tLoss: 0.307160\n",
      "Train Epoch: 13 [44800/37879 (90%)]\tLoss: 0.164896\n",
      "Train Epoch: 13 [45440/37879 (91%)]\tLoss: 0.203474\n",
      "Train Epoch: 13 [46080/37879 (92%)]\tLoss: 0.357228\n",
      "Train Epoch: 13 [46720/37879 (93%)]\tLoss: 0.092632\n",
      "Train Epoch: 13 [47360/37879 (95%)]\tLoss: 0.175765\n",
      "Train Epoch: 13 [48000/37879 (96%)]\tLoss: 0.102251\n",
      "Train Epoch: 13 [48640/37879 (97%)]\tLoss: 0.062773\n",
      "Train Epoch: 13 [49280/37879 (98%)]\tLoss: 0.140580\n",
      "Train Epoch: 13 [49920/37879 (100%)]\tLoss: 0.215478\n",
      "\n",
      "Test set: Avg. loss: 0.0542, Accuracy: 9829/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/37879 (0%)]\tLoss: 0.308390\n",
      "Train Epoch: 14 [640/37879 (1%)]\tLoss: 0.153168\n",
      "Train Epoch: 14 [1280/37879 (3%)]\tLoss: 0.179630\n",
      "Train Epoch: 14 [1920/37879 (4%)]\tLoss: 0.079639\n",
      "Train Epoch: 14 [2560/37879 (5%)]\tLoss: 0.201026\n",
      "Train Epoch: 14 [3200/37879 (6%)]\tLoss: 0.161911\n",
      "Train Epoch: 14 [3840/37879 (8%)]\tLoss: 0.181419\n",
      "Train Epoch: 14 [4480/37879 (9%)]\tLoss: 0.070815\n",
      "Train Epoch: 14 [5120/37879 (10%)]\tLoss: 0.244357\n",
      "Train Epoch: 14 [5760/37879 (12%)]\tLoss: 0.313041\n",
      "Train Epoch: 14 [6400/37879 (13%)]\tLoss: 0.209477\n",
      "Train Epoch: 14 [7040/37879 (14%)]\tLoss: 0.178590\n",
      "Train Epoch: 14 [7680/37879 (15%)]\tLoss: 0.235684\n",
      "Train Epoch: 14 [8320/37879 (17%)]\tLoss: 0.226678\n",
      "Train Epoch: 14 [8960/37879 (18%)]\tLoss: 0.241507\n",
      "Train Epoch: 14 [9600/37879 (19%)]\tLoss: 0.310349\n",
      "Train Epoch: 14 [10240/37879 (20%)]\tLoss: 0.320957\n",
      "Train Epoch: 14 [10880/37879 (22%)]\tLoss: 0.156160\n",
      "Train Epoch: 14 [11520/37879 (23%)]\tLoss: 0.233237\n",
      "Train Epoch: 14 [12160/37879 (24%)]\tLoss: 0.351447\n",
      "Train Epoch: 14 [12800/37879 (26%)]\tLoss: 0.131497\n",
      "Train Epoch: 14 [13440/37879 (27%)]\tLoss: 0.253156\n",
      "Train Epoch: 14 [14080/37879 (28%)]\tLoss: 0.240626\n",
      "Train Epoch: 14 [14720/37879 (29%)]\tLoss: 0.092630\n",
      "Train Epoch: 14 [15360/37879 (31%)]\tLoss: 0.210907\n",
      "Train Epoch: 14 [16000/37879 (32%)]\tLoss: 0.155735\n",
      "Train Epoch: 14 [16640/37879 (33%)]\tLoss: 0.155705\n",
      "Train Epoch: 14 [17280/37879 (35%)]\tLoss: 0.307971\n",
      "Train Epoch: 14 [17920/37879 (36%)]\tLoss: 0.234364\n",
      "Train Epoch: 14 [18560/37879 (37%)]\tLoss: 0.089916\n",
      "Train Epoch: 14 [19200/37879 (38%)]\tLoss: 0.164069\n",
      "Train Epoch: 14 [19840/37879 (40%)]\tLoss: 0.256664\n",
      "Train Epoch: 14 [20480/37879 (41%)]\tLoss: 0.211348\n",
      "Train Epoch: 14 [21120/37879 (42%)]\tLoss: 0.168566\n",
      "Train Epoch: 14 [21760/37879 (43%)]\tLoss: 0.181915\n",
      "Train Epoch: 14 [22400/37879 (45%)]\tLoss: 0.255182\n",
      "Train Epoch: 14 [23040/37879 (46%)]\tLoss: 0.209592\n",
      "Train Epoch: 14 [23680/37879 (47%)]\tLoss: 0.124789\n",
      "Train Epoch: 14 [24320/37879 (49%)]\tLoss: 0.429614\n",
      "Train Epoch: 14 [24960/37879 (50%)]\tLoss: 0.376633\n",
      "Train Epoch: 14 [25600/37879 (51%)]\tLoss: 0.329867\n",
      "Train Epoch: 14 [26240/37879 (52%)]\tLoss: 0.254474\n",
      "Train Epoch: 14 [26880/37879 (54%)]\tLoss: 0.191314\n",
      "Train Epoch: 14 [27520/37879 (55%)]\tLoss: 0.339535\n",
      "Train Epoch: 14 [28160/37879 (56%)]\tLoss: 0.168724\n",
      "Train Epoch: 14 [28800/37879 (58%)]\tLoss: 0.258222\n",
      "Train Epoch: 14 [29440/37879 (59%)]\tLoss: 0.210179\n",
      "Train Epoch: 14 [30080/37879 (60%)]\tLoss: 0.115574\n",
      "Train Epoch: 14 [30720/37879 (61%)]\tLoss: 0.206627\n",
      "Train Epoch: 14 [31360/37879 (63%)]\tLoss: 0.160024\n",
      "Train Epoch: 14 [32000/37879 (64%)]\tLoss: 0.066349\n",
      "Train Epoch: 14 [32640/37879 (65%)]\tLoss: 0.249705\n",
      "Train Epoch: 14 [33280/37879 (66%)]\tLoss: 0.135963\n",
      "Train Epoch: 14 [33920/37879 (68%)]\tLoss: 0.236596\n",
      "Train Epoch: 14 [34560/37879 (69%)]\tLoss: 0.201836\n",
      "Train Epoch: 14 [35200/37879 (70%)]\tLoss: 0.255181\n",
      "Train Epoch: 14 [35840/37879 (72%)]\tLoss: 0.109847\n",
      "Train Epoch: 14 [36480/37879 (73%)]\tLoss: 0.230068\n",
      "Train Epoch: 14 [37120/37879 (74%)]\tLoss: 0.114552\n",
      "Train Epoch: 14 [37760/37879 (75%)]\tLoss: 0.152895\n",
      "Train Epoch: 14 [38400/37879 (77%)]\tLoss: 0.263215\n",
      "Train Epoch: 14 [39040/37879 (78%)]\tLoss: 0.286422\n",
      "Train Epoch: 14 [39680/37879 (79%)]\tLoss: 0.175521\n",
      "Train Epoch: 14 [40320/37879 (81%)]\tLoss: 0.047819\n",
      "Train Epoch: 14 [40960/37879 (82%)]\tLoss: 0.237376\n",
      "Train Epoch: 14 [41600/37879 (83%)]\tLoss: 0.105933\n",
      "Train Epoch: 14 [42240/37879 (84%)]\tLoss: 0.259897\n",
      "Train Epoch: 14 [42880/37879 (86%)]\tLoss: 0.253470\n",
      "Train Epoch: 14 [43520/37879 (87%)]\tLoss: 0.275955\n",
      "Train Epoch: 14 [44160/37879 (88%)]\tLoss: 0.177070\n",
      "Train Epoch: 14 [44800/37879 (90%)]\tLoss: 0.251875\n",
      "Train Epoch: 14 [45440/37879 (91%)]\tLoss: 0.178538\n",
      "Train Epoch: 14 [46080/37879 (92%)]\tLoss: 0.270954\n",
      "Train Epoch: 14 [46720/37879 (93%)]\tLoss: 0.101927\n",
      "Train Epoch: 14 [47360/37879 (95%)]\tLoss: 0.096259\n",
      "Train Epoch: 14 [48000/37879 (96%)]\tLoss: 0.082843\n",
      "Train Epoch: 14 [48640/37879 (97%)]\tLoss: 0.303734\n",
      "Train Epoch: 14 [49280/37879 (98%)]\tLoss: 0.396299\n",
      "Train Epoch: 14 [49920/37879 (100%)]\tLoss: 0.192312\n",
      "\n",
      "Test set: Avg. loss: 0.0494, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/37879 (0%)]\tLoss: 0.071820\n",
      "Train Epoch: 15 [640/37879 (1%)]\tLoss: 0.285239\n",
      "Train Epoch: 15 [1280/37879 (3%)]\tLoss: 0.101236\n",
      "Train Epoch: 15 [1920/37879 (4%)]\tLoss: 0.190146\n",
      "Train Epoch: 15 [2560/37879 (5%)]\tLoss: 0.139618\n",
      "Train Epoch: 15 [3200/37879 (6%)]\tLoss: 0.256766\n",
      "Train Epoch: 15 [3840/37879 (8%)]\tLoss: 0.281436\n",
      "Train Epoch: 15 [4480/37879 (9%)]\tLoss: 0.208924\n",
      "Train Epoch: 15 [5120/37879 (10%)]\tLoss: 0.101212\n",
      "Train Epoch: 15 [5760/37879 (12%)]\tLoss: 0.198547\n",
      "Train Epoch: 15 [6400/37879 (13%)]\tLoss: 0.172798\n",
      "Train Epoch: 15 [7040/37879 (14%)]\tLoss: 0.186570\n",
      "Train Epoch: 15 [7680/37879 (15%)]\tLoss: 0.098077\n",
      "Train Epoch: 15 [8320/37879 (17%)]\tLoss: 0.193815\n",
      "Train Epoch: 15 [8960/37879 (18%)]\tLoss: 0.222747\n",
      "Train Epoch: 15 [9600/37879 (19%)]\tLoss: 0.175971\n",
      "Train Epoch: 15 [10240/37879 (20%)]\tLoss: 0.084300\n",
      "Train Epoch: 15 [10880/37879 (22%)]\tLoss: 0.221448\n",
      "Train Epoch: 15 [11520/37879 (23%)]\tLoss: 0.260722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [12160/37879 (24%)]\tLoss: 0.230475\n",
      "Train Epoch: 15 [12800/37879 (26%)]\tLoss: 0.238962\n",
      "Train Epoch: 15 [13440/37879 (27%)]\tLoss: 0.165810\n",
      "Train Epoch: 15 [14080/37879 (28%)]\tLoss: 0.167215\n",
      "Train Epoch: 15 [14720/37879 (29%)]\tLoss: 0.369741\n",
      "Train Epoch: 15 [15360/37879 (31%)]\tLoss: 0.084847\n",
      "Train Epoch: 15 [16000/37879 (32%)]\tLoss: 0.159940\n",
      "Train Epoch: 15 [16640/37879 (33%)]\tLoss: 0.319172\n",
      "Train Epoch: 15 [17280/37879 (35%)]\tLoss: 0.122352\n",
      "Train Epoch: 15 [17920/37879 (36%)]\tLoss: 0.226729\n",
      "Train Epoch: 15 [18560/37879 (37%)]\tLoss: 0.208260\n",
      "Train Epoch: 15 [19200/37879 (38%)]\tLoss: 0.292094\n",
      "Train Epoch: 15 [19840/37879 (40%)]\tLoss: 0.233768\n",
      "Train Epoch: 15 [20480/37879 (41%)]\tLoss: 0.295971\n",
      "Train Epoch: 15 [21120/37879 (42%)]\tLoss: 0.246613\n",
      "Train Epoch: 15 [21760/37879 (43%)]\tLoss: 0.186899\n",
      "Train Epoch: 15 [22400/37879 (45%)]\tLoss: 0.223548\n",
      "Train Epoch: 15 [23040/37879 (46%)]\tLoss: 0.163175\n",
      "Train Epoch: 15 [23680/37879 (47%)]\tLoss: 0.151563\n",
      "Train Epoch: 15 [24320/37879 (49%)]\tLoss: 0.150420\n",
      "Train Epoch: 15 [24960/37879 (50%)]\tLoss: 0.363847\n",
      "Train Epoch: 15 [25600/37879 (51%)]\tLoss: 0.091606\n",
      "Train Epoch: 15 [26240/37879 (52%)]\tLoss: 0.102872\n",
      "Train Epoch: 15 [26880/37879 (54%)]\tLoss: 0.163702\n",
      "Train Epoch: 15 [27520/37879 (55%)]\tLoss: 0.098548\n",
      "Train Epoch: 15 [28160/37879 (56%)]\tLoss: 0.383779\n",
      "Train Epoch: 15 [28800/37879 (58%)]\tLoss: 0.102327\n",
      "Train Epoch: 15 [29440/37879 (59%)]\tLoss: 0.136392\n",
      "Train Epoch: 15 [30080/37879 (60%)]\tLoss: 0.158760\n",
      "Train Epoch: 15 [30720/37879 (61%)]\tLoss: 0.313443\n",
      "Train Epoch: 15 [31360/37879 (63%)]\tLoss: 0.152411\n",
      "Train Epoch: 15 [32000/37879 (64%)]\tLoss: 0.284644\n",
      "Train Epoch: 15 [32640/37879 (65%)]\tLoss: 0.153327\n",
      "Train Epoch: 15 [33280/37879 (66%)]\tLoss: 0.126598\n",
      "Train Epoch: 15 [33920/37879 (68%)]\tLoss: 0.186508\n",
      "Train Epoch: 15 [34560/37879 (69%)]\tLoss: 0.208890\n",
      "Train Epoch: 15 [35200/37879 (70%)]\tLoss: 0.129482\n",
      "Train Epoch: 15 [35840/37879 (72%)]\tLoss: 0.134383\n",
      "Train Epoch: 15 [36480/37879 (73%)]\tLoss: 0.184112\n",
      "Train Epoch: 15 [37120/37879 (74%)]\tLoss: 0.169088\n",
      "Train Epoch: 15 [37760/37879 (75%)]\tLoss: 0.185014\n",
      "Train Epoch: 15 [38400/37879 (77%)]\tLoss: 0.132897\n",
      "Train Epoch: 15 [39040/37879 (78%)]\tLoss: 0.247025\n",
      "Train Epoch: 15 [39680/37879 (79%)]\tLoss: 0.255529\n",
      "Train Epoch: 15 [40320/37879 (81%)]\tLoss: 0.151265\n",
      "Train Epoch: 15 [40960/37879 (82%)]\tLoss: 0.412919\n",
      "Train Epoch: 15 [41600/37879 (83%)]\tLoss: 0.222601\n",
      "Train Epoch: 15 [42240/37879 (84%)]\tLoss: 0.261008\n",
      "Train Epoch: 15 [42880/37879 (86%)]\tLoss: 0.072906\n",
      "Train Epoch: 15 [43520/37879 (87%)]\tLoss: 0.186962\n",
      "Train Epoch: 15 [44160/37879 (88%)]\tLoss: 0.104531\n",
      "Train Epoch: 15 [44800/37879 (90%)]\tLoss: 0.162796\n",
      "Train Epoch: 15 [45440/37879 (91%)]\tLoss: 0.247851\n",
      "Train Epoch: 15 [46080/37879 (92%)]\tLoss: 0.227057\n",
      "Train Epoch: 15 [46720/37879 (93%)]\tLoss: 0.087548\n",
      "Train Epoch: 15 [47360/37879 (95%)]\tLoss: 0.282336\n",
      "Train Epoch: 15 [48000/37879 (96%)]\tLoss: 0.117987\n",
      "Train Epoch: 15 [48640/37879 (97%)]\tLoss: 0.132383\n",
      "Train Epoch: 15 [49280/37879 (98%)]\tLoss: 0.079891\n",
      "Train Epoch: 15 [49920/37879 (100%)]\tLoss: 0.096199\n",
      "\n",
      "Test set: Avg. loss: 0.0497, Accuracy: 9835/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/37879 (0%)]\tLoss: 0.238208\n",
      "Train Epoch: 16 [640/37879 (1%)]\tLoss: 0.256930\n",
      "Train Epoch: 16 [1280/37879 (3%)]\tLoss: 0.183310\n",
      "Train Epoch: 16 [1920/37879 (4%)]\tLoss: 0.063041\n",
      "Train Epoch: 16 [2560/37879 (5%)]\tLoss: 0.124939\n",
      "Train Epoch: 16 [3200/37879 (6%)]\tLoss: 0.094062\n",
      "Train Epoch: 16 [3840/37879 (8%)]\tLoss: 0.255366\n",
      "Train Epoch: 16 [4480/37879 (9%)]\tLoss: 0.252238\n",
      "Train Epoch: 16 [5120/37879 (10%)]\tLoss: 0.107718\n",
      "Train Epoch: 16 [5760/37879 (12%)]\tLoss: 0.201545\n",
      "Train Epoch: 16 [6400/37879 (13%)]\tLoss: 0.341649\n",
      "Train Epoch: 16 [7040/37879 (14%)]\tLoss: 0.232016\n",
      "Train Epoch: 16 [7680/37879 (15%)]\tLoss: 0.233057\n",
      "Train Epoch: 16 [8320/37879 (17%)]\tLoss: 0.339039\n",
      "Train Epoch: 16 [8960/37879 (18%)]\tLoss: 0.087888\n",
      "Train Epoch: 16 [9600/37879 (19%)]\tLoss: 0.238668\n",
      "Train Epoch: 16 [10240/37879 (20%)]\tLoss: 0.142434\n",
      "Train Epoch: 16 [10880/37879 (22%)]\tLoss: 0.152060\n",
      "Train Epoch: 16 [11520/37879 (23%)]\tLoss: 0.181106\n",
      "Train Epoch: 16 [12160/37879 (24%)]\tLoss: 0.130386\n",
      "Train Epoch: 16 [12800/37879 (26%)]\tLoss: 0.145341\n",
      "Train Epoch: 16 [13440/37879 (27%)]\tLoss: 0.187478\n",
      "Train Epoch: 16 [14080/37879 (28%)]\tLoss: 0.248764\n",
      "Train Epoch: 16 [14720/37879 (29%)]\tLoss: 0.153895\n",
      "Train Epoch: 16 [15360/37879 (31%)]\tLoss: 0.334883\n",
      "Train Epoch: 16 [16000/37879 (32%)]\tLoss: 0.187126\n",
      "Train Epoch: 16 [16640/37879 (33%)]\tLoss: 0.155426\n",
      "Train Epoch: 16 [17280/37879 (35%)]\tLoss: 0.190205\n",
      "Train Epoch: 16 [17920/37879 (36%)]\tLoss: 0.147951\n",
      "Train Epoch: 16 [18560/37879 (37%)]\tLoss: 0.193402\n",
      "Train Epoch: 16 [19200/37879 (38%)]\tLoss: 0.081358\n",
      "Train Epoch: 16 [19840/37879 (40%)]\tLoss: 0.196494\n",
      "Train Epoch: 16 [20480/37879 (41%)]\tLoss: 0.143658\n",
      "Train Epoch: 16 [21120/37879 (42%)]\tLoss: 0.297340\n",
      "Train Epoch: 16 [21760/37879 (43%)]\tLoss: 0.184225\n",
      "Train Epoch: 16 [22400/37879 (45%)]\tLoss: 0.335207\n",
      "Train Epoch: 16 [23040/37879 (46%)]\tLoss: 0.289725\n",
      "Train Epoch: 16 [23680/37879 (47%)]\tLoss: 0.123169\n",
      "Train Epoch: 16 [24320/37879 (49%)]\tLoss: 0.300685\n",
      "Train Epoch: 16 [24960/37879 (50%)]\tLoss: 0.127850\n",
      "Train Epoch: 16 [25600/37879 (51%)]\tLoss: 0.131288\n",
      "Train Epoch: 16 [26240/37879 (52%)]\tLoss: 0.195985\n",
      "Train Epoch: 16 [26880/37879 (54%)]\tLoss: 0.241694\n",
      "Train Epoch: 16 [27520/37879 (55%)]\tLoss: 0.527568\n",
      "Train Epoch: 16 [28160/37879 (56%)]\tLoss: 0.220626\n",
      "Train Epoch: 16 [28800/37879 (58%)]\tLoss: 0.212980\n",
      "Train Epoch: 16 [29440/37879 (59%)]\tLoss: 0.095215\n",
      "Train Epoch: 16 [30080/37879 (60%)]\tLoss: 0.140737\n",
      "Train Epoch: 16 [30720/37879 (61%)]\tLoss: 0.156907\n",
      "Train Epoch: 16 [31360/37879 (63%)]\tLoss: 0.288638\n",
      "Train Epoch: 16 [32000/37879 (64%)]\tLoss: 0.146231\n",
      "Train Epoch: 16 [32640/37879 (65%)]\tLoss: 0.095724\n",
      "Train Epoch: 16 [33280/37879 (66%)]\tLoss: 0.226386\n",
      "Train Epoch: 16 [33920/37879 (68%)]\tLoss: 0.243730\n",
      "Train Epoch: 16 [34560/37879 (69%)]\tLoss: 0.082922\n",
      "Train Epoch: 16 [35200/37879 (70%)]\tLoss: 0.201606\n",
      "Train Epoch: 16 [35840/37879 (72%)]\tLoss: 0.213160\n",
      "Train Epoch: 16 [36480/37879 (73%)]\tLoss: 0.161739\n",
      "Train Epoch: 16 [37120/37879 (74%)]\tLoss: 0.034666\n",
      "Train Epoch: 16 [37760/37879 (75%)]\tLoss: 0.081897\n",
      "Train Epoch: 16 [38400/37879 (77%)]\tLoss: 0.091702\n",
      "Train Epoch: 16 [39040/37879 (78%)]\tLoss: 0.130354\n",
      "Train Epoch: 16 [39680/37879 (79%)]\tLoss: 0.232083\n",
      "Train Epoch: 16 [40320/37879 (81%)]\tLoss: 0.318719\n",
      "Train Epoch: 16 [40960/37879 (82%)]\tLoss: 0.292425\n",
      "Train Epoch: 16 [41600/37879 (83%)]\tLoss: 0.569570\n",
      "Train Epoch: 16 [42240/37879 (84%)]\tLoss: 0.327937\n",
      "Train Epoch: 16 [42880/37879 (86%)]\tLoss: 0.126198\n",
      "Train Epoch: 16 [43520/37879 (87%)]\tLoss: 0.220635\n",
      "Train Epoch: 16 [44160/37879 (88%)]\tLoss: 0.145421\n",
      "Train Epoch: 16 [44800/37879 (90%)]\tLoss: 0.202322\n",
      "Train Epoch: 16 [45440/37879 (91%)]\tLoss: 0.233253\n",
      "Train Epoch: 16 [46080/37879 (92%)]\tLoss: 0.031363\n",
      "Train Epoch: 16 [46720/37879 (93%)]\tLoss: 0.289520\n",
      "Train Epoch: 16 [47360/37879 (95%)]\tLoss: 0.344949\n",
      "Train Epoch: 16 [48000/37879 (96%)]\tLoss: 0.169174\n",
      "Train Epoch: 16 [48640/37879 (97%)]\tLoss: 0.113289\n",
      "Train Epoch: 16 [49280/37879 (98%)]\tLoss: 0.216419\n",
      "Train Epoch: 16 [49920/37879 (100%)]\tLoss: 0.195475\n",
      "\n",
      "Test set: Avg. loss: 0.0485, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/37879 (0%)]\tLoss: 0.202956\n",
      "Train Epoch: 17 [640/37879 (1%)]\tLoss: 0.208509\n",
      "Train Epoch: 17 [1280/37879 (3%)]\tLoss: 0.140782\n",
      "Train Epoch: 17 [1920/37879 (4%)]\tLoss: 0.237939\n",
      "Train Epoch: 17 [2560/37879 (5%)]\tLoss: 0.172001\n",
      "Train Epoch: 17 [3200/37879 (6%)]\tLoss: 0.178207\n",
      "Train Epoch: 17 [3840/37879 (8%)]\tLoss: 0.189837\n",
      "Train Epoch: 17 [4480/37879 (9%)]\tLoss: 0.186944\n",
      "Train Epoch: 17 [5120/37879 (10%)]\tLoss: 0.176187\n",
      "Train Epoch: 17 [5760/37879 (12%)]\tLoss: 0.190844\n",
      "Train Epoch: 17 [6400/37879 (13%)]\tLoss: 0.189625\n",
      "Train Epoch: 17 [7040/37879 (14%)]\tLoss: 0.157033\n",
      "Train Epoch: 17 [7680/37879 (15%)]\tLoss: 0.093830\n",
      "Train Epoch: 17 [8320/37879 (17%)]\tLoss: 0.108870\n",
      "Train Epoch: 17 [8960/37879 (18%)]\tLoss: 0.229997\n",
      "Train Epoch: 17 [9600/37879 (19%)]\tLoss: 0.161568\n",
      "Train Epoch: 17 [10240/37879 (20%)]\tLoss: 0.220278\n",
      "Train Epoch: 17 [10880/37879 (22%)]\tLoss: 0.114285\n",
      "Train Epoch: 17 [11520/37879 (23%)]\tLoss: 0.122226\n",
      "Train Epoch: 17 [12160/37879 (24%)]\tLoss: 0.090881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [12800/37879 (26%)]\tLoss: 0.148378\n",
      "Train Epoch: 17 [13440/37879 (27%)]\tLoss: 0.421756\n",
      "Train Epoch: 17 [14080/37879 (28%)]\tLoss: 0.121690\n",
      "Train Epoch: 17 [14720/37879 (29%)]\tLoss: 0.226061\n",
      "Train Epoch: 17 [15360/37879 (31%)]\tLoss: 0.252841\n",
      "Train Epoch: 17 [16000/37879 (32%)]\tLoss: 0.154326\n",
      "Train Epoch: 17 [16640/37879 (33%)]\tLoss: 0.416326\n",
      "Train Epoch: 17 [17280/37879 (35%)]\tLoss: 0.406236\n",
      "Train Epoch: 17 [17920/37879 (36%)]\tLoss: 0.236644\n",
      "Train Epoch: 17 [18560/37879 (37%)]\tLoss: 0.243225\n",
      "Train Epoch: 17 [19200/37879 (38%)]\tLoss: 0.134969\n",
      "Train Epoch: 17 [19840/37879 (40%)]\tLoss: 0.132538\n",
      "Train Epoch: 17 [20480/37879 (41%)]\tLoss: 0.217450\n",
      "Train Epoch: 17 [21120/37879 (42%)]\tLoss: 0.096685\n",
      "Train Epoch: 17 [21760/37879 (43%)]\tLoss: 0.161012\n",
      "Train Epoch: 17 [22400/37879 (45%)]\tLoss: 0.113026\n",
      "Train Epoch: 17 [23040/37879 (46%)]\tLoss: 0.138352\n",
      "Train Epoch: 17 [23680/37879 (47%)]\tLoss: 0.266525\n",
      "Train Epoch: 17 [24320/37879 (49%)]\tLoss: 0.266117\n",
      "Train Epoch: 17 [24960/37879 (50%)]\tLoss: 0.171580\n",
      "Train Epoch: 17 [25600/37879 (51%)]\tLoss: 0.114346\n",
      "Train Epoch: 17 [26240/37879 (52%)]\tLoss: 0.174076\n",
      "Train Epoch: 17 [26880/37879 (54%)]\tLoss: 0.468465\n",
      "Train Epoch: 17 [27520/37879 (55%)]\tLoss: 0.103329\n",
      "Train Epoch: 17 [28160/37879 (56%)]\tLoss: 0.152634\n",
      "Train Epoch: 17 [28800/37879 (58%)]\tLoss: 0.124735\n",
      "Train Epoch: 17 [29440/37879 (59%)]\tLoss: 0.168121\n",
      "Train Epoch: 17 [30080/37879 (60%)]\tLoss: 0.241875\n",
      "Train Epoch: 17 [30720/37879 (61%)]\tLoss: 0.106818\n",
      "Train Epoch: 17 [31360/37879 (63%)]\tLoss: 0.157989\n",
      "Train Epoch: 17 [32000/37879 (64%)]\tLoss: 0.154923\n",
      "Train Epoch: 17 [32640/37879 (65%)]\tLoss: 0.061981\n",
      "Train Epoch: 17 [33280/37879 (66%)]\tLoss: 0.268210\n",
      "Train Epoch: 17 [33920/37879 (68%)]\tLoss: 0.138415\n",
      "Train Epoch: 17 [34560/37879 (69%)]\tLoss: 0.150424\n",
      "Train Epoch: 17 [35200/37879 (70%)]\tLoss: 0.079669\n",
      "Train Epoch: 17 [35840/37879 (72%)]\tLoss: 0.047190\n",
      "Train Epoch: 17 [36480/37879 (73%)]\tLoss: 0.094178\n",
      "Train Epoch: 17 [37120/37879 (74%)]\tLoss: 0.283957\n",
      "Train Epoch: 17 [37760/37879 (75%)]\tLoss: 0.205846\n",
      "Train Epoch: 17 [38400/37879 (77%)]\tLoss: 0.198840\n",
      "Train Epoch: 17 [39040/37879 (78%)]\tLoss: 0.129351\n",
      "Train Epoch: 17 [39680/37879 (79%)]\tLoss: 0.160548\n",
      "Train Epoch: 17 [40320/37879 (81%)]\tLoss: 0.301833\n",
      "Train Epoch: 17 [40960/37879 (82%)]\tLoss: 0.123914\n",
      "Train Epoch: 17 [41600/37879 (83%)]\tLoss: 0.279389\n",
      "Train Epoch: 17 [42240/37879 (84%)]\tLoss: 0.148949\n",
      "Train Epoch: 17 [42880/37879 (86%)]\tLoss: 0.247344\n",
      "Train Epoch: 17 [43520/37879 (87%)]\tLoss: 0.166873\n",
      "Train Epoch: 17 [44160/37879 (88%)]\tLoss: 0.323755\n",
      "Train Epoch: 17 [44800/37879 (90%)]\tLoss: 0.190833\n",
      "Train Epoch: 17 [45440/37879 (91%)]\tLoss: 0.104599\n",
      "Train Epoch: 17 [46080/37879 (92%)]\tLoss: 0.306999\n",
      "Train Epoch: 17 [46720/37879 (93%)]\tLoss: 0.233626\n",
      "Train Epoch: 17 [47360/37879 (95%)]\tLoss: 0.104625\n",
      "Train Epoch: 17 [48000/37879 (96%)]\tLoss: 0.088235\n",
      "Train Epoch: 17 [48640/37879 (97%)]\tLoss: 0.227845\n",
      "Train Epoch: 17 [49280/37879 (98%)]\tLoss: 0.312106\n",
      "Train Epoch: 17 [49920/37879 (100%)]\tLoss: 0.146906\n",
      "\n",
      "Test set: Avg. loss: 0.0473, Accuracy: 9856/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/37879 (0%)]\tLoss: 0.297736\n",
      "Train Epoch: 18 [640/37879 (1%)]\tLoss: 0.094075\n",
      "Train Epoch: 18 [1280/37879 (3%)]\tLoss: 0.242284\n",
      "Train Epoch: 18 [1920/37879 (4%)]\tLoss: 0.238079\n",
      "Train Epoch: 18 [2560/37879 (5%)]\tLoss: 0.259622\n",
      "Train Epoch: 18 [3200/37879 (6%)]\tLoss: 0.245852\n",
      "Train Epoch: 18 [3840/37879 (8%)]\tLoss: 0.251830\n",
      "Train Epoch: 18 [4480/37879 (9%)]\tLoss: 0.074133\n",
      "Train Epoch: 18 [5120/37879 (10%)]\tLoss: 0.059400\n",
      "Train Epoch: 18 [5760/37879 (12%)]\tLoss: 0.251032\n",
      "Train Epoch: 18 [6400/37879 (13%)]\tLoss: 0.145528\n",
      "Train Epoch: 18 [7040/37879 (14%)]\tLoss: 0.093378\n",
      "Train Epoch: 18 [7680/37879 (15%)]\tLoss: 0.133014\n",
      "Train Epoch: 18 [8320/37879 (17%)]\tLoss: 0.105222\n",
      "Train Epoch: 18 [8960/37879 (18%)]\tLoss: 0.110120\n",
      "Train Epoch: 18 [9600/37879 (19%)]\tLoss: 0.251357\n",
      "Train Epoch: 18 [10240/37879 (20%)]\tLoss: 0.181919\n",
      "Train Epoch: 18 [10880/37879 (22%)]\tLoss: 0.463993\n",
      "Train Epoch: 18 [11520/37879 (23%)]\tLoss: 0.175566\n",
      "Train Epoch: 18 [12160/37879 (24%)]\tLoss: 0.124257\n",
      "Train Epoch: 18 [12800/37879 (26%)]\tLoss: 0.176723\n",
      "Train Epoch: 18 [13440/37879 (27%)]\tLoss: 0.161511\n",
      "Train Epoch: 18 [14080/37879 (28%)]\tLoss: 0.198777\n",
      "Train Epoch: 18 [14720/37879 (29%)]\tLoss: 0.201516\n",
      "Train Epoch: 18 [15360/37879 (31%)]\tLoss: 0.237738\n",
      "Train Epoch: 18 [16000/37879 (32%)]\tLoss: 0.217947\n",
      "Train Epoch: 18 [16640/37879 (33%)]\tLoss: 0.097881\n",
      "Train Epoch: 18 [17280/37879 (35%)]\tLoss: 0.262076\n",
      "Train Epoch: 18 [17920/37879 (36%)]\tLoss: 0.135994\n",
      "Train Epoch: 18 [18560/37879 (37%)]\tLoss: 0.250471\n",
      "Train Epoch: 18 [19200/37879 (38%)]\tLoss: 0.132157\n",
      "Train Epoch: 18 [19840/37879 (40%)]\tLoss: 0.154098\n",
      "Train Epoch: 18 [20480/37879 (41%)]\tLoss: 0.128377\n",
      "Train Epoch: 18 [21120/37879 (42%)]\tLoss: 0.199806\n",
      "Train Epoch: 18 [21760/37879 (43%)]\tLoss: 0.158970\n",
      "Train Epoch: 18 [22400/37879 (45%)]\tLoss: 0.111294\n",
      "Train Epoch: 18 [23040/37879 (46%)]\tLoss: 0.191592\n",
      "Train Epoch: 18 [23680/37879 (47%)]\tLoss: 0.117302\n",
      "Train Epoch: 18 [24320/37879 (49%)]\tLoss: 0.140402\n",
      "Train Epoch: 18 [24960/37879 (50%)]\tLoss: 0.256094\n",
      "Train Epoch: 18 [25600/37879 (51%)]\tLoss: 0.180101\n",
      "Train Epoch: 18 [26240/37879 (52%)]\tLoss: 0.260808\n",
      "Train Epoch: 18 [26880/37879 (54%)]\tLoss: 0.215067\n",
      "Train Epoch: 18 [27520/37879 (55%)]\tLoss: 0.169664\n",
      "Train Epoch: 18 [28160/37879 (56%)]\tLoss: 0.115198\n",
      "Train Epoch: 18 [28800/37879 (58%)]\tLoss: 0.229209\n",
      "Train Epoch: 18 [29440/37879 (59%)]\tLoss: 0.131474\n",
      "Train Epoch: 18 [30080/37879 (60%)]\tLoss: 0.196309\n",
      "Train Epoch: 18 [30720/37879 (61%)]\tLoss: 0.236390\n",
      "Train Epoch: 18 [31360/37879 (63%)]\tLoss: 0.178412\n",
      "Train Epoch: 18 [32000/37879 (64%)]\tLoss: 0.332481\n",
      "Train Epoch: 18 [32640/37879 (65%)]\tLoss: 0.321812\n",
      "Train Epoch: 18 [33280/37879 (66%)]\tLoss: 0.166940\n",
      "Train Epoch: 18 [33920/37879 (68%)]\tLoss: 0.155279\n",
      "Train Epoch: 18 [34560/37879 (69%)]\tLoss: 0.089920\n",
      "Train Epoch: 18 [35200/37879 (70%)]\tLoss: 0.108938\n",
      "Train Epoch: 18 [35840/37879 (72%)]\tLoss: 0.184363\n",
      "Train Epoch: 18 [36480/37879 (73%)]\tLoss: 0.304056\n",
      "Train Epoch: 18 [37120/37879 (74%)]\tLoss: 0.106199\n",
      "Train Epoch: 18 [37760/37879 (75%)]\tLoss: 0.104329\n",
      "Train Epoch: 18 [38400/37879 (77%)]\tLoss: 0.130255\n",
      "Train Epoch: 18 [39040/37879 (78%)]\tLoss: 0.186125\n",
      "Train Epoch: 18 [39680/37879 (79%)]\tLoss: 0.121429\n",
      "Train Epoch: 18 [40320/37879 (81%)]\tLoss: 0.139394\n",
      "Train Epoch: 18 [40960/37879 (82%)]\tLoss: 0.211886\n",
      "Train Epoch: 18 [41600/37879 (83%)]\tLoss: 0.220422\n",
      "Train Epoch: 18 [42240/37879 (84%)]\tLoss: 0.109661\n",
      "Train Epoch: 18 [42880/37879 (86%)]\tLoss: 0.115240\n",
      "Train Epoch: 18 [43520/37879 (87%)]\tLoss: 0.070618\n",
      "Train Epoch: 18 [44160/37879 (88%)]\tLoss: 0.325233\n",
      "Train Epoch: 18 [44800/37879 (90%)]\tLoss: 0.208700\n",
      "Train Epoch: 18 [45440/37879 (91%)]\tLoss: 0.073366\n",
      "Train Epoch: 18 [46080/37879 (92%)]\tLoss: 0.175802\n",
      "Train Epoch: 18 [46720/37879 (93%)]\tLoss: 0.324454\n",
      "Train Epoch: 18 [47360/37879 (95%)]\tLoss: 0.210966\n",
      "Train Epoch: 18 [48000/37879 (96%)]\tLoss: 0.178465\n",
      "Train Epoch: 18 [48640/37879 (97%)]\tLoss: 0.159476\n",
      "Train Epoch: 18 [49280/37879 (98%)]\tLoss: 0.160115\n",
      "Train Epoch: 18 [49920/37879 (100%)]\tLoss: 0.184501\n",
      "\n",
      "Test set: Avg. loss: 0.0490, Accuracy: 9842/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/37879 (0%)]\tLoss: 0.130531\n",
      "Train Epoch: 19 [640/37879 (1%)]\tLoss: 0.180746\n",
      "Train Epoch: 19 [1280/37879 (3%)]\tLoss: 0.129798\n",
      "Train Epoch: 19 [1920/37879 (4%)]\tLoss: 0.210599\n",
      "Train Epoch: 19 [2560/37879 (5%)]\tLoss: 0.058518\n",
      "Train Epoch: 19 [3200/37879 (6%)]\tLoss: 0.254256\n",
      "Train Epoch: 19 [3840/37879 (8%)]\tLoss: 0.122192\n",
      "Train Epoch: 19 [4480/37879 (9%)]\tLoss: 0.397984\n",
      "Train Epoch: 19 [5120/37879 (10%)]\tLoss: 0.112523\n",
      "Train Epoch: 19 [5760/37879 (12%)]\tLoss: 0.169012\n",
      "Train Epoch: 19 [6400/37879 (13%)]\tLoss: 0.326885\n",
      "Train Epoch: 19 [7040/37879 (14%)]\tLoss: 0.167438\n",
      "Train Epoch: 19 [7680/37879 (15%)]\tLoss: 0.144422\n",
      "Train Epoch: 19 [8320/37879 (17%)]\tLoss: 0.352019\n",
      "Train Epoch: 19 [8960/37879 (18%)]\tLoss: 0.158742\n",
      "Train Epoch: 19 [9600/37879 (19%)]\tLoss: 0.250009\n",
      "Train Epoch: 19 [10240/37879 (20%)]\tLoss: 0.041614\n",
      "Train Epoch: 19 [10880/37879 (22%)]\tLoss: 0.220202\n",
      "Train Epoch: 19 [11520/37879 (23%)]\tLoss: 0.083723\n",
      "Train Epoch: 19 [12160/37879 (24%)]\tLoss: 0.238981\n",
      "Train Epoch: 19 [12800/37879 (26%)]\tLoss: 0.126143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [13440/37879 (27%)]\tLoss: 0.149843\n",
      "Train Epoch: 19 [14080/37879 (28%)]\tLoss: 0.224408\n",
      "Train Epoch: 19 [14720/37879 (29%)]\tLoss: 0.066124\n",
      "Train Epoch: 19 [15360/37879 (31%)]\tLoss: 0.237965\n",
      "Train Epoch: 19 [16000/37879 (32%)]\tLoss: 0.084117\n",
      "Train Epoch: 19 [16640/37879 (33%)]\tLoss: 0.135090\n",
      "Train Epoch: 19 [17280/37879 (35%)]\tLoss: 0.116440\n",
      "Train Epoch: 19 [17920/37879 (36%)]\tLoss: 0.301676\n",
      "Train Epoch: 19 [18560/37879 (37%)]\tLoss: 0.169089\n",
      "Train Epoch: 19 [19200/37879 (38%)]\tLoss: 0.098857\n",
      "Train Epoch: 19 [19840/37879 (40%)]\tLoss: 0.159048\n",
      "Train Epoch: 19 [20480/37879 (41%)]\tLoss: 0.299923\n",
      "Train Epoch: 19 [21120/37879 (42%)]\tLoss: 0.160080\n",
      "Train Epoch: 19 [21760/37879 (43%)]\tLoss: 0.150633\n",
      "Train Epoch: 19 [22400/37879 (45%)]\tLoss: 0.120114\n",
      "Train Epoch: 19 [23040/37879 (46%)]\tLoss: 0.184820\n",
      "Train Epoch: 19 [23680/37879 (47%)]\tLoss: 0.125085\n",
      "Train Epoch: 19 [24320/37879 (49%)]\tLoss: 0.094390\n",
      "Train Epoch: 19 [24960/37879 (50%)]\tLoss: 0.241978\n",
      "Train Epoch: 19 [25600/37879 (51%)]\tLoss: 0.211346\n",
      "Train Epoch: 19 [26240/37879 (52%)]\tLoss: 0.316193\n",
      "Train Epoch: 19 [26880/37879 (54%)]\tLoss: 0.150921\n",
      "Train Epoch: 19 [27520/37879 (55%)]\tLoss: 0.149186\n",
      "Train Epoch: 19 [28160/37879 (56%)]\tLoss: 0.094363\n",
      "Train Epoch: 19 [28800/37879 (58%)]\tLoss: 0.125482\n",
      "Train Epoch: 19 [29440/37879 (59%)]\tLoss: 0.160152\n",
      "Train Epoch: 19 [30080/37879 (60%)]\tLoss: 0.137924\n",
      "Train Epoch: 19 [30720/37879 (61%)]\tLoss: 0.129153\n",
      "Train Epoch: 19 [31360/37879 (63%)]\tLoss: 0.183182\n",
      "Train Epoch: 19 [32000/37879 (64%)]\tLoss: 0.353667\n",
      "Train Epoch: 19 [32640/37879 (65%)]\tLoss: 0.076650\n",
      "Train Epoch: 19 [33280/37879 (66%)]\tLoss: 0.392795\n",
      "Train Epoch: 19 [33920/37879 (68%)]\tLoss: 0.268005\n",
      "Train Epoch: 19 [34560/37879 (69%)]\tLoss: 0.191080\n",
      "Train Epoch: 19 [35200/37879 (70%)]\tLoss: 0.205573\n",
      "Train Epoch: 19 [35840/37879 (72%)]\tLoss: 0.183155\n",
      "Train Epoch: 19 [36480/37879 (73%)]\tLoss: 0.221344\n",
      "Train Epoch: 19 [37120/37879 (74%)]\tLoss: 0.237994\n",
      "Train Epoch: 19 [37760/37879 (75%)]\tLoss: 0.112625\n",
      "Train Epoch: 19 [38400/37879 (77%)]\tLoss: 0.129549\n",
      "Train Epoch: 19 [39040/37879 (78%)]\tLoss: 0.218990\n",
      "Train Epoch: 19 [39680/37879 (79%)]\tLoss: 0.188351\n",
      "Train Epoch: 19 [40320/37879 (81%)]\tLoss: 0.244231\n",
      "Train Epoch: 19 [40960/37879 (82%)]\tLoss: 0.223030\n",
      "Train Epoch: 19 [41600/37879 (83%)]\tLoss: 0.158482\n",
      "Train Epoch: 19 [42240/37879 (84%)]\tLoss: 0.253702\n",
      "Train Epoch: 19 [42880/37879 (86%)]\tLoss: 0.214186\n",
      "Train Epoch: 19 [43520/37879 (87%)]\tLoss: 0.224122\n",
      "Train Epoch: 19 [44160/37879 (88%)]\tLoss: 0.179797\n",
      "Train Epoch: 19 [44800/37879 (90%)]\tLoss: 0.174434\n",
      "Train Epoch: 19 [45440/37879 (91%)]\tLoss: 0.149135\n",
      "Train Epoch: 19 [46080/37879 (92%)]\tLoss: 0.410824\n",
      "Train Epoch: 19 [46720/37879 (93%)]\tLoss: 0.267663\n",
      "Train Epoch: 19 [47360/37879 (95%)]\tLoss: 0.186495\n",
      "Train Epoch: 19 [48000/37879 (96%)]\tLoss: 0.183198\n",
      "Train Epoch: 19 [48640/37879 (97%)]\tLoss: 0.198943\n",
      "Train Epoch: 19 [49280/37879 (98%)]\tLoss: 0.316386\n",
      "Train Epoch: 19 [49920/37879 (100%)]\tLoss: 0.122521\n",
      "\n",
      "Test set: Avg. loss: 0.0478, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/37879 (0%)]\tLoss: 0.223463\n",
      "Train Epoch: 20 [640/37879 (1%)]\tLoss: 0.298941\n",
      "Train Epoch: 20 [1280/37879 (3%)]\tLoss: 0.193131\n",
      "Train Epoch: 20 [1920/37879 (4%)]\tLoss: 0.208797\n",
      "Train Epoch: 20 [2560/37879 (5%)]\tLoss: 0.133269\n",
      "Train Epoch: 20 [3200/37879 (6%)]\tLoss: 0.116737\n",
      "Train Epoch: 20 [3840/37879 (8%)]\tLoss: 0.103611\n",
      "Train Epoch: 20 [4480/37879 (9%)]\tLoss: 0.140319\n",
      "Train Epoch: 20 [5120/37879 (10%)]\tLoss: 0.145764\n",
      "Train Epoch: 20 [5760/37879 (12%)]\tLoss: 0.244152\n",
      "Train Epoch: 20 [6400/37879 (13%)]\tLoss: 0.136687\n",
      "Train Epoch: 20 [7040/37879 (14%)]\tLoss: 0.306082\n",
      "Train Epoch: 20 [7680/37879 (15%)]\tLoss: 0.116552\n",
      "Train Epoch: 20 [8320/37879 (17%)]\tLoss: 0.134719\n",
      "Train Epoch: 20 [8960/37879 (18%)]\tLoss: 0.255523\n",
      "Train Epoch: 20 [9600/37879 (19%)]\tLoss: 0.169747\n",
      "Train Epoch: 20 [10240/37879 (20%)]\tLoss: 0.058822\n",
      "Train Epoch: 20 [10880/37879 (22%)]\tLoss: 0.267500\n",
      "Train Epoch: 20 [11520/37879 (23%)]\tLoss: 0.125809\n",
      "Train Epoch: 20 [12160/37879 (24%)]\tLoss: 0.223752\n",
      "Train Epoch: 20 [12800/37879 (26%)]\tLoss: 0.180976\n",
      "Train Epoch: 20 [13440/37879 (27%)]\tLoss: 0.148706\n",
      "Train Epoch: 20 [14080/37879 (28%)]\tLoss: 0.183469\n",
      "Train Epoch: 20 [14720/37879 (29%)]\tLoss: 0.175779\n",
      "Train Epoch: 20 [15360/37879 (31%)]\tLoss: 0.251268\n",
      "Train Epoch: 20 [16000/37879 (32%)]\tLoss: 0.113900\n",
      "Train Epoch: 20 [16640/37879 (33%)]\tLoss: 0.161814\n",
      "Train Epoch: 20 [17280/37879 (35%)]\tLoss: 0.162296\n",
      "Train Epoch: 20 [17920/37879 (36%)]\tLoss: 0.156366\n",
      "Train Epoch: 20 [18560/37879 (37%)]\tLoss: 0.133857\n",
      "Train Epoch: 20 [19200/37879 (38%)]\tLoss: 0.139935\n",
      "Train Epoch: 20 [19840/37879 (40%)]\tLoss: 0.091733\n",
      "Train Epoch: 20 [20480/37879 (41%)]\tLoss: 0.156696\n",
      "Train Epoch: 20 [21120/37879 (42%)]\tLoss: 0.186524\n",
      "Train Epoch: 20 [21760/37879 (43%)]\tLoss: 0.105288\n",
      "Train Epoch: 20 [22400/37879 (45%)]\tLoss: 0.142058\n",
      "Train Epoch: 20 [23040/37879 (46%)]\tLoss: 0.122172\n",
      "Train Epoch: 20 [23680/37879 (47%)]\tLoss: 0.105656\n",
      "Train Epoch: 20 [24320/37879 (49%)]\tLoss: 0.165254\n",
      "Train Epoch: 20 [24960/37879 (50%)]\tLoss: 0.172450\n",
      "Train Epoch: 20 [25600/37879 (51%)]\tLoss: 0.084205\n",
      "Train Epoch: 20 [26240/37879 (52%)]\tLoss: 0.060384\n",
      "Train Epoch: 20 [26880/37879 (54%)]\tLoss: 0.208825\n",
      "Train Epoch: 20 [27520/37879 (55%)]\tLoss: 0.093214\n",
      "Train Epoch: 20 [28160/37879 (56%)]\tLoss: 0.382684\n",
      "Train Epoch: 20 [28800/37879 (58%)]\tLoss: 0.268610\n",
      "Train Epoch: 20 [29440/37879 (59%)]\tLoss: 0.165595\n",
      "Train Epoch: 20 [30080/37879 (60%)]\tLoss: 0.234171\n",
      "Train Epoch: 20 [30720/37879 (61%)]\tLoss: 0.150301\n",
      "Train Epoch: 20 [31360/37879 (63%)]\tLoss: 0.144650\n",
      "Train Epoch: 20 [32000/37879 (64%)]\tLoss: 0.296901\n",
      "Train Epoch: 20 [32640/37879 (65%)]\tLoss: 0.168618\n",
      "Train Epoch: 20 [33280/37879 (66%)]\tLoss: 0.141071\n",
      "Train Epoch: 20 [33920/37879 (68%)]\tLoss: 0.221656\n",
      "Train Epoch: 20 [34560/37879 (69%)]\tLoss: 0.407395\n",
      "Train Epoch: 20 [35200/37879 (70%)]\tLoss: 0.277111\n",
      "Train Epoch: 20 [35840/37879 (72%)]\tLoss: 0.297521\n",
      "Train Epoch: 20 [36480/37879 (73%)]\tLoss: 0.121177\n",
      "Train Epoch: 20 [37120/37879 (74%)]\tLoss: 0.121918\n",
      "Train Epoch: 20 [37760/37879 (75%)]\tLoss: 0.232582\n",
      "Train Epoch: 20 [38400/37879 (77%)]\tLoss: 0.119196\n",
      "Train Epoch: 20 [39040/37879 (78%)]\tLoss: 0.151973\n",
      "Train Epoch: 20 [39680/37879 (79%)]\tLoss: 0.192117\n",
      "Train Epoch: 20 [40320/37879 (81%)]\tLoss: 0.054656\n",
      "Train Epoch: 20 [40960/37879 (82%)]\tLoss: 0.047989\n",
      "Train Epoch: 20 [41600/37879 (83%)]\tLoss: 0.258690\n",
      "Train Epoch: 20 [42240/37879 (84%)]\tLoss: 0.133470\n",
      "Train Epoch: 20 [42880/37879 (86%)]\tLoss: 0.171608\n",
      "Train Epoch: 20 [43520/37879 (87%)]\tLoss: 0.319138\n",
      "Train Epoch: 20 [44160/37879 (88%)]\tLoss: 0.253483\n",
      "Train Epoch: 20 [44800/37879 (90%)]\tLoss: 0.183817\n",
      "Train Epoch: 20 [45440/37879 (91%)]\tLoss: 0.194678\n",
      "Train Epoch: 20 [46080/37879 (92%)]\tLoss: 0.233566\n",
      "Train Epoch: 20 [46720/37879 (93%)]\tLoss: 0.089704\n",
      "Train Epoch: 20 [47360/37879 (95%)]\tLoss: 0.065919\n",
      "Train Epoch: 20 [48000/37879 (96%)]\tLoss: 0.158491\n",
      "Train Epoch: 20 [48640/37879 (97%)]\tLoss: 0.121214\n",
      "Train Epoch: 20 [49280/37879 (98%)]\tLoss: 0.265494\n",
      "Train Epoch: 20 [49920/37879 (100%)]\tLoss: 0.130486\n",
      "\n",
      "Test set: Avg. loss: 0.0442, Accuracy: 9866/10000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/37879 (0%)]\tLoss: 0.230511\n",
      "Train Epoch: 21 [640/37879 (1%)]\tLoss: 0.102089\n",
      "Train Epoch: 21 [1280/37879 (3%)]\tLoss: 0.171822\n",
      "Train Epoch: 21 [1920/37879 (4%)]\tLoss: 0.115733\n",
      "Train Epoch: 21 [2560/37879 (5%)]\tLoss: 0.116255\n",
      "Train Epoch: 21 [3200/37879 (6%)]\tLoss: 0.114368\n",
      "Train Epoch: 21 [3840/37879 (8%)]\tLoss: 0.161304\n",
      "Train Epoch: 21 [4480/37879 (9%)]\tLoss: 0.372706\n",
      "Train Epoch: 21 [5120/37879 (10%)]\tLoss: 0.052008\n",
      "Train Epoch: 21 [5760/37879 (12%)]\tLoss: 0.102413\n",
      "Train Epoch: 21 [6400/37879 (13%)]\tLoss: 0.210647\n",
      "Train Epoch: 21 [7040/37879 (14%)]\tLoss: 0.160507\n",
      "Train Epoch: 21 [7680/37879 (15%)]\tLoss: 0.350813\n",
      "Train Epoch: 21 [8320/37879 (17%)]\tLoss: 0.155193\n",
      "Train Epoch: 21 [8960/37879 (18%)]\tLoss: 0.097163\n",
      "Train Epoch: 21 [9600/37879 (19%)]\tLoss: 0.101980\n",
      "Train Epoch: 21 [10240/37879 (20%)]\tLoss: 0.216004\n",
      "Train Epoch: 21 [10880/37879 (22%)]\tLoss: 0.173646\n",
      "Train Epoch: 21 [11520/37879 (23%)]\tLoss: 0.113699\n",
      "Train Epoch: 21 [12160/37879 (24%)]\tLoss: 0.132568\n",
      "Train Epoch: 21 [12800/37879 (26%)]\tLoss: 0.225799\n",
      "Train Epoch: 21 [13440/37879 (27%)]\tLoss: 0.245482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [14080/37879 (28%)]\tLoss: 0.228284\n",
      "Train Epoch: 21 [14720/37879 (29%)]\tLoss: 0.292735\n",
      "Train Epoch: 21 [15360/37879 (31%)]\tLoss: 0.301237\n",
      "Train Epoch: 21 [16000/37879 (32%)]\tLoss: 0.245025\n",
      "Train Epoch: 21 [16640/37879 (33%)]\tLoss: 0.255215\n",
      "Train Epoch: 21 [17280/37879 (35%)]\tLoss: 0.180422\n",
      "Train Epoch: 21 [17920/37879 (36%)]\tLoss: 0.072543\n",
      "Train Epoch: 21 [18560/37879 (37%)]\tLoss: 0.230374\n",
      "Train Epoch: 21 [19200/37879 (38%)]\tLoss: 0.025487\n",
      "Train Epoch: 21 [19840/37879 (40%)]\tLoss: 0.138841\n",
      "Train Epoch: 21 [20480/37879 (41%)]\tLoss: 0.104039\n",
      "Train Epoch: 21 [21120/37879 (42%)]\tLoss: 0.096254\n",
      "Train Epoch: 21 [21760/37879 (43%)]\tLoss: 0.342453\n",
      "Train Epoch: 21 [22400/37879 (45%)]\tLoss: 0.187126\n",
      "Train Epoch: 21 [23040/37879 (46%)]\tLoss: 0.057501\n",
      "Train Epoch: 21 [23680/37879 (47%)]\tLoss: 0.211611\n",
      "Train Epoch: 21 [24320/37879 (49%)]\tLoss: 0.125024\n",
      "Train Epoch: 21 [24960/37879 (50%)]\tLoss: 0.155901\n",
      "Train Epoch: 21 [25600/37879 (51%)]\tLoss: 0.302465\n",
      "Train Epoch: 21 [26240/37879 (52%)]\tLoss: 0.176759\n",
      "Train Epoch: 21 [26880/37879 (54%)]\tLoss: 0.129500\n",
      "Train Epoch: 21 [27520/37879 (55%)]\tLoss: 0.215052\n",
      "Train Epoch: 21 [28160/37879 (56%)]\tLoss: 0.119721\n",
      "Train Epoch: 21 [28800/37879 (58%)]\tLoss: 0.153595\n",
      "Train Epoch: 21 [29440/37879 (59%)]\tLoss: 0.180610\n",
      "Train Epoch: 21 [30080/37879 (60%)]\tLoss: 0.211550\n",
      "Train Epoch: 21 [30720/37879 (61%)]\tLoss: 0.208455\n",
      "Train Epoch: 21 [31360/37879 (63%)]\tLoss: 0.100843\n",
      "Train Epoch: 21 [32000/37879 (64%)]\tLoss: 0.168152\n",
      "Train Epoch: 21 [32640/37879 (65%)]\tLoss: 0.137474\n",
      "Train Epoch: 21 [33280/37879 (66%)]\tLoss: 0.254628\n",
      "Train Epoch: 21 [33920/37879 (68%)]\tLoss: 0.282000\n",
      "Train Epoch: 21 [34560/37879 (69%)]\tLoss: 0.120596\n",
      "Train Epoch: 21 [35200/37879 (70%)]\tLoss: 0.191164\n",
      "Train Epoch: 21 [35840/37879 (72%)]\tLoss: 0.156166\n",
      "Train Epoch: 21 [36480/37879 (73%)]\tLoss: 0.228956\n",
      "Train Epoch: 21 [37120/37879 (74%)]\tLoss: 0.209485\n",
      "Train Epoch: 21 [37760/37879 (75%)]\tLoss: 0.102972\n",
      "Train Epoch: 21 [38400/37879 (77%)]\tLoss: 0.121787\n",
      "Train Epoch: 21 [39040/37879 (78%)]\tLoss: 0.093939\n",
      "Train Epoch: 21 [39680/37879 (79%)]\tLoss: 0.203516\n",
      "Train Epoch: 21 [40320/37879 (81%)]\tLoss: 0.220874\n",
      "Train Epoch: 21 [40960/37879 (82%)]\tLoss: 0.145808\n",
      "Train Epoch: 21 [41600/37879 (83%)]\tLoss: 0.170458\n",
      "Train Epoch: 21 [42240/37879 (84%)]\tLoss: 0.194591\n",
      "Train Epoch: 21 [42880/37879 (86%)]\tLoss: 0.265993\n",
      "Train Epoch: 21 [43520/37879 (87%)]\tLoss: 0.098149\n",
      "Train Epoch: 21 [44160/37879 (88%)]\tLoss: 0.172580\n",
      "Train Epoch: 21 [44800/37879 (90%)]\tLoss: 0.283366\n",
      "Train Epoch: 21 [45440/37879 (91%)]\tLoss: 0.159027\n",
      "Train Epoch: 21 [46080/37879 (92%)]\tLoss: 0.136217\n",
      "Train Epoch: 21 [46720/37879 (93%)]\tLoss: 0.179266\n",
      "Train Epoch: 21 [47360/37879 (95%)]\tLoss: 0.051489\n",
      "Train Epoch: 21 [48000/37879 (96%)]\tLoss: 0.175181\n",
      "Train Epoch: 21 [48640/37879 (97%)]\tLoss: 0.192765\n",
      "Train Epoch: 21 [49280/37879 (98%)]\tLoss: 0.181935\n",
      "Train Epoch: 21 [49920/37879 (100%)]\tLoss: 0.162298\n",
      "\n",
      "Test set: Avg. loss: 0.0428, Accuracy: 9863/10000 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/37879 (0%)]\tLoss: 0.155420\n",
      "Train Epoch: 22 [640/37879 (1%)]\tLoss: 0.193299\n",
      "Train Epoch: 22 [1280/37879 (3%)]\tLoss: 0.272635\n",
      "Train Epoch: 22 [1920/37879 (4%)]\tLoss: 0.264793\n",
      "Train Epoch: 22 [2560/37879 (5%)]\tLoss: 0.074520\n",
      "Train Epoch: 22 [3200/37879 (6%)]\tLoss: 0.142807\n",
      "Train Epoch: 22 [3840/37879 (8%)]\tLoss: 0.069196\n",
      "Train Epoch: 22 [4480/37879 (9%)]\tLoss: 0.246690\n",
      "Train Epoch: 22 [5120/37879 (10%)]\tLoss: 0.460318\n",
      "Train Epoch: 22 [5760/37879 (12%)]\tLoss: 0.108842\n",
      "Train Epoch: 22 [6400/37879 (13%)]\tLoss: 0.136349\n",
      "Train Epoch: 22 [7040/37879 (14%)]\tLoss: 0.220510\n",
      "Train Epoch: 22 [7680/37879 (15%)]\tLoss: 0.087389\n",
      "Train Epoch: 22 [8320/37879 (17%)]\tLoss: 0.105591\n",
      "Train Epoch: 22 [8960/37879 (18%)]\tLoss: 0.381307\n",
      "Train Epoch: 22 [9600/37879 (19%)]\tLoss: 0.103330\n",
      "Train Epoch: 22 [10240/37879 (20%)]\tLoss: 0.189832\n",
      "Train Epoch: 22 [10880/37879 (22%)]\tLoss: 0.156922\n",
      "Train Epoch: 22 [11520/37879 (23%)]\tLoss: 0.168206\n",
      "Train Epoch: 22 [12160/37879 (24%)]\tLoss: 0.297569\n",
      "Train Epoch: 22 [12800/37879 (26%)]\tLoss: 0.211751\n",
      "Train Epoch: 22 [13440/37879 (27%)]\tLoss: 0.262889\n",
      "Train Epoch: 22 [14080/37879 (28%)]\tLoss: 0.134272\n",
      "Train Epoch: 22 [14720/37879 (29%)]\tLoss: 0.205532\n",
      "Train Epoch: 22 [15360/37879 (31%)]\tLoss: 0.150418\n",
      "Train Epoch: 22 [16000/37879 (32%)]\tLoss: 0.087483\n",
      "Train Epoch: 22 [16640/37879 (33%)]\tLoss: 0.222970\n",
      "Train Epoch: 22 [17280/37879 (35%)]\tLoss: 0.162409\n",
      "Train Epoch: 22 [17920/37879 (36%)]\tLoss: 0.149595\n",
      "Train Epoch: 22 [18560/37879 (37%)]\tLoss: 0.594974\n",
      "Train Epoch: 22 [19200/37879 (38%)]\tLoss: 0.062721\n",
      "Train Epoch: 22 [19840/37879 (40%)]\tLoss: 0.152378\n",
      "Train Epoch: 22 [20480/37879 (41%)]\tLoss: 0.235315\n",
      "Train Epoch: 22 [21120/37879 (42%)]\tLoss: 0.352414\n",
      "Train Epoch: 22 [21760/37879 (43%)]\tLoss: 0.104638\n",
      "Train Epoch: 22 [22400/37879 (45%)]\tLoss: 0.156629\n",
      "Train Epoch: 22 [23040/37879 (46%)]\tLoss: 0.192618\n",
      "Train Epoch: 22 [23680/37879 (47%)]\tLoss: 0.215941\n",
      "Train Epoch: 22 [24320/37879 (49%)]\tLoss: 0.119212\n",
      "Train Epoch: 22 [24960/37879 (50%)]\tLoss: 0.176941\n",
      "Train Epoch: 22 [25600/37879 (51%)]\tLoss: 0.193320\n",
      "Train Epoch: 22 [26240/37879 (52%)]\tLoss: 0.161245\n",
      "Train Epoch: 22 [26880/37879 (54%)]\tLoss: 0.139557\n",
      "Train Epoch: 22 [27520/37879 (55%)]\tLoss: 0.273428\n",
      "Train Epoch: 22 [28160/37879 (56%)]\tLoss: 0.093262\n",
      "Train Epoch: 22 [28800/37879 (58%)]\tLoss: 0.077267\n",
      "Train Epoch: 22 [29440/37879 (59%)]\tLoss: 0.318279\n",
      "Train Epoch: 22 [30080/37879 (60%)]\tLoss: 0.115485\n",
      "Train Epoch: 22 [30720/37879 (61%)]\tLoss: 0.143668\n",
      "Train Epoch: 22 [31360/37879 (63%)]\tLoss: 0.217740\n",
      "Train Epoch: 22 [32000/37879 (64%)]\tLoss: 0.233670\n",
      "Train Epoch: 22 [32640/37879 (65%)]\tLoss: 0.254087\n",
      "Train Epoch: 22 [33280/37879 (66%)]\tLoss: 0.135770\n",
      "Train Epoch: 22 [33920/37879 (68%)]\tLoss: 0.116740\n",
      "Train Epoch: 22 [34560/37879 (69%)]\tLoss: 0.148074\n",
      "Train Epoch: 22 [35200/37879 (70%)]\tLoss: 0.129104\n",
      "Train Epoch: 22 [35840/37879 (72%)]\tLoss: 0.137026\n",
      "Train Epoch: 22 [36480/37879 (73%)]\tLoss: 0.142708\n",
      "Train Epoch: 22 [37120/37879 (74%)]\tLoss: 0.177049\n",
      "Train Epoch: 22 [37760/37879 (75%)]\tLoss: 0.214608\n",
      "Train Epoch: 22 [38400/37879 (77%)]\tLoss: 0.119009\n",
      "Train Epoch: 22 [39040/37879 (78%)]\tLoss: 0.140338\n",
      "Train Epoch: 22 [39680/37879 (79%)]\tLoss: 0.179142\n",
      "Train Epoch: 22 [40320/37879 (81%)]\tLoss: 0.112691\n",
      "Train Epoch: 22 [40960/37879 (82%)]\tLoss: 0.189194\n",
      "Train Epoch: 22 [41600/37879 (83%)]\tLoss: 0.191302\n",
      "Train Epoch: 22 [42240/37879 (84%)]\tLoss: 0.185419\n",
      "Train Epoch: 22 [42880/37879 (86%)]\tLoss: 0.230832\n",
      "Train Epoch: 22 [43520/37879 (87%)]\tLoss: 0.214904\n",
      "Train Epoch: 22 [44160/37879 (88%)]\tLoss: 0.082711\n",
      "Train Epoch: 22 [44800/37879 (90%)]\tLoss: 0.279689\n",
      "Train Epoch: 22 [45440/37879 (91%)]\tLoss: 0.104933\n",
      "Train Epoch: 22 [46080/37879 (92%)]\tLoss: 0.186459\n",
      "Train Epoch: 22 [46720/37879 (93%)]\tLoss: 0.175702\n",
      "Train Epoch: 22 [47360/37879 (95%)]\tLoss: 0.177310\n",
      "Train Epoch: 22 [48000/37879 (96%)]\tLoss: 0.209099\n",
      "Train Epoch: 22 [48640/37879 (97%)]\tLoss: 0.166985\n",
      "Train Epoch: 22 [49280/37879 (98%)]\tLoss: 0.219331\n",
      "Train Epoch: 22 [49920/37879 (100%)]\tLoss: 0.149153\n",
      "\n",
      "Test set: Avg. loss: 0.0416, Accuracy: 9869/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/37879 (0%)]\tLoss: 0.103380\n",
      "Train Epoch: 23 [640/37879 (1%)]\tLoss: 0.197687\n",
      "Train Epoch: 23 [1280/37879 (3%)]\tLoss: 0.164981\n",
      "Train Epoch: 23 [1920/37879 (4%)]\tLoss: 0.246680\n",
      "Train Epoch: 23 [2560/37879 (5%)]\tLoss: 0.235195\n",
      "Train Epoch: 23 [3200/37879 (6%)]\tLoss: 0.098673\n",
      "Train Epoch: 23 [3840/37879 (8%)]\tLoss: 0.161283\n",
      "Train Epoch: 23 [4480/37879 (9%)]\tLoss: 0.323908\n",
      "Train Epoch: 23 [5120/37879 (10%)]\tLoss: 0.152386\n",
      "Train Epoch: 23 [5760/37879 (12%)]\tLoss: 0.260595\n",
      "Train Epoch: 23 [6400/37879 (13%)]\tLoss: 0.362215\n",
      "Train Epoch: 23 [7040/37879 (14%)]\tLoss: 0.057848\n",
      "Train Epoch: 23 [7680/37879 (15%)]\tLoss: 0.158801\n",
      "Train Epoch: 23 [8320/37879 (17%)]\tLoss: 0.128617\n",
      "Train Epoch: 23 [8960/37879 (18%)]\tLoss: 0.111936\n",
      "Train Epoch: 23 [9600/37879 (19%)]\tLoss: 0.156642\n",
      "Train Epoch: 23 [10240/37879 (20%)]\tLoss: 0.157044\n",
      "Train Epoch: 23 [10880/37879 (22%)]\tLoss: 0.171491\n",
      "Train Epoch: 23 [11520/37879 (23%)]\tLoss: 0.199017\n",
      "Train Epoch: 23 [12160/37879 (24%)]\tLoss: 0.178504\n",
      "Train Epoch: 23 [12800/37879 (26%)]\tLoss: 0.127833\n",
      "Train Epoch: 23 [13440/37879 (27%)]\tLoss: 0.086853\n",
      "Train Epoch: 23 [14080/37879 (28%)]\tLoss: 0.070646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [14720/37879 (29%)]\tLoss: 0.182508\n",
      "Train Epoch: 23 [15360/37879 (31%)]\tLoss: 0.325548\n",
      "Train Epoch: 23 [16000/37879 (32%)]\tLoss: 0.117521\n",
      "Train Epoch: 23 [16640/37879 (33%)]\tLoss: 0.158729\n",
      "Train Epoch: 23 [17280/37879 (35%)]\tLoss: 0.126657\n",
      "Train Epoch: 23 [17920/37879 (36%)]\tLoss: 0.221716\n",
      "Train Epoch: 23 [18560/37879 (37%)]\tLoss: 0.372055\n",
      "Train Epoch: 23 [19200/37879 (38%)]\tLoss: 0.158599\n",
      "Train Epoch: 23 [19840/37879 (40%)]\tLoss: 0.163449\n",
      "Train Epoch: 23 [20480/37879 (41%)]\tLoss: 0.234585\n",
      "Train Epoch: 23 [21120/37879 (42%)]\tLoss: 0.093589\n",
      "Train Epoch: 23 [21760/37879 (43%)]\tLoss: 0.122035\n",
      "Train Epoch: 23 [22400/37879 (45%)]\tLoss: 0.168586\n",
      "Train Epoch: 23 [23040/37879 (46%)]\tLoss: 0.062435\n",
      "Train Epoch: 23 [23680/37879 (47%)]\tLoss: 0.300748\n",
      "Train Epoch: 23 [24320/37879 (49%)]\tLoss: 0.171021\n",
      "Train Epoch: 23 [24960/37879 (50%)]\tLoss: 0.194622\n",
      "Train Epoch: 23 [25600/37879 (51%)]\tLoss: 0.065172\n",
      "Train Epoch: 23 [26240/37879 (52%)]\tLoss: 0.212956\n",
      "Train Epoch: 23 [26880/37879 (54%)]\tLoss: 0.107036\n",
      "Train Epoch: 23 [27520/37879 (55%)]\tLoss: 0.192675\n",
      "Train Epoch: 23 [28160/37879 (56%)]\tLoss: 0.205126\n",
      "Train Epoch: 23 [28800/37879 (58%)]\tLoss: 0.154484\n",
      "Train Epoch: 23 [29440/37879 (59%)]\tLoss: 0.066711\n",
      "Train Epoch: 23 [30080/37879 (60%)]\tLoss: 0.121124\n",
      "Train Epoch: 23 [30720/37879 (61%)]\tLoss: 0.224231\n",
      "Train Epoch: 23 [31360/37879 (63%)]\tLoss: 0.240125\n",
      "Train Epoch: 23 [32000/37879 (64%)]\tLoss: 0.151325\n",
      "Train Epoch: 23 [32640/37879 (65%)]\tLoss: 0.246997\n",
      "Train Epoch: 23 [33280/37879 (66%)]\tLoss: 0.182833\n",
      "Train Epoch: 23 [33920/37879 (68%)]\tLoss: 0.187573\n",
      "Train Epoch: 23 [34560/37879 (69%)]\tLoss: 0.193770\n",
      "Train Epoch: 23 [35200/37879 (70%)]\tLoss: 0.110480\n",
      "Train Epoch: 23 [35840/37879 (72%)]\tLoss: 0.086855\n",
      "Train Epoch: 23 [36480/37879 (73%)]\tLoss: 0.116802\n",
      "Train Epoch: 23 [37120/37879 (74%)]\tLoss: 0.115096\n",
      "Train Epoch: 23 [37760/37879 (75%)]\tLoss: 0.092025\n",
      "Train Epoch: 23 [38400/37879 (77%)]\tLoss: 0.236183\n",
      "Train Epoch: 23 [39040/37879 (78%)]\tLoss: 0.168081\n",
      "Train Epoch: 23 [39680/37879 (79%)]\tLoss: 0.241170\n",
      "Train Epoch: 23 [40320/37879 (81%)]\tLoss: 0.081919\n",
      "Train Epoch: 23 [40960/37879 (82%)]\tLoss: 0.112759\n",
      "Train Epoch: 23 [41600/37879 (83%)]\tLoss: 0.132322\n",
      "Train Epoch: 23 [42240/37879 (84%)]\tLoss: 0.157819\n",
      "Train Epoch: 23 [42880/37879 (86%)]\tLoss: 0.055214\n",
      "Train Epoch: 23 [43520/37879 (87%)]\tLoss: 0.135796\n",
      "Train Epoch: 23 [44160/37879 (88%)]\tLoss: 0.214655\n",
      "Train Epoch: 23 [44800/37879 (90%)]\tLoss: 0.194773\n",
      "Train Epoch: 23 [45440/37879 (91%)]\tLoss: 0.079531\n",
      "Train Epoch: 23 [46080/37879 (92%)]\tLoss: 0.363638\n",
      "Train Epoch: 23 [46720/37879 (93%)]\tLoss: 0.212911\n",
      "Train Epoch: 23 [47360/37879 (95%)]\tLoss: 0.172774\n",
      "Train Epoch: 23 [48000/37879 (96%)]\tLoss: 0.268794\n",
      "Train Epoch: 23 [48640/37879 (97%)]\tLoss: 0.094678\n",
      "Train Epoch: 23 [49280/37879 (98%)]\tLoss: 0.156215\n",
      "Train Epoch: 23 [49920/37879 (100%)]\tLoss: 0.271468\n",
      "\n",
      "Test set: Avg. loss: 0.0410, Accuracy: 9867/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/37879 (0%)]\tLoss: 0.241493\n",
      "Train Epoch: 24 [640/37879 (1%)]\tLoss: 0.081591\n",
      "Train Epoch: 24 [1280/37879 (3%)]\tLoss: 0.100813\n",
      "Train Epoch: 24 [1920/37879 (4%)]\tLoss: 0.051553\n",
      "Train Epoch: 24 [2560/37879 (5%)]\tLoss: 0.284674\n",
      "Train Epoch: 24 [3200/37879 (6%)]\tLoss: 0.127493\n",
      "Train Epoch: 24 [3840/37879 (8%)]\tLoss: 0.042983\n",
      "Train Epoch: 24 [4480/37879 (9%)]\tLoss: 0.152009\n",
      "Train Epoch: 24 [5120/37879 (10%)]\tLoss: 0.214518\n",
      "Train Epoch: 24 [5760/37879 (12%)]\tLoss: 0.179886\n",
      "Train Epoch: 24 [6400/37879 (13%)]\tLoss: 0.124987\n",
      "Train Epoch: 24 [7040/37879 (14%)]\tLoss: 0.172912\n",
      "Train Epoch: 24 [7680/37879 (15%)]\tLoss: 0.158502\n",
      "Train Epoch: 24 [8320/37879 (17%)]\tLoss: 0.201993\n",
      "Train Epoch: 24 [8960/37879 (18%)]\tLoss: 0.096415\n",
      "Train Epoch: 24 [9600/37879 (19%)]\tLoss: 0.166164\n",
      "Train Epoch: 24 [10240/37879 (20%)]\tLoss: 0.096640\n",
      "Train Epoch: 24 [10880/37879 (22%)]\tLoss: 0.254001\n",
      "Train Epoch: 24 [11520/37879 (23%)]\tLoss: 0.084223\n",
      "Train Epoch: 24 [12160/37879 (24%)]\tLoss: 0.033970\n",
      "Train Epoch: 24 [12800/37879 (26%)]\tLoss: 0.215909\n",
      "Train Epoch: 24 [13440/37879 (27%)]\tLoss: 0.160952\n",
      "Train Epoch: 24 [14080/37879 (28%)]\tLoss: 0.265443\n",
      "Train Epoch: 24 [14720/37879 (29%)]\tLoss: 0.136184\n",
      "Train Epoch: 24 [15360/37879 (31%)]\tLoss: 0.031493\n",
      "Train Epoch: 24 [16000/37879 (32%)]\tLoss: 0.183377\n",
      "Train Epoch: 24 [16640/37879 (33%)]\tLoss: 0.160663\n",
      "Train Epoch: 24 [17280/37879 (35%)]\tLoss: 0.487391\n",
      "Train Epoch: 24 [17920/37879 (36%)]\tLoss: 0.068421\n",
      "Train Epoch: 24 [18560/37879 (37%)]\tLoss: 0.306950\n",
      "Train Epoch: 24 [19200/37879 (38%)]\tLoss: 0.138331\n",
      "Train Epoch: 24 [19840/37879 (40%)]\tLoss: 0.211714\n",
      "Train Epoch: 24 [20480/37879 (41%)]\tLoss: 0.254762\n",
      "Train Epoch: 24 [21120/37879 (42%)]\tLoss: 0.155485\n",
      "Train Epoch: 24 [21760/37879 (43%)]\tLoss: 0.198859\n",
      "Train Epoch: 24 [22400/37879 (45%)]\tLoss: 0.261821\n",
      "Train Epoch: 24 [23040/37879 (46%)]\tLoss: 0.138223\n",
      "Train Epoch: 24 [23680/37879 (47%)]\tLoss: 0.085210\n",
      "Train Epoch: 24 [24320/37879 (49%)]\tLoss: 0.118659\n",
      "Train Epoch: 24 [24960/37879 (50%)]\tLoss: 0.192201\n",
      "Train Epoch: 24 [25600/37879 (51%)]\tLoss: 0.117967\n",
      "Train Epoch: 24 [26240/37879 (52%)]\tLoss: 0.134314\n",
      "Train Epoch: 24 [26880/37879 (54%)]\tLoss: 0.238847\n",
      "Train Epoch: 24 [27520/37879 (55%)]\tLoss: 0.208505\n",
      "Train Epoch: 24 [28160/37879 (56%)]\tLoss: 0.120617\n",
      "Train Epoch: 24 [28800/37879 (58%)]\tLoss: 0.196084\n",
      "Train Epoch: 24 [29440/37879 (59%)]\tLoss: 0.094833\n",
      "Train Epoch: 24 [30080/37879 (60%)]\tLoss: 0.109739\n",
      "Train Epoch: 24 [30720/37879 (61%)]\tLoss: 0.044321\n",
      "Train Epoch: 24 [31360/37879 (63%)]\tLoss: 0.131895\n",
      "Train Epoch: 24 [32000/37879 (64%)]\tLoss: 0.185774\n",
      "Train Epoch: 24 [32640/37879 (65%)]\tLoss: 0.123857\n",
      "Train Epoch: 24 [33280/37879 (66%)]\tLoss: 0.304450\n",
      "Train Epoch: 24 [33920/37879 (68%)]\tLoss: 0.111748\n",
      "Train Epoch: 24 [34560/37879 (69%)]\tLoss: 0.097656\n",
      "Train Epoch: 24 [35200/37879 (70%)]\tLoss: 0.186839\n",
      "Train Epoch: 24 [35840/37879 (72%)]\tLoss: 0.149741\n",
      "Train Epoch: 24 [36480/37879 (73%)]\tLoss: 0.378215\n",
      "Train Epoch: 24 [37120/37879 (74%)]\tLoss: 0.105534\n",
      "Train Epoch: 24 [37760/37879 (75%)]\tLoss: 0.094257\n",
      "Train Epoch: 24 [38400/37879 (77%)]\tLoss: 0.153869\n",
      "Train Epoch: 24 [39040/37879 (78%)]\tLoss: 0.331039\n",
      "Train Epoch: 24 [39680/37879 (79%)]\tLoss: 0.156637\n",
      "Train Epoch: 24 [40320/37879 (81%)]\tLoss: 0.145112\n",
      "Train Epoch: 24 [40960/37879 (82%)]\tLoss: 0.159511\n",
      "Train Epoch: 24 [41600/37879 (83%)]\tLoss: 0.133524\n",
      "Train Epoch: 24 [42240/37879 (84%)]\tLoss: 0.415017\n",
      "Train Epoch: 24 [42880/37879 (86%)]\tLoss: 0.208468\n",
      "Train Epoch: 24 [43520/37879 (87%)]\tLoss: 0.120977\n",
      "Train Epoch: 24 [44160/37879 (88%)]\tLoss: 0.159736\n",
      "Train Epoch: 24 [44800/37879 (90%)]\tLoss: 0.095259\n",
      "Train Epoch: 24 [45440/37879 (91%)]\tLoss: 0.167275\n",
      "Train Epoch: 24 [46080/37879 (92%)]\tLoss: 0.353382\n",
      "Train Epoch: 24 [46720/37879 (93%)]\tLoss: 0.193502\n",
      "Train Epoch: 24 [47360/37879 (95%)]\tLoss: 0.144400\n",
      "Train Epoch: 24 [48000/37879 (96%)]\tLoss: 0.079358\n",
      "Train Epoch: 24 [48640/37879 (97%)]\tLoss: 0.088478\n",
      "Train Epoch: 24 [49280/37879 (98%)]\tLoss: 0.160595\n",
      "Train Epoch: 24 [49920/37879 (100%)]\tLoss: 0.098978\n",
      "\n",
      "Test set: Avg. loss: 0.0417, Accuracy: 9872/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/37879 (0%)]\tLoss: 0.213061\n",
      "Train Epoch: 25 [640/37879 (1%)]\tLoss: 0.064651\n",
      "Train Epoch: 25 [1280/37879 (3%)]\tLoss: 0.124544\n",
      "Train Epoch: 25 [1920/37879 (4%)]\tLoss: 0.194486\n",
      "Train Epoch: 25 [2560/37879 (5%)]\tLoss: 0.210356\n",
      "Train Epoch: 25 [3200/37879 (6%)]\tLoss: 0.158480\n",
      "Train Epoch: 25 [3840/37879 (8%)]\tLoss: 0.152618\n",
      "Train Epoch: 25 [4480/37879 (9%)]\tLoss: 0.268784\n",
      "Train Epoch: 25 [5120/37879 (10%)]\tLoss: 0.153489\n",
      "Train Epoch: 25 [5760/37879 (12%)]\tLoss: 0.070862\n",
      "Train Epoch: 25 [6400/37879 (13%)]\tLoss: 0.126901\n",
      "Train Epoch: 25 [7040/37879 (14%)]\tLoss: 0.066297\n",
      "Train Epoch: 25 [7680/37879 (15%)]\tLoss: 0.203611\n",
      "Train Epoch: 25 [8320/37879 (17%)]\tLoss: 0.150404\n",
      "Train Epoch: 25 [8960/37879 (18%)]\tLoss: 0.060026\n",
      "Train Epoch: 25 [9600/37879 (19%)]\tLoss: 0.090102\n",
      "Train Epoch: 25 [10240/37879 (20%)]\tLoss: 0.267159\n",
      "Train Epoch: 25 [10880/37879 (22%)]\tLoss: 0.310344\n",
      "Train Epoch: 25 [11520/37879 (23%)]\tLoss: 0.086836\n",
      "Train Epoch: 25 [12160/37879 (24%)]\tLoss: 0.116936\n",
      "Train Epoch: 25 [12800/37879 (26%)]\tLoss: 0.084302\n",
      "Train Epoch: 25 [13440/37879 (27%)]\tLoss: 0.090633\n",
      "Train Epoch: 25 [14080/37879 (28%)]\tLoss: 0.163782\n",
      "Train Epoch: 25 [14720/37879 (29%)]\tLoss: 0.222547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [15360/37879 (31%)]\tLoss: 0.114060\n",
      "Train Epoch: 25 [16000/37879 (32%)]\tLoss: 0.180793\n",
      "Train Epoch: 25 [16640/37879 (33%)]\tLoss: 0.133117\n",
      "Train Epoch: 25 [17280/37879 (35%)]\tLoss: 0.218761\n",
      "Train Epoch: 25 [17920/37879 (36%)]\tLoss: 0.151357\n",
      "Train Epoch: 25 [18560/37879 (37%)]\tLoss: 0.092322\n",
      "Train Epoch: 25 [19200/37879 (38%)]\tLoss: 0.091146\n",
      "Train Epoch: 25 [19840/37879 (40%)]\tLoss: 0.313754\n",
      "Train Epoch: 25 [20480/37879 (41%)]\tLoss: 0.134775\n",
      "Train Epoch: 25 [21120/37879 (42%)]\tLoss: 0.114153\n",
      "Train Epoch: 25 [21760/37879 (43%)]\tLoss: 0.217101\n",
      "Train Epoch: 25 [22400/37879 (45%)]\tLoss: 0.237640\n",
      "Train Epoch: 25 [23040/37879 (46%)]\tLoss: 0.063223\n",
      "Train Epoch: 25 [23680/37879 (47%)]\tLoss: 0.204766\n",
      "Train Epoch: 25 [24320/37879 (49%)]\tLoss: 0.142590\n",
      "Train Epoch: 25 [24960/37879 (50%)]\tLoss: 0.064319\n",
      "Train Epoch: 25 [25600/37879 (51%)]\tLoss: 0.270565\n",
      "Train Epoch: 25 [26240/37879 (52%)]\tLoss: 0.184976\n",
      "Train Epoch: 25 [26880/37879 (54%)]\tLoss: 0.255436\n",
      "Train Epoch: 25 [27520/37879 (55%)]\tLoss: 0.068095\n",
      "Train Epoch: 25 [28160/37879 (56%)]\tLoss: 0.085123\n",
      "Train Epoch: 25 [28800/37879 (58%)]\tLoss: 0.081556\n",
      "Train Epoch: 25 [29440/37879 (59%)]\tLoss: 0.129235\n",
      "Train Epoch: 25 [30080/37879 (60%)]\tLoss: 0.159976\n",
      "Train Epoch: 25 [30720/37879 (61%)]\tLoss: 0.112378\n",
      "Train Epoch: 25 [31360/37879 (63%)]\tLoss: 0.385709\n",
      "Train Epoch: 25 [32000/37879 (64%)]\tLoss: 0.437611\n",
      "Train Epoch: 25 [32640/37879 (65%)]\tLoss: 0.079240\n",
      "Train Epoch: 25 [33280/37879 (66%)]\tLoss: 0.093107\n",
      "Train Epoch: 25 [33920/37879 (68%)]\tLoss: 0.147509\n",
      "Train Epoch: 25 [34560/37879 (69%)]\tLoss: 0.119768\n",
      "Train Epoch: 25 [35200/37879 (70%)]\tLoss: 0.083814\n",
      "Train Epoch: 25 [35840/37879 (72%)]\tLoss: 0.121234\n",
      "Train Epoch: 25 [36480/37879 (73%)]\tLoss: 0.090092\n",
      "Train Epoch: 25 [37120/37879 (74%)]\tLoss: 0.284677\n",
      "Train Epoch: 25 [37760/37879 (75%)]\tLoss: 0.224108\n",
      "Train Epoch: 25 [38400/37879 (77%)]\tLoss: 0.161468\n",
      "Train Epoch: 25 [39040/37879 (78%)]\tLoss: 0.130088\n",
      "Train Epoch: 25 [39680/37879 (79%)]\tLoss: 0.129699\n",
      "Train Epoch: 25 [40320/37879 (81%)]\tLoss: 0.102972\n",
      "Train Epoch: 25 [40960/37879 (82%)]\tLoss: 0.206513\n",
      "Train Epoch: 25 [41600/37879 (83%)]\tLoss: 0.224794\n",
      "Train Epoch: 25 [42240/37879 (84%)]\tLoss: 0.228482\n",
      "Train Epoch: 25 [42880/37879 (86%)]\tLoss: 0.086140\n",
      "Train Epoch: 25 [43520/37879 (87%)]\tLoss: 0.096468\n",
      "Train Epoch: 25 [44160/37879 (88%)]\tLoss: 0.163852\n",
      "Train Epoch: 25 [44800/37879 (90%)]\tLoss: 0.167381\n",
      "Train Epoch: 25 [45440/37879 (91%)]\tLoss: 0.299305\n",
      "Train Epoch: 25 [46080/37879 (92%)]\tLoss: 0.193059\n",
      "Train Epoch: 25 [46720/37879 (93%)]\tLoss: 0.168225\n",
      "Train Epoch: 25 [47360/37879 (95%)]\tLoss: 0.094789\n",
      "Train Epoch: 25 [48000/37879 (96%)]\tLoss: 0.157724\n",
      "Train Epoch: 25 [48640/37879 (97%)]\tLoss: 0.125827\n",
      "Train Epoch: 25 [49280/37879 (98%)]\tLoss: 0.087154\n",
      "Train Epoch: 25 [49920/37879 (100%)]\tLoss: 0.113144\n",
      "\n",
      "Test set: Avg. loss: 0.0409, Accuracy: 9874/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network_balanced_linear = CNN()\n",
    "optimizer_balanced_linear = optim.SGD(network_balanced_linear.parameters(), lr=args.learning_rate, momentum=args.momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i * len(balanced_linear_loader) for i in range(args.n_epochs + 1)]\n",
    "\n",
    "test(network_balanced_linear)\n",
    "for epoch in range(1, args.n_epochs + 1):\n",
    "    train(epoch, balanced_linear_loader, network_balanced_linear, optimizer_balanced_linear)\n",
    "    test(network_balanced_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3123, Accuracy: 935/10000 (9%)\n",
      "\n",
      "Train Epoch: 1 [0/41964 (0%)]\tLoss: 2.324201\n",
      "Train Epoch: 1 [640/41964 (1%)]\tLoss: 2.256661\n",
      "Train Epoch: 1 [1280/41964 (3%)]\tLoss: 2.337394\n",
      "Train Epoch: 1 [1920/41964 (4%)]\tLoss: 2.276453\n",
      "Train Epoch: 1 [2560/41964 (5%)]\tLoss: 2.271804\n",
      "Train Epoch: 1 [3200/41964 (6%)]\tLoss: 2.258252\n",
      "Train Epoch: 1 [3840/41964 (8%)]\tLoss: 2.223268\n",
      "Train Epoch: 1 [4480/41964 (9%)]\tLoss: 2.240035\n",
      "Train Epoch: 1 [5120/41964 (10%)]\tLoss: 2.210395\n",
      "Train Epoch: 1 [5760/41964 (12%)]\tLoss: 2.073308\n",
      "Train Epoch: 1 [6400/41964 (13%)]\tLoss: 2.156110\n",
      "Train Epoch: 1 [7040/41964 (14%)]\tLoss: 1.958014\n",
      "Train Epoch: 1 [7680/41964 (15%)]\tLoss: 1.932250\n",
      "Train Epoch: 1 [8320/41964 (17%)]\tLoss: 1.868136\n",
      "Train Epoch: 1 [8960/41964 (18%)]\tLoss: 1.723988\n",
      "Train Epoch: 1 [9600/41964 (19%)]\tLoss: 1.802272\n",
      "Train Epoch: 1 [10240/41964 (20%)]\tLoss: 1.582659\n",
      "Train Epoch: 1 [10880/41964 (22%)]\tLoss: 1.489352\n",
      "Train Epoch: 1 [11520/41964 (23%)]\tLoss: 1.432522\n",
      "Train Epoch: 1 [12160/41964 (24%)]\tLoss: 1.352908\n",
      "Train Epoch: 1 [12800/41964 (26%)]\tLoss: 1.444276\n",
      "Train Epoch: 1 [13440/41964 (27%)]\tLoss: 1.354236\n",
      "Train Epoch: 1 [14080/41964 (28%)]\tLoss: 1.322723\n",
      "Train Epoch: 1 [14720/41964 (29%)]\tLoss: 1.205587\n",
      "Train Epoch: 1 [15360/41964 (31%)]\tLoss: 1.138310\n",
      "Train Epoch: 1 [16000/41964 (32%)]\tLoss: 0.921057\n",
      "Train Epoch: 1 [16640/41964 (33%)]\tLoss: 1.069442\n",
      "Train Epoch: 1 [17280/41964 (35%)]\tLoss: 1.151244\n",
      "Train Epoch: 1 [17920/41964 (36%)]\tLoss: 1.118114\n",
      "Train Epoch: 1 [18560/41964 (37%)]\tLoss: 1.077157\n",
      "Train Epoch: 1 [19200/41964 (38%)]\tLoss: 0.961664\n",
      "Train Epoch: 1 [19840/41964 (40%)]\tLoss: 0.855334\n",
      "Train Epoch: 1 [20480/41964 (41%)]\tLoss: 0.912056\n",
      "Train Epoch: 1 [21120/41964 (42%)]\tLoss: 0.933438\n",
      "Train Epoch: 1 [21760/41964 (43%)]\tLoss: 0.933175\n",
      "Train Epoch: 1 [22400/41964 (45%)]\tLoss: 0.691703\n",
      "Train Epoch: 1 [23040/41964 (46%)]\tLoss: 0.845342\n",
      "Train Epoch: 1 [23680/41964 (47%)]\tLoss: 0.988640\n",
      "Train Epoch: 1 [24320/41964 (49%)]\tLoss: 0.865961\n",
      "Train Epoch: 1 [24960/41964 (50%)]\tLoss: 0.932008\n",
      "Train Epoch: 1 [25600/41964 (51%)]\tLoss: 0.630208\n",
      "Train Epoch: 1 [26240/41964 (52%)]\tLoss: 0.642636\n",
      "Train Epoch: 1 [26880/41964 (54%)]\tLoss: 0.830883\n",
      "Train Epoch: 1 [27520/41964 (55%)]\tLoss: 0.748955\n",
      "Train Epoch: 1 [28160/41964 (56%)]\tLoss: 0.809329\n",
      "Train Epoch: 1 [28800/41964 (58%)]\tLoss: 0.644541\n",
      "Train Epoch: 1 [29440/41964 (59%)]\tLoss: 0.798625\n",
      "Train Epoch: 1 [30080/41964 (60%)]\tLoss: 0.895424\n",
      "Train Epoch: 1 [30720/41964 (61%)]\tLoss: 0.823967\n",
      "Train Epoch: 1 [31360/41964 (63%)]\tLoss: 0.704467\n",
      "Train Epoch: 1 [32000/41964 (64%)]\tLoss: 0.831123\n",
      "Train Epoch: 1 [32640/41964 (65%)]\tLoss: 0.480954\n",
      "Train Epoch: 1 [33280/41964 (66%)]\tLoss: 0.564102\n",
      "Train Epoch: 1 [33920/41964 (68%)]\tLoss: 0.561637\n",
      "Train Epoch: 1 [34560/41964 (69%)]\tLoss: 0.642414\n",
      "Train Epoch: 1 [35200/41964 (70%)]\tLoss: 0.642805\n",
      "Train Epoch: 1 [35840/41964 (72%)]\tLoss: 0.543761\n",
      "Train Epoch: 1 [36480/41964 (73%)]\tLoss: 0.771622\n",
      "Train Epoch: 1 [37120/41964 (74%)]\tLoss: 0.549094\n",
      "Train Epoch: 1 [37760/41964 (75%)]\tLoss: 0.714032\n",
      "Train Epoch: 1 [38400/41964 (77%)]\tLoss: 0.668403\n",
      "Train Epoch: 1 [39040/41964 (78%)]\tLoss: 0.700073\n",
      "Train Epoch: 1 [39680/41964 (79%)]\tLoss: 0.668418\n",
      "Train Epoch: 1 [40320/41964 (81%)]\tLoss: 0.690754\n",
      "Train Epoch: 1 [40960/41964 (82%)]\tLoss: 0.750129\n",
      "Train Epoch: 1 [41600/41964 (83%)]\tLoss: 0.685601\n",
      "Train Epoch: 1 [42240/41964 (84%)]\tLoss: 0.543279\n",
      "Train Epoch: 1 [42880/41964 (86%)]\tLoss: 0.624271\n",
      "Train Epoch: 1 [43520/41964 (87%)]\tLoss: 0.558315\n",
      "Train Epoch: 1 [44160/41964 (88%)]\tLoss: 0.840827\n",
      "Train Epoch: 1 [44800/41964 (90%)]\tLoss: 0.589124\n",
      "Train Epoch: 1 [45440/41964 (91%)]\tLoss: 0.539948\n",
      "Train Epoch: 1 [46080/41964 (92%)]\tLoss: 0.574107\n",
      "Train Epoch: 1 [46720/41964 (93%)]\tLoss: 0.669550\n",
      "Train Epoch: 1 [47360/41964 (95%)]\tLoss: 0.588949\n",
      "Train Epoch: 1 [48000/41964 (96%)]\tLoss: 0.379063\n",
      "Train Epoch: 1 [48640/41964 (97%)]\tLoss: 0.513623\n",
      "Train Epoch: 1 [49280/41964 (98%)]\tLoss: 0.662792\n",
      "Train Epoch: 1 [49920/41964 (100%)]\tLoss: 0.424385\n",
      "\n",
      "Test set: Avg. loss: 0.2515, Accuracy: 9288/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/41964 (0%)]\tLoss: 0.586675\n",
      "Train Epoch: 2 [640/41964 (1%)]\tLoss: 0.545021\n",
      "Train Epoch: 2 [1280/41964 (3%)]\tLoss: 0.575428\n",
      "Train Epoch: 2 [1920/41964 (4%)]\tLoss: 0.515963\n",
      "Train Epoch: 2 [2560/41964 (5%)]\tLoss: 0.472735\n",
      "Train Epoch: 2 [3200/41964 (6%)]\tLoss: 0.772320\n",
      "Train Epoch: 2 [3840/41964 (8%)]\tLoss: 0.721423\n",
      "Train Epoch: 2 [4480/41964 (9%)]\tLoss: 0.703211\n",
      "Train Epoch: 2 [5120/41964 (10%)]\tLoss: 0.398371\n",
      "Train Epoch: 2 [5760/41964 (12%)]\tLoss: 0.704001\n",
      "Train Epoch: 2 [6400/41964 (13%)]\tLoss: 0.409371\n",
      "Train Epoch: 2 [7040/41964 (14%)]\tLoss: 0.390009\n",
      "Train Epoch: 2 [7680/41964 (15%)]\tLoss: 0.370789\n",
      "Train Epoch: 2 [8320/41964 (17%)]\tLoss: 0.660755\n",
      "Train Epoch: 2 [8960/41964 (18%)]\tLoss: 0.660576\n",
      "Train Epoch: 2 [9600/41964 (19%)]\tLoss: 0.317300\n",
      "Train Epoch: 2 [10240/41964 (20%)]\tLoss: 0.263894\n",
      "Train Epoch: 2 [10880/41964 (22%)]\tLoss: 0.701672\n",
      "Train Epoch: 2 [11520/41964 (23%)]\tLoss: 0.944592\n",
      "Train Epoch: 2 [12160/41964 (24%)]\tLoss: 0.653408\n",
      "Train Epoch: 2 [12800/41964 (26%)]\tLoss: 0.471136\n",
      "Train Epoch: 2 [13440/41964 (27%)]\tLoss: 0.813271\n",
      "Train Epoch: 2 [14080/41964 (28%)]\tLoss: 0.462878\n",
      "Train Epoch: 2 [14720/41964 (29%)]\tLoss: 0.397417\n",
      "Train Epoch: 2 [15360/41964 (31%)]\tLoss: 0.473801\n",
      "Train Epoch: 2 [16000/41964 (32%)]\tLoss: 0.525331\n",
      "Train Epoch: 2 [16640/41964 (33%)]\tLoss: 0.409244\n",
      "Train Epoch: 2 [17280/41964 (35%)]\tLoss: 0.670482\n",
      "Train Epoch: 2 [17920/41964 (36%)]\tLoss: 0.514762\n",
      "Train Epoch: 2 [18560/41964 (37%)]\tLoss: 0.412071\n",
      "Train Epoch: 2 [19200/41964 (38%)]\tLoss: 0.689241\n",
      "Train Epoch: 2 [19840/41964 (40%)]\tLoss: 0.522617\n",
      "Train Epoch: 2 [20480/41964 (41%)]\tLoss: 0.427040\n",
      "Train Epoch: 2 [21120/41964 (42%)]\tLoss: 0.471946\n",
      "Train Epoch: 2 [21760/41964 (43%)]\tLoss: 0.364284\n",
      "Train Epoch: 2 [22400/41964 (45%)]\tLoss: 0.434140\n",
      "Train Epoch: 2 [23040/41964 (46%)]\tLoss: 0.267156\n",
      "Train Epoch: 2 [23680/41964 (47%)]\tLoss: 0.531883\n",
      "Train Epoch: 2 [24320/41964 (49%)]\tLoss: 0.376386\n",
      "Train Epoch: 2 [24960/41964 (50%)]\tLoss: 0.367134\n",
      "Train Epoch: 2 [25600/41964 (51%)]\tLoss: 0.758847\n",
      "Train Epoch: 2 [26240/41964 (52%)]\tLoss: 0.447045\n",
      "Train Epoch: 2 [26880/41964 (54%)]\tLoss: 0.580572\n",
      "Train Epoch: 2 [27520/41964 (55%)]\tLoss: 0.615109\n",
      "Train Epoch: 2 [28160/41964 (56%)]\tLoss: 0.427203\n",
      "Train Epoch: 2 [28800/41964 (58%)]\tLoss: 0.435108\n",
      "Train Epoch: 2 [29440/41964 (59%)]\tLoss: 0.594802\n",
      "Train Epoch: 2 [30080/41964 (60%)]\tLoss: 0.458348\n",
      "Train Epoch: 2 [30720/41964 (61%)]\tLoss: 0.505541\n",
      "Train Epoch: 2 [31360/41964 (63%)]\tLoss: 0.458417\n",
      "Train Epoch: 2 [32000/41964 (64%)]\tLoss: 0.582930\n",
      "Train Epoch: 2 [32640/41964 (65%)]\tLoss: 0.544275\n",
      "Train Epoch: 2 [33280/41964 (66%)]\tLoss: 0.532168\n",
      "Train Epoch: 2 [33920/41964 (68%)]\tLoss: 0.279004\n",
      "Train Epoch: 2 [34560/41964 (69%)]\tLoss: 0.363797\n",
      "Train Epoch: 2 [35200/41964 (70%)]\tLoss: 0.614363\n",
      "Train Epoch: 2 [35840/41964 (72%)]\tLoss: 0.253526\n",
      "Train Epoch: 2 [36480/41964 (73%)]\tLoss: 0.452392\n",
      "Train Epoch: 2 [37120/41964 (74%)]\tLoss: 0.266988\n",
      "Train Epoch: 2 [37760/41964 (75%)]\tLoss: 0.554213\n",
      "Train Epoch: 2 [38400/41964 (77%)]\tLoss: 0.446379\n",
      "Train Epoch: 2 [39040/41964 (78%)]\tLoss: 0.698999\n",
      "Train Epoch: 2 [39680/41964 (79%)]\tLoss: 0.400043\n",
      "Train Epoch: 2 [40320/41964 (81%)]\tLoss: 0.681897\n",
      "Train Epoch: 2 [40960/41964 (82%)]\tLoss: 0.382305\n",
      "Train Epoch: 2 [41600/41964 (83%)]\tLoss: 0.418783\n",
      "Train Epoch: 2 [42240/41964 (84%)]\tLoss: 0.299856\n",
      "Train Epoch: 2 [42880/41964 (86%)]\tLoss: 0.363785\n",
      "Train Epoch: 2 [43520/41964 (87%)]\tLoss: 0.465451\n",
      "Train Epoch: 2 [44160/41964 (88%)]\tLoss: 0.418056\n",
      "Train Epoch: 2 [44800/41964 (90%)]\tLoss: 0.369564\n",
      "Train Epoch: 2 [45440/41964 (91%)]\tLoss: 0.387606\n",
      "Train Epoch: 2 [46080/41964 (92%)]\tLoss: 0.539552\n",
      "Train Epoch: 2 [46720/41964 (93%)]\tLoss: 0.449169\n",
      "Train Epoch: 2 [47360/41964 (95%)]\tLoss: 0.563353\n",
      "Train Epoch: 2 [48000/41964 (96%)]\tLoss: 0.447461\n",
      "Train Epoch: 2 [48640/41964 (97%)]\tLoss: 0.315490\n",
      "Train Epoch: 2 [49280/41964 (98%)]\tLoss: 0.258131\n",
      "Train Epoch: 2 [49920/41964 (100%)]\tLoss: 0.268838\n",
      "\n",
      "Test set: Avg. loss: 0.1512, Accuracy: 9549/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/41964 (0%)]\tLoss: 0.484258\n",
      "Train Epoch: 3 [640/41964 (1%)]\tLoss: 0.558696\n",
      "Train Epoch: 3 [1280/41964 (3%)]\tLoss: 0.484913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [1920/41964 (4%)]\tLoss: 0.429385\n",
      "Train Epoch: 3 [2560/41964 (5%)]\tLoss: 0.271612\n",
      "Train Epoch: 3 [3200/41964 (6%)]\tLoss: 0.562618\n",
      "Train Epoch: 3 [3840/41964 (8%)]\tLoss: 0.267329\n",
      "Train Epoch: 3 [4480/41964 (9%)]\tLoss: 0.374646\n",
      "Train Epoch: 3 [5120/41964 (10%)]\tLoss: 0.438730\n",
      "Train Epoch: 3 [5760/41964 (12%)]\tLoss: 0.369071\n",
      "Train Epoch: 3 [6400/41964 (13%)]\tLoss: 0.553568\n",
      "Train Epoch: 3 [7040/41964 (14%)]\tLoss: 0.527731\n",
      "Train Epoch: 3 [7680/41964 (15%)]\tLoss: 0.420581\n",
      "Train Epoch: 3 [8320/41964 (17%)]\tLoss: 0.370480\n",
      "Train Epoch: 3 [8960/41964 (18%)]\tLoss: 0.210446\n",
      "Train Epoch: 3 [9600/41964 (19%)]\tLoss: 0.390866\n",
      "Train Epoch: 3 [10240/41964 (20%)]\tLoss: 0.734242\n",
      "Train Epoch: 3 [10880/41964 (22%)]\tLoss: 0.246486\n",
      "Train Epoch: 3 [11520/41964 (23%)]\tLoss: 0.389965\n",
      "Train Epoch: 3 [12160/41964 (24%)]\tLoss: 0.437879\n",
      "Train Epoch: 3 [12800/41964 (26%)]\tLoss: 0.254929\n",
      "Train Epoch: 3 [13440/41964 (27%)]\tLoss: 0.523341\n",
      "Train Epoch: 3 [14080/41964 (28%)]\tLoss: 0.301496\n",
      "Train Epoch: 3 [14720/41964 (29%)]\tLoss: 0.389552\n",
      "Train Epoch: 3 [15360/41964 (31%)]\tLoss: 0.243012\n",
      "Train Epoch: 3 [16000/41964 (32%)]\tLoss: 0.388446\n",
      "Train Epoch: 3 [16640/41964 (33%)]\tLoss: 0.458369\n",
      "Train Epoch: 3 [17280/41964 (35%)]\tLoss: 0.541110\n",
      "Train Epoch: 3 [17920/41964 (36%)]\tLoss: 0.547544\n",
      "Train Epoch: 3 [18560/41964 (37%)]\tLoss: 0.548507\n",
      "Train Epoch: 3 [19200/41964 (38%)]\tLoss: 0.555259\n",
      "Train Epoch: 3 [19840/41964 (40%)]\tLoss: 0.315459\n",
      "Train Epoch: 3 [20480/41964 (41%)]\tLoss: 0.402409\n",
      "Train Epoch: 3 [21120/41964 (42%)]\tLoss: 0.310009\n",
      "Train Epoch: 3 [21760/41964 (43%)]\tLoss: 0.188063\n",
      "Train Epoch: 3 [22400/41964 (45%)]\tLoss: 0.262049\n",
      "Train Epoch: 3 [23040/41964 (46%)]\tLoss: 0.394877\n",
      "Train Epoch: 3 [23680/41964 (47%)]\tLoss: 0.480708\n",
      "Train Epoch: 3 [24320/41964 (49%)]\tLoss: 0.293073\n",
      "Train Epoch: 3 [24960/41964 (50%)]\tLoss: 0.365325\n",
      "Train Epoch: 3 [25600/41964 (51%)]\tLoss: 0.366488\n",
      "Train Epoch: 3 [26240/41964 (52%)]\tLoss: 0.335599\n",
      "Train Epoch: 3 [26880/41964 (54%)]\tLoss: 0.424125\n",
      "Train Epoch: 3 [27520/41964 (55%)]\tLoss: 0.327208\n",
      "Train Epoch: 3 [28160/41964 (56%)]\tLoss: 0.400558\n",
      "Train Epoch: 3 [28800/41964 (58%)]\tLoss: 0.291355\n",
      "Train Epoch: 3 [29440/41964 (59%)]\tLoss: 0.408226\n",
      "Train Epoch: 3 [30080/41964 (60%)]\tLoss: 0.322339\n",
      "Train Epoch: 3 [30720/41964 (61%)]\tLoss: 0.363651\n",
      "Train Epoch: 3 [31360/41964 (63%)]\tLoss: 0.556009\n",
      "Train Epoch: 3 [32000/41964 (64%)]\tLoss: 0.329190\n",
      "Train Epoch: 3 [32640/41964 (65%)]\tLoss: 0.315665\n",
      "Train Epoch: 3 [33280/41964 (66%)]\tLoss: 0.425966\n",
      "Train Epoch: 3 [33920/41964 (68%)]\tLoss: 0.289567\n",
      "Train Epoch: 3 [34560/41964 (69%)]\tLoss: 0.322063\n",
      "Train Epoch: 3 [35200/41964 (70%)]\tLoss: 0.249020\n",
      "Train Epoch: 3 [35840/41964 (72%)]\tLoss: 0.340671\n",
      "Train Epoch: 3 [36480/41964 (73%)]\tLoss: 0.334513\n",
      "Train Epoch: 3 [37120/41964 (74%)]\tLoss: 0.560861\n",
      "Train Epoch: 3 [37760/41964 (75%)]\tLoss: 0.326434\n",
      "Train Epoch: 3 [38400/41964 (77%)]\tLoss: 0.422865\n",
      "Train Epoch: 3 [39040/41964 (78%)]\tLoss: 0.364285\n",
      "Train Epoch: 3 [39680/41964 (79%)]\tLoss: 0.481878\n",
      "Train Epoch: 3 [40320/41964 (81%)]\tLoss: 0.569346\n",
      "Train Epoch: 3 [40960/41964 (82%)]\tLoss: 0.306074\n",
      "Train Epoch: 3 [41600/41964 (83%)]\tLoss: 0.572048\n",
      "Train Epoch: 3 [42240/41964 (84%)]\tLoss: 0.419202\n",
      "Train Epoch: 3 [42880/41964 (86%)]\tLoss: 0.265097\n",
      "Train Epoch: 3 [43520/41964 (87%)]\tLoss: 0.313500\n",
      "Train Epoch: 3 [44160/41964 (88%)]\tLoss: 0.285082\n",
      "Train Epoch: 3 [44800/41964 (90%)]\tLoss: 0.198307\n",
      "Train Epoch: 3 [45440/41964 (91%)]\tLoss: 0.215765\n",
      "Train Epoch: 3 [46080/41964 (92%)]\tLoss: 0.202969\n",
      "Train Epoch: 3 [46720/41964 (93%)]\tLoss: 0.498365\n",
      "Train Epoch: 3 [47360/41964 (95%)]\tLoss: 0.364217\n",
      "Train Epoch: 3 [48000/41964 (96%)]\tLoss: 0.361203\n",
      "Train Epoch: 3 [48640/41964 (97%)]\tLoss: 0.195973\n",
      "Train Epoch: 3 [49280/41964 (98%)]\tLoss: 0.225351\n",
      "Train Epoch: 3 [49920/41964 (100%)]\tLoss: 0.284559\n",
      "\n",
      "Test set: Avg. loss: 0.1197, Accuracy: 9649/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/41964 (0%)]\tLoss: 0.398413\n",
      "Train Epoch: 4 [640/41964 (1%)]\tLoss: 0.534175\n",
      "Train Epoch: 4 [1280/41964 (3%)]\tLoss: 0.295993\n",
      "Train Epoch: 4 [1920/41964 (4%)]\tLoss: 0.278467\n",
      "Train Epoch: 4 [2560/41964 (5%)]\tLoss: 0.376821\n",
      "Train Epoch: 4 [3200/41964 (6%)]\tLoss: 0.374168\n",
      "Train Epoch: 4 [3840/41964 (8%)]\tLoss: 0.388474\n",
      "Train Epoch: 4 [4480/41964 (9%)]\tLoss: 0.391720\n",
      "Train Epoch: 4 [5120/41964 (10%)]\tLoss: 0.397983\n",
      "Train Epoch: 4 [5760/41964 (12%)]\tLoss: 0.452857\n",
      "Train Epoch: 4 [6400/41964 (13%)]\tLoss: 0.376690\n",
      "Train Epoch: 4 [7040/41964 (14%)]\tLoss: 0.253777\n",
      "Train Epoch: 4 [7680/41964 (15%)]\tLoss: 0.551898\n",
      "Train Epoch: 4 [8320/41964 (17%)]\tLoss: 0.703164\n",
      "Train Epoch: 4 [8960/41964 (18%)]\tLoss: 0.373011\n",
      "Train Epoch: 4 [9600/41964 (19%)]\tLoss: 0.340773\n",
      "Train Epoch: 4 [10240/41964 (20%)]\tLoss: 0.326597\n",
      "Train Epoch: 4 [10880/41964 (22%)]\tLoss: 0.206275\n",
      "Train Epoch: 4 [11520/41964 (23%)]\tLoss: 0.631009\n",
      "Train Epoch: 4 [12160/41964 (24%)]\tLoss: 0.236648\n",
      "Train Epoch: 4 [12800/41964 (26%)]\tLoss: 0.264031\n",
      "Train Epoch: 4 [13440/41964 (27%)]\tLoss: 0.619804\n",
      "Train Epoch: 4 [14080/41964 (28%)]\tLoss: 0.278244\n",
      "Train Epoch: 4 [14720/41964 (29%)]\tLoss: 0.399976\n",
      "Train Epoch: 4 [15360/41964 (31%)]\tLoss: 0.497001\n",
      "Train Epoch: 4 [16000/41964 (32%)]\tLoss: 0.272961\n",
      "Train Epoch: 4 [16640/41964 (33%)]\tLoss: 0.217338\n",
      "Train Epoch: 4 [17280/41964 (35%)]\tLoss: 0.363764\n",
      "Train Epoch: 4 [17920/41964 (36%)]\tLoss: 0.394376\n",
      "Train Epoch: 4 [18560/41964 (37%)]\tLoss: 0.332767\n",
      "Train Epoch: 4 [19200/41964 (38%)]\tLoss: 0.229894\n",
      "Train Epoch: 4 [19840/41964 (40%)]\tLoss: 0.560975\n",
      "Train Epoch: 4 [20480/41964 (41%)]\tLoss: 0.454443\n",
      "Train Epoch: 4 [21120/41964 (42%)]\tLoss: 0.291384\n",
      "Train Epoch: 4 [21760/41964 (43%)]\tLoss: 0.333445\n",
      "Train Epoch: 4 [22400/41964 (45%)]\tLoss: 0.200829\n",
      "Train Epoch: 4 [23040/41964 (46%)]\tLoss: 0.221504\n",
      "Train Epoch: 4 [23680/41964 (47%)]\tLoss: 0.280090\n",
      "Train Epoch: 4 [24320/41964 (49%)]\tLoss: 0.107993\n",
      "Train Epoch: 4 [24960/41964 (50%)]\tLoss: 0.231857\n",
      "Train Epoch: 4 [25600/41964 (51%)]\tLoss: 0.235030\n",
      "Train Epoch: 4 [26240/41964 (52%)]\tLoss: 0.514606\n",
      "Train Epoch: 4 [26880/41964 (54%)]\tLoss: 0.168024\n",
      "Train Epoch: 4 [27520/41964 (55%)]\tLoss: 0.206119\n",
      "Train Epoch: 4 [28160/41964 (56%)]\tLoss: 0.400736\n",
      "Train Epoch: 4 [28800/41964 (58%)]\tLoss: 0.423176\n",
      "Train Epoch: 4 [29440/41964 (59%)]\tLoss: 0.426701\n",
      "Train Epoch: 4 [30080/41964 (60%)]\tLoss: 0.378321\n",
      "Train Epoch: 4 [30720/41964 (61%)]\tLoss: 0.138852\n",
      "Train Epoch: 4 [31360/41964 (63%)]\tLoss: 0.404068\n",
      "Train Epoch: 4 [32000/41964 (64%)]\tLoss: 0.211230\n",
      "Train Epoch: 4 [32640/41964 (65%)]\tLoss: 0.329641\n",
      "Train Epoch: 4 [33280/41964 (66%)]\tLoss: 0.423592\n",
      "Train Epoch: 4 [33920/41964 (68%)]\tLoss: 0.269515\n",
      "Train Epoch: 4 [34560/41964 (69%)]\tLoss: 0.262371\n",
      "Train Epoch: 4 [35200/41964 (70%)]\tLoss: 0.312063\n",
      "Train Epoch: 4 [35840/41964 (72%)]\tLoss: 0.214299\n",
      "Train Epoch: 4 [36480/41964 (73%)]\tLoss: 0.395065\n",
      "Train Epoch: 4 [37120/41964 (74%)]\tLoss: 0.331273\n",
      "Train Epoch: 4 [37760/41964 (75%)]\tLoss: 0.322113\n",
      "Train Epoch: 4 [38400/41964 (77%)]\tLoss: 0.475830\n",
      "Train Epoch: 4 [39040/41964 (78%)]\tLoss: 0.309701\n",
      "Train Epoch: 4 [39680/41964 (79%)]\tLoss: 0.383911\n",
      "Train Epoch: 4 [40320/41964 (81%)]\tLoss: 0.346871\n",
      "Train Epoch: 4 [40960/41964 (82%)]\tLoss: 0.231358\n",
      "Train Epoch: 4 [41600/41964 (83%)]\tLoss: 0.530724\n",
      "Train Epoch: 4 [42240/41964 (84%)]\tLoss: 0.233085\n",
      "Train Epoch: 4 [42880/41964 (86%)]\tLoss: 0.555969\n",
      "Train Epoch: 4 [43520/41964 (87%)]\tLoss: 0.386665\n",
      "Train Epoch: 4 [44160/41964 (88%)]\tLoss: 0.408810\n",
      "Train Epoch: 4 [44800/41964 (90%)]\tLoss: 0.273113\n",
      "Train Epoch: 4 [45440/41964 (91%)]\tLoss: 0.399846\n",
      "Train Epoch: 4 [46080/41964 (92%)]\tLoss: 0.166339\n",
      "Train Epoch: 4 [46720/41964 (93%)]\tLoss: 0.391037\n",
      "Train Epoch: 4 [47360/41964 (95%)]\tLoss: 0.153226\n",
      "Train Epoch: 4 [48000/41964 (96%)]\tLoss: 0.267094\n",
      "Train Epoch: 4 [48640/41964 (97%)]\tLoss: 0.246642\n",
      "Train Epoch: 4 [49280/41964 (98%)]\tLoss: 0.355717\n",
      "Train Epoch: 4 [49920/41964 (100%)]\tLoss: 0.259466\n",
      "\n",
      "Test set: Avg. loss: 0.1037, Accuracy: 9700/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/41964 (0%)]\tLoss: 0.605030\n",
      "Train Epoch: 5 [640/41964 (1%)]\tLoss: 0.307867\n",
      "Train Epoch: 5 [1280/41964 (3%)]\tLoss: 0.448231\n",
      "Train Epoch: 5 [1920/41964 (4%)]\tLoss: 0.272820\n",
      "Train Epoch: 5 [2560/41964 (5%)]\tLoss: 0.400946\n",
      "Train Epoch: 5 [3200/41964 (6%)]\tLoss: 0.363914\n",
      "Train Epoch: 5 [3840/41964 (8%)]\tLoss: 0.300549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [4480/41964 (9%)]\tLoss: 0.284210\n",
      "Train Epoch: 5 [5120/41964 (10%)]\tLoss: 0.275990\n",
      "Train Epoch: 5 [5760/41964 (12%)]\tLoss: 0.457277\n",
      "Train Epoch: 5 [6400/41964 (13%)]\tLoss: 0.343838\n",
      "Train Epoch: 5 [7040/41964 (14%)]\tLoss: 0.170489\n",
      "Train Epoch: 5 [7680/41964 (15%)]\tLoss: 0.239555\n",
      "Train Epoch: 5 [8320/41964 (17%)]\tLoss: 0.224252\n",
      "Train Epoch: 5 [8960/41964 (18%)]\tLoss: 0.437919\n",
      "Train Epoch: 5 [9600/41964 (19%)]\tLoss: 0.267377\n",
      "Train Epoch: 5 [10240/41964 (20%)]\tLoss: 0.388821\n",
      "Train Epoch: 5 [10880/41964 (22%)]\tLoss: 0.433458\n",
      "Train Epoch: 5 [11520/41964 (23%)]\tLoss: 0.285546\n",
      "Train Epoch: 5 [12160/41964 (24%)]\tLoss: 0.363283\n",
      "Train Epoch: 5 [12800/41964 (26%)]\tLoss: 0.183065\n",
      "Train Epoch: 5 [13440/41964 (27%)]\tLoss: 0.289997\n",
      "Train Epoch: 5 [14080/41964 (28%)]\tLoss: 0.365388\n",
      "Train Epoch: 5 [14720/41964 (29%)]\tLoss: 0.202032\n",
      "Train Epoch: 5 [15360/41964 (31%)]\tLoss: 0.178430\n",
      "Train Epoch: 5 [16000/41964 (32%)]\tLoss: 0.287213\n",
      "Train Epoch: 5 [16640/41964 (33%)]\tLoss: 0.302881\n",
      "Train Epoch: 5 [17280/41964 (35%)]\tLoss: 0.350991\n",
      "Train Epoch: 5 [17920/41964 (36%)]\tLoss: 0.187161\n",
      "Train Epoch: 5 [18560/41964 (37%)]\tLoss: 0.280844\n",
      "Train Epoch: 5 [19200/41964 (38%)]\tLoss: 0.308412\n",
      "Train Epoch: 5 [19840/41964 (40%)]\tLoss: 0.218316\n",
      "Train Epoch: 5 [20480/41964 (41%)]\tLoss: 0.365133\n",
      "Train Epoch: 5 [21120/41964 (42%)]\tLoss: 0.344530\n",
      "Train Epoch: 5 [21760/41964 (43%)]\tLoss: 0.164613\n",
      "Train Epoch: 5 [22400/41964 (45%)]\tLoss: 0.322942\n",
      "Train Epoch: 5 [23040/41964 (46%)]\tLoss: 0.253630\n",
      "Train Epoch: 5 [23680/41964 (47%)]\tLoss: 0.301553\n",
      "Train Epoch: 5 [24320/41964 (49%)]\tLoss: 0.349676\n",
      "Train Epoch: 5 [24960/41964 (50%)]\tLoss: 0.192352\n",
      "Train Epoch: 5 [25600/41964 (51%)]\tLoss: 0.139128\n",
      "Train Epoch: 5 [26240/41964 (52%)]\tLoss: 0.277772\n",
      "Train Epoch: 5 [26880/41964 (54%)]\tLoss: 0.385717\n",
      "Train Epoch: 5 [27520/41964 (55%)]\tLoss: 0.415798\n",
      "Train Epoch: 5 [28160/41964 (56%)]\tLoss: 0.147757\n",
      "Train Epoch: 5 [28800/41964 (58%)]\tLoss: 0.262031\n",
      "Train Epoch: 5 [29440/41964 (59%)]\tLoss: 0.241164\n",
      "Train Epoch: 5 [30080/41964 (60%)]\tLoss: 0.218100\n",
      "Train Epoch: 5 [30720/41964 (61%)]\tLoss: 0.343648\n",
      "Train Epoch: 5 [31360/41964 (63%)]\tLoss: 0.276460\n",
      "Train Epoch: 5 [32000/41964 (64%)]\tLoss: 0.218453\n",
      "Train Epoch: 5 [32640/41964 (65%)]\tLoss: 0.358055\n",
      "Train Epoch: 5 [33280/41964 (66%)]\tLoss: 0.200925\n",
      "Train Epoch: 5 [33920/41964 (68%)]\tLoss: 0.169239\n",
      "Train Epoch: 5 [34560/41964 (69%)]\tLoss: 0.278348\n",
      "Train Epoch: 5 [35200/41964 (70%)]\tLoss: 0.087248\n",
      "Train Epoch: 5 [35840/41964 (72%)]\tLoss: 0.197146\n",
      "Train Epoch: 5 [36480/41964 (73%)]\tLoss: 0.220579\n",
      "Train Epoch: 5 [37120/41964 (74%)]\tLoss: 0.251096\n",
      "Train Epoch: 5 [37760/41964 (75%)]\tLoss: 0.263951\n",
      "Train Epoch: 5 [38400/41964 (77%)]\tLoss: 0.164919\n",
      "Train Epoch: 5 [39040/41964 (78%)]\tLoss: 0.573956\n",
      "Train Epoch: 5 [39680/41964 (79%)]\tLoss: 0.486095\n",
      "Train Epoch: 5 [40320/41964 (81%)]\tLoss: 0.366253\n",
      "Train Epoch: 5 [40960/41964 (82%)]\tLoss: 0.214043\n",
      "Train Epoch: 5 [41600/41964 (83%)]\tLoss: 0.302509\n",
      "Train Epoch: 5 [42240/41964 (84%)]\tLoss: 0.171841\n",
      "Train Epoch: 5 [42880/41964 (86%)]\tLoss: 0.284771\n",
      "Train Epoch: 5 [43520/41964 (87%)]\tLoss: 0.184694\n",
      "Train Epoch: 5 [44160/41964 (88%)]\tLoss: 0.388549\n",
      "Train Epoch: 5 [44800/41964 (90%)]\tLoss: 0.159841\n",
      "Train Epoch: 5 [45440/41964 (91%)]\tLoss: 0.550550\n",
      "Train Epoch: 5 [46080/41964 (92%)]\tLoss: 0.422186\n",
      "Train Epoch: 5 [46720/41964 (93%)]\tLoss: 0.357779\n",
      "Train Epoch: 5 [47360/41964 (95%)]\tLoss: 0.315662\n",
      "Train Epoch: 5 [48000/41964 (96%)]\tLoss: 0.347912\n",
      "Train Epoch: 5 [48640/41964 (97%)]\tLoss: 0.237644\n",
      "Train Epoch: 5 [49280/41964 (98%)]\tLoss: 0.250241\n",
      "Train Epoch: 5 [49920/41964 (100%)]\tLoss: 0.287398\n",
      "\n",
      "Test set: Avg. loss: 0.0861, Accuracy: 9732/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/41964 (0%)]\tLoss: 0.353053\n",
      "Train Epoch: 6 [640/41964 (1%)]\tLoss: 0.222394\n",
      "Train Epoch: 6 [1280/41964 (3%)]\tLoss: 0.416972\n",
      "Train Epoch: 6 [1920/41964 (4%)]\tLoss: 0.397525\n",
      "Train Epoch: 6 [2560/41964 (5%)]\tLoss: 0.238300\n",
      "Train Epoch: 6 [3200/41964 (6%)]\tLoss: 0.309099\n",
      "Train Epoch: 6 [3840/41964 (8%)]\tLoss: 0.244335\n",
      "Train Epoch: 6 [4480/41964 (9%)]\tLoss: 0.250968\n",
      "Train Epoch: 6 [5120/41964 (10%)]\tLoss: 0.186169\n",
      "Train Epoch: 6 [5760/41964 (12%)]\tLoss: 0.276291\n",
      "Train Epoch: 6 [6400/41964 (13%)]\tLoss: 0.310870\n",
      "Train Epoch: 6 [7040/41964 (14%)]\tLoss: 0.106835\n",
      "Train Epoch: 6 [7680/41964 (15%)]\tLoss: 0.220688\n",
      "Train Epoch: 6 [8320/41964 (17%)]\tLoss: 0.239168\n",
      "Train Epoch: 6 [8960/41964 (18%)]\tLoss: 0.260906\n",
      "Train Epoch: 6 [9600/41964 (19%)]\tLoss: 0.383784\n",
      "Train Epoch: 6 [10240/41964 (20%)]\tLoss: 0.126566\n",
      "Train Epoch: 6 [10880/41964 (22%)]\tLoss: 0.467015\n",
      "Train Epoch: 6 [11520/41964 (23%)]\tLoss: 0.307675\n",
      "Train Epoch: 6 [12160/41964 (24%)]\tLoss: 0.154193\n",
      "Train Epoch: 6 [12800/41964 (26%)]\tLoss: 0.345587\n",
      "Train Epoch: 6 [13440/41964 (27%)]\tLoss: 0.615278\n",
      "Train Epoch: 6 [14080/41964 (28%)]\tLoss: 0.222316\n",
      "Train Epoch: 6 [14720/41964 (29%)]\tLoss: 0.298698\n",
      "Train Epoch: 6 [15360/41964 (31%)]\tLoss: 0.125632\n",
      "Train Epoch: 6 [16000/41964 (32%)]\tLoss: 0.120141\n",
      "Train Epoch: 6 [16640/41964 (33%)]\tLoss: 0.256612\n",
      "Train Epoch: 6 [17280/41964 (35%)]\tLoss: 0.283630\n",
      "Train Epoch: 6 [17920/41964 (36%)]\tLoss: 0.346403\n",
      "Train Epoch: 6 [18560/41964 (37%)]\tLoss: 0.190855\n",
      "Train Epoch: 6 [19200/41964 (38%)]\tLoss: 0.249973\n",
      "Train Epoch: 6 [19840/41964 (40%)]\tLoss: 0.255932\n",
      "Train Epoch: 6 [20480/41964 (41%)]\tLoss: 0.388269\n",
      "Train Epoch: 6 [21120/41964 (42%)]\tLoss: 0.204604\n",
      "Train Epoch: 6 [21760/41964 (43%)]\tLoss: 0.306870\n",
      "Train Epoch: 6 [22400/41964 (45%)]\tLoss: 0.172199\n",
      "Train Epoch: 6 [23040/41964 (46%)]\tLoss: 0.236360\n",
      "Train Epoch: 6 [23680/41964 (47%)]\tLoss: 0.233716\n",
      "Train Epoch: 6 [24320/41964 (49%)]\tLoss: 0.146571\n",
      "Train Epoch: 6 [24960/41964 (50%)]\tLoss: 0.230321\n",
      "Train Epoch: 6 [25600/41964 (51%)]\tLoss: 0.255852\n",
      "Train Epoch: 6 [26240/41964 (52%)]\tLoss: 0.137777\n",
      "Train Epoch: 6 [26880/41964 (54%)]\tLoss: 0.271924\n",
      "Train Epoch: 6 [27520/41964 (55%)]\tLoss: 0.242821\n",
      "Train Epoch: 6 [28160/41964 (56%)]\tLoss: 0.222779\n",
      "Train Epoch: 6 [28800/41964 (58%)]\tLoss: 0.196156\n",
      "Train Epoch: 6 [29440/41964 (59%)]\tLoss: 0.334596\n",
      "Train Epoch: 6 [30080/41964 (60%)]\tLoss: 0.449131\n",
      "Train Epoch: 6 [30720/41964 (61%)]\tLoss: 0.190240\n",
      "Train Epoch: 6 [31360/41964 (63%)]\tLoss: 0.292422\n",
      "Train Epoch: 6 [32000/41964 (64%)]\tLoss: 0.402337\n",
      "Train Epoch: 6 [32640/41964 (65%)]\tLoss: 0.383916\n",
      "Train Epoch: 6 [33280/41964 (66%)]\tLoss: 0.545234\n",
      "Train Epoch: 6 [33920/41964 (68%)]\tLoss: 0.452652\n",
      "Train Epoch: 6 [34560/41964 (69%)]\tLoss: 0.293765\n",
      "Train Epoch: 6 [35200/41964 (70%)]\tLoss: 0.263720\n",
      "Train Epoch: 6 [35840/41964 (72%)]\tLoss: 0.271304\n",
      "Train Epoch: 6 [36480/41964 (73%)]\tLoss: 0.180297\n",
      "Train Epoch: 6 [37120/41964 (74%)]\tLoss: 0.252695\n",
      "Train Epoch: 6 [37760/41964 (75%)]\tLoss: 0.296593\n",
      "Train Epoch: 6 [38400/41964 (77%)]\tLoss: 0.235142\n",
      "Train Epoch: 6 [39040/41964 (78%)]\tLoss: 0.402676\n",
      "Train Epoch: 6 [39680/41964 (79%)]\tLoss: 0.550750\n",
      "Train Epoch: 6 [40320/41964 (81%)]\tLoss: 0.185031\n",
      "Train Epoch: 6 [40960/41964 (82%)]\tLoss: 0.156463\n",
      "Train Epoch: 6 [41600/41964 (83%)]\tLoss: 0.606560\n",
      "Train Epoch: 6 [42240/41964 (84%)]\tLoss: 0.326483\n",
      "Train Epoch: 6 [42880/41964 (86%)]\tLoss: 0.332069\n",
      "Train Epoch: 6 [43520/41964 (87%)]\tLoss: 0.531034\n",
      "Train Epoch: 6 [44160/41964 (88%)]\tLoss: 0.396615\n",
      "Train Epoch: 6 [44800/41964 (90%)]\tLoss: 0.221136\n",
      "Train Epoch: 6 [45440/41964 (91%)]\tLoss: 0.285381\n",
      "Train Epoch: 6 [46080/41964 (92%)]\tLoss: 0.498881\n",
      "Train Epoch: 6 [46720/41964 (93%)]\tLoss: 0.097648\n",
      "Train Epoch: 6 [47360/41964 (95%)]\tLoss: 0.124631\n",
      "Train Epoch: 6 [48000/41964 (96%)]\tLoss: 0.158225\n",
      "Train Epoch: 6 [48640/41964 (97%)]\tLoss: 0.203589\n",
      "Train Epoch: 6 [49280/41964 (98%)]\tLoss: 0.301847\n",
      "Train Epoch: 6 [49920/41964 (100%)]\tLoss: 0.159341\n",
      "\n",
      "Test set: Avg. loss: 0.0798, Accuracy: 9762/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/41964 (0%)]\tLoss: 0.356138\n",
      "Train Epoch: 7 [640/41964 (1%)]\tLoss: 0.345760\n",
      "Train Epoch: 7 [1280/41964 (3%)]\tLoss: 0.288001\n",
      "Train Epoch: 7 [1920/41964 (4%)]\tLoss: 0.192721\n",
      "Train Epoch: 7 [2560/41964 (5%)]\tLoss: 0.265771\n",
      "Train Epoch: 7 [3200/41964 (6%)]\tLoss: 0.190594\n",
      "Train Epoch: 7 [3840/41964 (8%)]\tLoss: 0.143822\n",
      "Train Epoch: 7 [4480/41964 (9%)]\tLoss: 0.245812\n",
      "Train Epoch: 7 [5120/41964 (10%)]\tLoss: 0.137288\n",
      "Train Epoch: 7 [5760/41964 (12%)]\tLoss: 0.282625\n",
      "Train Epoch: 7 [6400/41964 (13%)]\tLoss: 0.242236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [7040/41964 (14%)]\tLoss: 0.164931\n",
      "Train Epoch: 7 [7680/41964 (15%)]\tLoss: 0.358013\n",
      "Train Epoch: 7 [8320/41964 (17%)]\tLoss: 0.240018\n",
      "Train Epoch: 7 [8960/41964 (18%)]\tLoss: 0.549231\n",
      "Train Epoch: 7 [9600/41964 (19%)]\tLoss: 0.329593\n",
      "Train Epoch: 7 [10240/41964 (20%)]\tLoss: 0.203366\n",
      "Train Epoch: 7 [10880/41964 (22%)]\tLoss: 0.290946\n",
      "Train Epoch: 7 [11520/41964 (23%)]\tLoss: 0.336368\n",
      "Train Epoch: 7 [12160/41964 (24%)]\tLoss: 0.163767\n",
      "Train Epoch: 7 [12800/41964 (26%)]\tLoss: 0.165526\n",
      "Train Epoch: 7 [13440/41964 (27%)]\tLoss: 0.348356\n",
      "Train Epoch: 7 [14080/41964 (28%)]\tLoss: 0.157636\n",
      "Train Epoch: 7 [14720/41964 (29%)]\tLoss: 0.142245\n",
      "Train Epoch: 7 [15360/41964 (31%)]\tLoss: 0.160499\n",
      "Train Epoch: 7 [16000/41964 (32%)]\tLoss: 0.273481\n",
      "Train Epoch: 7 [16640/41964 (33%)]\tLoss: 0.104060\n",
      "Train Epoch: 7 [17280/41964 (35%)]\tLoss: 0.237098\n",
      "Train Epoch: 7 [17920/41964 (36%)]\tLoss: 0.182194\n",
      "Train Epoch: 7 [18560/41964 (37%)]\tLoss: 0.224861\n",
      "Train Epoch: 7 [19200/41964 (38%)]\tLoss: 0.349554\n",
      "Train Epoch: 7 [19840/41964 (40%)]\tLoss: 0.364301\n",
      "Train Epoch: 7 [20480/41964 (41%)]\tLoss: 0.536991\n",
      "Train Epoch: 7 [21120/41964 (42%)]\tLoss: 0.158120\n",
      "Train Epoch: 7 [21760/41964 (43%)]\tLoss: 0.143328\n",
      "Train Epoch: 7 [22400/41964 (45%)]\tLoss: 0.330746\n",
      "Train Epoch: 7 [23040/41964 (46%)]\tLoss: 0.196179\n",
      "Train Epoch: 7 [23680/41964 (47%)]\tLoss: 0.266380\n",
      "Train Epoch: 7 [24320/41964 (49%)]\tLoss: 0.173551\n",
      "Train Epoch: 7 [24960/41964 (50%)]\tLoss: 0.240516\n",
      "Train Epoch: 7 [25600/41964 (51%)]\tLoss: 0.227022\n",
      "Train Epoch: 7 [26240/41964 (52%)]\tLoss: 0.328838\n",
      "Train Epoch: 7 [26880/41964 (54%)]\tLoss: 0.104676\n",
      "Train Epoch: 7 [27520/41964 (55%)]\tLoss: 0.394891\n",
      "Train Epoch: 7 [28160/41964 (56%)]\tLoss: 0.249742\n",
      "Train Epoch: 7 [28800/41964 (58%)]\tLoss: 0.213004\n",
      "Train Epoch: 7 [29440/41964 (59%)]\tLoss: 0.154021\n",
      "Train Epoch: 7 [30080/41964 (60%)]\tLoss: 0.494651\n",
      "Train Epoch: 7 [30720/41964 (61%)]\tLoss: 0.442833\n",
      "Train Epoch: 7 [31360/41964 (63%)]\tLoss: 0.240347\n",
      "Train Epoch: 7 [32000/41964 (64%)]\tLoss: 0.119452\n",
      "Train Epoch: 7 [32640/41964 (65%)]\tLoss: 0.333088\n",
      "Train Epoch: 7 [33280/41964 (66%)]\tLoss: 0.197129\n",
      "Train Epoch: 7 [33920/41964 (68%)]\tLoss: 0.267266\n",
      "Train Epoch: 7 [34560/41964 (69%)]\tLoss: 0.205926\n",
      "Train Epoch: 7 [35200/41964 (70%)]\tLoss: 0.243845\n",
      "Train Epoch: 7 [35840/41964 (72%)]\tLoss: 0.215725\n",
      "Train Epoch: 7 [36480/41964 (73%)]\tLoss: 0.265347\n",
      "Train Epoch: 7 [37120/41964 (74%)]\tLoss: 0.189070\n",
      "Train Epoch: 7 [37760/41964 (75%)]\tLoss: 0.243163\n",
      "Train Epoch: 7 [38400/41964 (77%)]\tLoss: 0.206077\n",
      "Train Epoch: 7 [39040/41964 (78%)]\tLoss: 0.295680\n",
      "Train Epoch: 7 [39680/41964 (79%)]\tLoss: 0.269183\n",
      "Train Epoch: 7 [40320/41964 (81%)]\tLoss: 0.072761\n",
      "Train Epoch: 7 [40960/41964 (82%)]\tLoss: 0.260989\n",
      "Train Epoch: 7 [41600/41964 (83%)]\tLoss: 0.275456\n",
      "Train Epoch: 7 [42240/41964 (84%)]\tLoss: 0.423819\n",
      "Train Epoch: 7 [42880/41964 (86%)]\tLoss: 0.165476\n",
      "Train Epoch: 7 [43520/41964 (87%)]\tLoss: 0.324832\n",
      "Train Epoch: 7 [44160/41964 (88%)]\tLoss: 0.294305\n",
      "Train Epoch: 7 [44800/41964 (90%)]\tLoss: 0.131811\n",
      "Train Epoch: 7 [45440/41964 (91%)]\tLoss: 0.420865\n",
      "Train Epoch: 7 [46080/41964 (92%)]\tLoss: 0.177059\n",
      "Train Epoch: 7 [46720/41964 (93%)]\tLoss: 0.330349\n",
      "Train Epoch: 7 [47360/41964 (95%)]\tLoss: 0.215479\n",
      "Train Epoch: 7 [48000/41964 (96%)]\tLoss: 0.181548\n",
      "Train Epoch: 7 [48640/41964 (97%)]\tLoss: 0.321589\n",
      "Train Epoch: 7 [49280/41964 (98%)]\tLoss: 0.266475\n",
      "Train Epoch: 7 [49920/41964 (100%)]\tLoss: 0.392786\n",
      "\n",
      "Test set: Avg. loss: 0.0760, Accuracy: 9761/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/41964 (0%)]\tLoss: 0.277182\n",
      "Train Epoch: 8 [640/41964 (1%)]\tLoss: 0.199756\n",
      "Train Epoch: 8 [1280/41964 (3%)]\tLoss: 0.168397\n",
      "Train Epoch: 8 [1920/41964 (4%)]\tLoss: 0.244439\n",
      "Train Epoch: 8 [2560/41964 (5%)]\tLoss: 0.193747\n",
      "Train Epoch: 8 [3200/41964 (6%)]\tLoss: 0.191018\n",
      "Train Epoch: 8 [3840/41964 (8%)]\tLoss: 0.143194\n",
      "Train Epoch: 8 [4480/41964 (9%)]\tLoss: 0.295999\n",
      "Train Epoch: 8 [5120/41964 (10%)]\tLoss: 0.411697\n",
      "Train Epoch: 8 [5760/41964 (12%)]\tLoss: 0.262318\n",
      "Train Epoch: 8 [6400/41964 (13%)]\tLoss: 0.212906\n",
      "Train Epoch: 8 [7040/41964 (14%)]\tLoss: 0.264982\n",
      "Train Epoch: 8 [7680/41964 (15%)]\tLoss: 0.303070\n",
      "Train Epoch: 8 [8320/41964 (17%)]\tLoss: 0.333313\n",
      "Train Epoch: 8 [8960/41964 (18%)]\tLoss: 0.201284\n",
      "Train Epoch: 8 [9600/41964 (19%)]\tLoss: 0.133146\n",
      "Train Epoch: 8 [10240/41964 (20%)]\tLoss: 0.313561\n",
      "Train Epoch: 8 [10880/41964 (22%)]\tLoss: 0.153612\n",
      "Train Epoch: 8 [11520/41964 (23%)]\tLoss: 0.327797\n",
      "Train Epoch: 8 [12160/41964 (24%)]\tLoss: 0.104833\n",
      "Train Epoch: 8 [12800/41964 (26%)]\tLoss: 0.241259\n",
      "Train Epoch: 8 [13440/41964 (27%)]\tLoss: 0.343609\n",
      "Train Epoch: 8 [14080/41964 (28%)]\tLoss: 0.287959\n",
      "Train Epoch: 8 [14720/41964 (29%)]\tLoss: 0.188480\n",
      "Train Epoch: 8 [15360/41964 (31%)]\tLoss: 0.291528\n",
      "Train Epoch: 8 [16000/41964 (32%)]\tLoss: 0.166313\n",
      "Train Epoch: 8 [16640/41964 (33%)]\tLoss: 0.472766\n",
      "Train Epoch: 8 [17280/41964 (35%)]\tLoss: 0.380435\n",
      "Train Epoch: 8 [17920/41964 (36%)]\tLoss: 0.361908\n",
      "Train Epoch: 8 [18560/41964 (37%)]\tLoss: 0.223063\n",
      "Train Epoch: 8 [19200/41964 (38%)]\tLoss: 0.366383\n",
      "Train Epoch: 8 [19840/41964 (40%)]\tLoss: 0.222340\n",
      "Train Epoch: 8 [20480/41964 (41%)]\tLoss: 0.244363\n",
      "Train Epoch: 8 [21120/41964 (42%)]\tLoss: 0.276337\n",
      "Train Epoch: 8 [21760/41964 (43%)]\tLoss: 0.457187\n",
      "Train Epoch: 8 [22400/41964 (45%)]\tLoss: 0.371355\n",
      "Train Epoch: 8 [23040/41964 (46%)]\tLoss: 0.249345\n",
      "Train Epoch: 8 [23680/41964 (47%)]\tLoss: 0.265876\n",
      "Train Epoch: 8 [24320/41964 (49%)]\tLoss: 0.303561\n",
      "Train Epoch: 8 [24960/41964 (50%)]\tLoss: 0.207581\n",
      "Train Epoch: 8 [25600/41964 (51%)]\tLoss: 0.146648\n",
      "Train Epoch: 8 [26240/41964 (52%)]\tLoss: 0.259687\n",
      "Train Epoch: 8 [26880/41964 (54%)]\tLoss: 0.410283\n",
      "Train Epoch: 8 [27520/41964 (55%)]\tLoss: 0.188984\n",
      "Train Epoch: 8 [28160/41964 (56%)]\tLoss: 0.123852\n",
      "Train Epoch: 8 [28800/41964 (58%)]\tLoss: 0.148022\n",
      "Train Epoch: 8 [29440/41964 (59%)]\tLoss: 0.271973\n",
      "Train Epoch: 8 [30080/41964 (60%)]\tLoss: 0.255521\n",
      "Train Epoch: 8 [30720/41964 (61%)]\tLoss: 0.260921\n",
      "Train Epoch: 8 [31360/41964 (63%)]\tLoss: 0.208829\n",
      "Train Epoch: 8 [32000/41964 (64%)]\tLoss: 0.302989\n",
      "Train Epoch: 8 [32640/41964 (65%)]\tLoss: 0.436581\n",
      "Train Epoch: 8 [33280/41964 (66%)]\tLoss: 0.082620\n",
      "Train Epoch: 8 [33920/41964 (68%)]\tLoss: 0.289119\n",
      "Train Epoch: 8 [34560/41964 (69%)]\tLoss: 0.341863\n",
      "Train Epoch: 8 [35200/41964 (70%)]\tLoss: 0.230944\n",
      "Train Epoch: 8 [35840/41964 (72%)]\tLoss: 0.179566\n",
      "Train Epoch: 8 [36480/41964 (73%)]\tLoss: 0.209081\n",
      "Train Epoch: 8 [37120/41964 (74%)]\tLoss: 0.160588\n",
      "Train Epoch: 8 [37760/41964 (75%)]\tLoss: 0.210520\n",
      "Train Epoch: 8 [38400/41964 (77%)]\tLoss: 0.191117\n",
      "Train Epoch: 8 [39040/41964 (78%)]\tLoss: 0.195870\n",
      "Train Epoch: 8 [39680/41964 (79%)]\tLoss: 0.278047\n",
      "Train Epoch: 8 [40320/41964 (81%)]\tLoss: 0.273345\n",
      "Train Epoch: 8 [40960/41964 (82%)]\tLoss: 0.440726\n",
      "Train Epoch: 8 [41600/41964 (83%)]\tLoss: 0.271867\n",
      "Train Epoch: 8 [42240/41964 (84%)]\tLoss: 0.309295\n",
      "Train Epoch: 8 [42880/41964 (86%)]\tLoss: 0.248237\n",
      "Train Epoch: 8 [43520/41964 (87%)]\tLoss: 0.219108\n",
      "Train Epoch: 8 [44160/41964 (88%)]\tLoss: 0.344045\n",
      "Train Epoch: 8 [44800/41964 (90%)]\tLoss: 0.178845\n",
      "Train Epoch: 8 [45440/41964 (91%)]\tLoss: 0.311110\n",
      "Train Epoch: 8 [46080/41964 (92%)]\tLoss: 0.241654\n",
      "Train Epoch: 8 [46720/41964 (93%)]\tLoss: 0.244582\n",
      "Train Epoch: 8 [47360/41964 (95%)]\tLoss: 0.461726\n",
      "Train Epoch: 8 [48000/41964 (96%)]\tLoss: 0.251349\n",
      "Train Epoch: 8 [48640/41964 (97%)]\tLoss: 0.237430\n",
      "Train Epoch: 8 [49280/41964 (98%)]\tLoss: 0.324514\n",
      "Train Epoch: 8 [49920/41964 (100%)]\tLoss: 0.366788\n",
      "\n",
      "Test set: Avg. loss: 0.0687, Accuracy: 9782/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/41964 (0%)]\tLoss: 0.222852\n",
      "Train Epoch: 9 [640/41964 (1%)]\tLoss: 0.225912\n",
      "Train Epoch: 9 [1280/41964 (3%)]\tLoss: 0.200542\n",
      "Train Epoch: 9 [1920/41964 (4%)]\tLoss: 0.225216\n",
      "Train Epoch: 9 [2560/41964 (5%)]\tLoss: 0.189680\n",
      "Train Epoch: 9 [3200/41964 (6%)]\tLoss: 0.228146\n",
      "Train Epoch: 9 [3840/41964 (8%)]\tLoss: 0.152748\n",
      "Train Epoch: 9 [4480/41964 (9%)]\tLoss: 0.271343\n",
      "Train Epoch: 9 [5120/41964 (10%)]\tLoss: 0.355290\n",
      "Train Epoch: 9 [5760/41964 (12%)]\tLoss: 0.169628\n",
      "Train Epoch: 9 [6400/41964 (13%)]\tLoss: 0.193668\n",
      "Train Epoch: 9 [7040/41964 (14%)]\tLoss: 0.346330\n",
      "Train Epoch: 9 [7680/41964 (15%)]\tLoss: 0.146760\n",
      "Train Epoch: 9 [8320/41964 (17%)]\tLoss: 0.227437\n",
      "Train Epoch: 9 [8960/41964 (18%)]\tLoss: 0.181243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [9600/41964 (19%)]\tLoss: 0.363581\n",
      "Train Epoch: 9 [10240/41964 (20%)]\tLoss: 0.199494\n",
      "Train Epoch: 9 [10880/41964 (22%)]\tLoss: 0.330231\n",
      "Train Epoch: 9 [11520/41964 (23%)]\tLoss: 0.154532\n",
      "Train Epoch: 9 [12160/41964 (24%)]\tLoss: 0.212227\n",
      "Train Epoch: 9 [12800/41964 (26%)]\tLoss: 0.265772\n",
      "Train Epoch: 9 [13440/41964 (27%)]\tLoss: 0.263010\n",
      "Train Epoch: 9 [14080/41964 (28%)]\tLoss: 0.163965\n",
      "Train Epoch: 9 [14720/41964 (29%)]\tLoss: 0.146174\n",
      "Train Epoch: 9 [15360/41964 (31%)]\tLoss: 0.232826\n",
      "Train Epoch: 9 [16000/41964 (32%)]\tLoss: 0.120245\n",
      "Train Epoch: 9 [16640/41964 (33%)]\tLoss: 0.204433\n",
      "Train Epoch: 9 [17280/41964 (35%)]\tLoss: 0.233313\n",
      "Train Epoch: 9 [17920/41964 (36%)]\tLoss: 0.170474\n",
      "Train Epoch: 9 [18560/41964 (37%)]\tLoss: 0.338289\n",
      "Train Epoch: 9 [19200/41964 (38%)]\tLoss: 0.405144\n",
      "Train Epoch: 9 [19840/41964 (40%)]\tLoss: 0.350966\n",
      "Train Epoch: 9 [20480/41964 (41%)]\tLoss: 0.225834\n",
      "Train Epoch: 9 [21120/41964 (42%)]\tLoss: 0.164568\n",
      "Train Epoch: 9 [21760/41964 (43%)]\tLoss: 0.358209\n",
      "Train Epoch: 9 [22400/41964 (45%)]\tLoss: 0.178342\n",
      "Train Epoch: 9 [23040/41964 (46%)]\tLoss: 0.155380\n",
      "Train Epoch: 9 [23680/41964 (47%)]\tLoss: 0.173597\n",
      "Train Epoch: 9 [24320/41964 (49%)]\tLoss: 0.365500\n",
      "Train Epoch: 9 [24960/41964 (50%)]\tLoss: 0.207383\n",
      "Train Epoch: 9 [25600/41964 (51%)]\tLoss: 0.114447\n",
      "Train Epoch: 9 [26240/41964 (52%)]\tLoss: 0.122741\n",
      "Train Epoch: 9 [26880/41964 (54%)]\tLoss: 0.256421\n",
      "Train Epoch: 9 [27520/41964 (55%)]\tLoss: 0.207053\n",
      "Train Epoch: 9 [28160/41964 (56%)]\tLoss: 0.133964\n",
      "Train Epoch: 9 [28800/41964 (58%)]\tLoss: 0.409328\n",
      "Train Epoch: 9 [29440/41964 (59%)]\tLoss: 0.273366\n",
      "Train Epoch: 9 [30080/41964 (60%)]\tLoss: 0.169100\n",
      "Train Epoch: 9 [30720/41964 (61%)]\tLoss: 0.159073\n",
      "Train Epoch: 9 [31360/41964 (63%)]\tLoss: 0.272599\n",
      "Train Epoch: 9 [32000/41964 (64%)]\tLoss: 0.092568\n",
      "Train Epoch: 9 [32640/41964 (65%)]\tLoss: 0.133287\n",
      "Train Epoch: 9 [33280/41964 (66%)]\tLoss: 0.132066\n",
      "Train Epoch: 9 [33920/41964 (68%)]\tLoss: 0.205989\n",
      "Train Epoch: 9 [34560/41964 (69%)]\tLoss: 0.241455\n",
      "Train Epoch: 9 [35200/41964 (70%)]\tLoss: 0.315151\n",
      "Train Epoch: 9 [35840/41964 (72%)]\tLoss: 0.320475\n",
      "Train Epoch: 9 [36480/41964 (73%)]\tLoss: 0.197707\n",
      "Train Epoch: 9 [37120/41964 (74%)]\tLoss: 0.399594\n",
      "Train Epoch: 9 [37760/41964 (75%)]\tLoss: 0.213273\n",
      "Train Epoch: 9 [38400/41964 (77%)]\tLoss: 0.215683\n",
      "Train Epoch: 9 [39040/41964 (78%)]\tLoss: 0.170659\n",
      "Train Epoch: 9 [39680/41964 (79%)]\tLoss: 0.206334\n",
      "Train Epoch: 9 [40320/41964 (81%)]\tLoss: 0.295340\n",
      "Train Epoch: 9 [40960/41964 (82%)]\tLoss: 0.444790\n",
      "Train Epoch: 9 [41600/41964 (83%)]\tLoss: 0.378242\n",
      "Train Epoch: 9 [42240/41964 (84%)]\tLoss: 0.249056\n",
      "Train Epoch: 9 [42880/41964 (86%)]\tLoss: 0.187508\n",
      "Train Epoch: 9 [43520/41964 (87%)]\tLoss: 0.106554\n",
      "Train Epoch: 9 [44160/41964 (88%)]\tLoss: 0.371636\n",
      "Train Epoch: 9 [44800/41964 (90%)]\tLoss: 0.224441\n",
      "Train Epoch: 9 [45440/41964 (91%)]\tLoss: 0.252843\n",
      "Train Epoch: 9 [46080/41964 (92%)]\tLoss: 0.378694\n",
      "Train Epoch: 9 [46720/41964 (93%)]\tLoss: 0.387791\n",
      "Train Epoch: 9 [47360/41964 (95%)]\tLoss: 0.158181\n",
      "Train Epoch: 9 [48000/41964 (96%)]\tLoss: 0.149135\n",
      "Train Epoch: 9 [48640/41964 (97%)]\tLoss: 0.098744\n",
      "Train Epoch: 9 [49280/41964 (98%)]\tLoss: 0.250275\n",
      "Train Epoch: 9 [49920/41964 (100%)]\tLoss: 0.135809\n",
      "\n",
      "Test set: Avg. loss: 0.0652, Accuracy: 9790/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/41964 (0%)]\tLoss: 0.187049\n",
      "Train Epoch: 10 [640/41964 (1%)]\tLoss: 0.144415\n",
      "Train Epoch: 10 [1280/41964 (3%)]\tLoss: 0.240219\n",
      "Train Epoch: 10 [1920/41964 (4%)]\tLoss: 0.168830\n",
      "Train Epoch: 10 [2560/41964 (5%)]\tLoss: 0.238858\n",
      "Train Epoch: 10 [3200/41964 (6%)]\tLoss: 0.121680\n",
      "Train Epoch: 10 [3840/41964 (8%)]\tLoss: 0.190412\n",
      "Train Epoch: 10 [4480/41964 (9%)]\tLoss: 0.126868\n",
      "Train Epoch: 10 [5120/41964 (10%)]\tLoss: 0.290550\n",
      "Train Epoch: 10 [5760/41964 (12%)]\tLoss: 0.312842\n",
      "Train Epoch: 10 [6400/41964 (13%)]\tLoss: 0.291392\n",
      "Train Epoch: 10 [7040/41964 (14%)]\tLoss: 0.327756\n",
      "Train Epoch: 10 [7680/41964 (15%)]\tLoss: 0.225179\n",
      "Train Epoch: 10 [8320/41964 (17%)]\tLoss: 0.092257\n",
      "Train Epoch: 10 [8960/41964 (18%)]\tLoss: 0.133311\n",
      "Train Epoch: 10 [9600/41964 (19%)]\tLoss: 0.353674\n",
      "Train Epoch: 10 [10240/41964 (20%)]\tLoss: 0.108686\n",
      "Train Epoch: 10 [10880/41964 (22%)]\tLoss: 0.258462\n",
      "Train Epoch: 10 [11520/41964 (23%)]\tLoss: 0.220877\n",
      "Train Epoch: 10 [12160/41964 (24%)]\tLoss: 0.438223\n",
      "Train Epoch: 10 [12800/41964 (26%)]\tLoss: 0.051281\n",
      "Train Epoch: 10 [13440/41964 (27%)]\tLoss: 0.121628\n",
      "Train Epoch: 10 [14080/41964 (28%)]\tLoss: 0.335461\n",
      "Train Epoch: 10 [14720/41964 (29%)]\tLoss: 0.216853\n",
      "Train Epoch: 10 [15360/41964 (31%)]\tLoss: 0.209547\n",
      "Train Epoch: 10 [16000/41964 (32%)]\tLoss: 0.360941\n",
      "Train Epoch: 10 [16640/41964 (33%)]\tLoss: 0.416556\n",
      "Train Epoch: 10 [17280/41964 (35%)]\tLoss: 0.356959\n",
      "Train Epoch: 10 [17920/41964 (36%)]\tLoss: 0.250769\n",
      "Train Epoch: 10 [18560/41964 (37%)]\tLoss: 0.101683\n",
      "Train Epoch: 10 [19200/41964 (38%)]\tLoss: 0.201584\n",
      "Train Epoch: 10 [19840/41964 (40%)]\tLoss: 0.495057\n",
      "Train Epoch: 10 [20480/41964 (41%)]\tLoss: 0.218670\n",
      "Train Epoch: 10 [21120/41964 (42%)]\tLoss: 0.374947\n",
      "Train Epoch: 10 [21760/41964 (43%)]\tLoss: 0.417033\n",
      "Train Epoch: 10 [22400/41964 (45%)]\tLoss: 0.176885\n",
      "Train Epoch: 10 [23040/41964 (46%)]\tLoss: 0.249542\n",
      "Train Epoch: 10 [23680/41964 (47%)]\tLoss: 0.139322\n",
      "Train Epoch: 10 [24320/41964 (49%)]\tLoss: 0.282972\n",
      "Train Epoch: 10 [24960/41964 (50%)]\tLoss: 0.224518\n",
      "Train Epoch: 10 [25600/41964 (51%)]\tLoss: 0.096839\n",
      "Train Epoch: 10 [26240/41964 (52%)]\tLoss: 0.125604\n",
      "Train Epoch: 10 [26880/41964 (54%)]\tLoss: 0.180182\n",
      "Train Epoch: 10 [27520/41964 (55%)]\tLoss: 0.207100\n",
      "Train Epoch: 10 [28160/41964 (56%)]\tLoss: 0.181452\n",
      "Train Epoch: 10 [28800/41964 (58%)]\tLoss: 0.397363\n",
      "Train Epoch: 10 [29440/41964 (59%)]\tLoss: 0.146383\n",
      "Train Epoch: 10 [30080/41964 (60%)]\tLoss: 0.096903\n",
      "Train Epoch: 10 [30720/41964 (61%)]\tLoss: 0.159734\n",
      "Train Epoch: 10 [31360/41964 (63%)]\tLoss: 0.369464\n",
      "Train Epoch: 10 [32000/41964 (64%)]\tLoss: 0.304422\n",
      "Train Epoch: 10 [32640/41964 (65%)]\tLoss: 0.276056\n",
      "Train Epoch: 10 [33280/41964 (66%)]\tLoss: 0.181969\n",
      "Train Epoch: 10 [33920/41964 (68%)]\tLoss: 0.153733\n",
      "Train Epoch: 10 [34560/41964 (69%)]\tLoss: 0.236633\n",
      "Train Epoch: 10 [35200/41964 (70%)]\tLoss: 0.198607\n",
      "Train Epoch: 10 [35840/41964 (72%)]\tLoss: 0.186841\n",
      "Train Epoch: 10 [36480/41964 (73%)]\tLoss: 0.211991\n",
      "Train Epoch: 10 [37120/41964 (74%)]\tLoss: 0.153703\n",
      "Train Epoch: 10 [37760/41964 (75%)]\tLoss: 0.174973\n",
      "Train Epoch: 10 [38400/41964 (77%)]\tLoss: 0.284081\n",
      "Train Epoch: 10 [39040/41964 (78%)]\tLoss: 0.387485\n",
      "Train Epoch: 10 [39680/41964 (79%)]\tLoss: 0.074516\n",
      "Train Epoch: 10 [40320/41964 (81%)]\tLoss: 0.162767\n",
      "Train Epoch: 10 [40960/41964 (82%)]\tLoss: 0.103543\n",
      "Train Epoch: 10 [41600/41964 (83%)]\tLoss: 0.288528\n",
      "Train Epoch: 10 [42240/41964 (84%)]\tLoss: 0.120219\n",
      "Train Epoch: 10 [42880/41964 (86%)]\tLoss: 0.341375\n",
      "Train Epoch: 10 [43520/41964 (87%)]\tLoss: 0.208444\n",
      "Train Epoch: 10 [44160/41964 (88%)]\tLoss: 0.206993\n",
      "Train Epoch: 10 [44800/41964 (90%)]\tLoss: 0.368933\n",
      "Train Epoch: 10 [45440/41964 (91%)]\tLoss: 0.215162\n",
      "Train Epoch: 10 [46080/41964 (92%)]\tLoss: 0.255629\n",
      "Train Epoch: 10 [46720/41964 (93%)]\tLoss: 0.128988\n",
      "Train Epoch: 10 [47360/41964 (95%)]\tLoss: 0.278644\n",
      "Train Epoch: 10 [48000/41964 (96%)]\tLoss: 0.351534\n",
      "Train Epoch: 10 [48640/41964 (97%)]\tLoss: 0.377730\n",
      "Train Epoch: 10 [49280/41964 (98%)]\tLoss: 0.416920\n",
      "Train Epoch: 10 [49920/41964 (100%)]\tLoss: 0.180088\n",
      "\n",
      "Test set: Avg. loss: 0.0591, Accuracy: 9814/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/41964 (0%)]\tLoss: 0.217775\n",
      "Train Epoch: 11 [640/41964 (1%)]\tLoss: 0.246630\n",
      "Train Epoch: 11 [1280/41964 (3%)]\tLoss: 0.262156\n",
      "Train Epoch: 11 [1920/41964 (4%)]\tLoss: 0.328693\n",
      "Train Epoch: 11 [2560/41964 (5%)]\tLoss: 0.236770\n",
      "Train Epoch: 11 [3200/41964 (6%)]\tLoss: 0.203714\n",
      "Train Epoch: 11 [3840/41964 (8%)]\tLoss: 0.354674\n",
      "Train Epoch: 11 [4480/41964 (9%)]\tLoss: 0.212721\n",
      "Train Epoch: 11 [5120/41964 (10%)]\tLoss: 0.220019\n",
      "Train Epoch: 11 [5760/41964 (12%)]\tLoss: 0.216781\n",
      "Train Epoch: 11 [6400/41964 (13%)]\tLoss: 0.461748\n",
      "Train Epoch: 11 [7040/41964 (14%)]\tLoss: 0.169778\n",
      "Train Epoch: 11 [7680/41964 (15%)]\tLoss: 0.299117\n",
      "Train Epoch: 11 [8320/41964 (17%)]\tLoss: 0.242608\n",
      "Train Epoch: 11 [8960/41964 (18%)]\tLoss: 0.120156\n",
      "Train Epoch: 11 [9600/41964 (19%)]\tLoss: 0.252205\n",
      "Train Epoch: 11 [10240/41964 (20%)]\tLoss: 0.241519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [10880/41964 (22%)]\tLoss: 0.113651\n",
      "Train Epoch: 11 [11520/41964 (23%)]\tLoss: 0.192728\n",
      "Train Epoch: 11 [12160/41964 (24%)]\tLoss: 0.205744\n",
      "Train Epoch: 11 [12800/41964 (26%)]\tLoss: 0.290822\n",
      "Train Epoch: 11 [13440/41964 (27%)]\tLoss: 0.336529\n",
      "Train Epoch: 11 [14080/41964 (28%)]\tLoss: 0.323817\n",
      "Train Epoch: 11 [14720/41964 (29%)]\tLoss: 0.106122\n",
      "Train Epoch: 11 [15360/41964 (31%)]\tLoss: 0.098636\n",
      "Train Epoch: 11 [16000/41964 (32%)]\tLoss: 0.251287\n",
      "Train Epoch: 11 [16640/41964 (33%)]\tLoss: 0.276121\n",
      "Train Epoch: 11 [17280/41964 (35%)]\tLoss: 0.327267\n",
      "Train Epoch: 11 [17920/41964 (36%)]\tLoss: 0.162662\n",
      "Train Epoch: 11 [18560/41964 (37%)]\tLoss: 0.163549\n",
      "Train Epoch: 11 [19200/41964 (38%)]\tLoss: 0.371192\n",
      "Train Epoch: 11 [19840/41964 (40%)]\tLoss: 0.244385\n",
      "Train Epoch: 11 [20480/41964 (41%)]\tLoss: 0.065269\n",
      "Train Epoch: 11 [21120/41964 (42%)]\tLoss: 0.198409\n",
      "Train Epoch: 11 [21760/41964 (43%)]\tLoss: 0.210567\n",
      "Train Epoch: 11 [22400/41964 (45%)]\tLoss: 0.078774\n",
      "Train Epoch: 11 [23040/41964 (46%)]\tLoss: 0.180324\n",
      "Train Epoch: 11 [23680/41964 (47%)]\tLoss: 0.178157\n",
      "Train Epoch: 11 [24320/41964 (49%)]\tLoss: 0.219214\n",
      "Train Epoch: 11 [24960/41964 (50%)]\tLoss: 0.098564\n",
      "Train Epoch: 11 [25600/41964 (51%)]\tLoss: 0.274276\n",
      "Train Epoch: 11 [26240/41964 (52%)]\tLoss: 0.147804\n",
      "Train Epoch: 11 [26880/41964 (54%)]\tLoss: 0.350056\n",
      "Train Epoch: 11 [27520/41964 (55%)]\tLoss: 0.362533\n",
      "Train Epoch: 11 [28160/41964 (56%)]\tLoss: 0.181253\n",
      "Train Epoch: 11 [28800/41964 (58%)]\tLoss: 0.236877\n",
      "Train Epoch: 11 [29440/41964 (59%)]\tLoss: 0.254125\n",
      "Train Epoch: 11 [30080/41964 (60%)]\tLoss: 0.198148\n",
      "Train Epoch: 11 [30720/41964 (61%)]\tLoss: 0.100724\n",
      "Train Epoch: 11 [31360/41964 (63%)]\tLoss: 0.301899\n",
      "Train Epoch: 11 [32000/41964 (64%)]\tLoss: 0.197788\n",
      "Train Epoch: 11 [32640/41964 (65%)]\tLoss: 0.081977\n",
      "Train Epoch: 11 [33280/41964 (66%)]\tLoss: 0.133178\n",
      "Train Epoch: 11 [33920/41964 (68%)]\tLoss: 0.143320\n",
      "Train Epoch: 11 [34560/41964 (69%)]\tLoss: 0.118032\n",
      "Train Epoch: 11 [35200/41964 (70%)]\tLoss: 0.230330\n",
      "Train Epoch: 11 [35840/41964 (72%)]\tLoss: 0.205502\n",
      "Train Epoch: 11 [36480/41964 (73%)]\tLoss: 0.117758\n",
      "Train Epoch: 11 [37120/41964 (74%)]\tLoss: 0.136382\n",
      "Train Epoch: 11 [37760/41964 (75%)]\tLoss: 0.146095\n",
      "Train Epoch: 11 [38400/41964 (77%)]\tLoss: 0.170582\n",
      "Train Epoch: 11 [39040/41964 (78%)]\tLoss: 0.141956\n",
      "Train Epoch: 11 [39680/41964 (79%)]\tLoss: 0.092582\n",
      "Train Epoch: 11 [40320/41964 (81%)]\tLoss: 0.135932\n",
      "Train Epoch: 11 [40960/41964 (82%)]\tLoss: 0.344966\n",
      "Train Epoch: 11 [41600/41964 (83%)]\tLoss: 0.224605\n",
      "Train Epoch: 11 [42240/41964 (84%)]\tLoss: 0.295856\n",
      "Train Epoch: 11 [42880/41964 (86%)]\tLoss: 0.292980\n",
      "Train Epoch: 11 [43520/41964 (87%)]\tLoss: 0.147568\n",
      "Train Epoch: 11 [44160/41964 (88%)]\tLoss: 0.206528\n",
      "Train Epoch: 11 [44800/41964 (90%)]\tLoss: 0.273103\n",
      "Train Epoch: 11 [45440/41964 (91%)]\tLoss: 0.296260\n",
      "Train Epoch: 11 [46080/41964 (92%)]\tLoss: 0.146281\n",
      "Train Epoch: 11 [46720/41964 (93%)]\tLoss: 0.241879\n",
      "Train Epoch: 11 [47360/41964 (95%)]\tLoss: 0.168145\n",
      "Train Epoch: 11 [48000/41964 (96%)]\tLoss: 0.289537\n",
      "Train Epoch: 11 [48640/41964 (97%)]\tLoss: 0.172119\n",
      "Train Epoch: 11 [49280/41964 (98%)]\tLoss: 0.178462\n",
      "Train Epoch: 11 [49920/41964 (100%)]\tLoss: 0.143480\n",
      "\n",
      "Test set: Avg. loss: 0.0573, Accuracy: 9822/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/41964 (0%)]\tLoss: 0.146995\n",
      "Train Epoch: 12 [640/41964 (1%)]\tLoss: 0.407949\n",
      "Train Epoch: 12 [1280/41964 (3%)]\tLoss: 0.258821\n",
      "Train Epoch: 12 [1920/41964 (4%)]\tLoss: 0.279018\n",
      "Train Epoch: 12 [2560/41964 (5%)]\tLoss: 0.054290\n",
      "Train Epoch: 12 [3200/41964 (6%)]\tLoss: 0.115580\n",
      "Train Epoch: 12 [3840/41964 (8%)]\tLoss: 0.081620\n",
      "Train Epoch: 12 [4480/41964 (9%)]\tLoss: 0.270554\n",
      "Train Epoch: 12 [5120/41964 (10%)]\tLoss: 0.267723\n",
      "Train Epoch: 12 [5760/41964 (12%)]\tLoss: 0.182121\n",
      "Train Epoch: 12 [6400/41964 (13%)]\tLoss: 0.189963\n",
      "Train Epoch: 12 [7040/41964 (14%)]\tLoss: 0.122552\n",
      "Train Epoch: 12 [7680/41964 (15%)]\tLoss: 0.276139\n",
      "Train Epoch: 12 [8320/41964 (17%)]\tLoss: 0.103551\n",
      "Train Epoch: 12 [8960/41964 (18%)]\tLoss: 0.318877\n",
      "Train Epoch: 12 [9600/41964 (19%)]\tLoss: 0.292784\n",
      "Train Epoch: 12 [10240/41964 (20%)]\tLoss: 0.132569\n",
      "Train Epoch: 12 [10880/41964 (22%)]\tLoss: 0.478235\n",
      "Train Epoch: 12 [11520/41964 (23%)]\tLoss: 0.141074\n",
      "Train Epoch: 12 [12160/41964 (24%)]\tLoss: 0.190858\n",
      "Train Epoch: 12 [12800/41964 (26%)]\tLoss: 0.094423\n",
      "Train Epoch: 12 [13440/41964 (27%)]\tLoss: 0.359503\n",
      "Train Epoch: 12 [14080/41964 (28%)]\tLoss: 0.083724\n",
      "Train Epoch: 12 [14720/41964 (29%)]\tLoss: 0.456286\n",
      "Train Epoch: 12 [15360/41964 (31%)]\tLoss: 0.122648\n",
      "Train Epoch: 12 [16000/41964 (32%)]\tLoss: 0.157421\n",
      "Train Epoch: 12 [16640/41964 (33%)]\tLoss: 0.229981\n",
      "Train Epoch: 12 [17280/41964 (35%)]\tLoss: 0.313977\n",
      "Train Epoch: 12 [17920/41964 (36%)]\tLoss: 0.192749\n",
      "Train Epoch: 12 [18560/41964 (37%)]\tLoss: 0.185401\n",
      "Train Epoch: 12 [19200/41964 (38%)]\tLoss: 0.202577\n",
      "Train Epoch: 12 [19840/41964 (40%)]\tLoss: 0.152294\n",
      "Train Epoch: 12 [20480/41964 (41%)]\tLoss: 0.275184\n",
      "Train Epoch: 12 [21120/41964 (42%)]\tLoss: 0.228374\n",
      "Train Epoch: 12 [21760/41964 (43%)]\tLoss: 0.253164\n",
      "Train Epoch: 12 [22400/41964 (45%)]\tLoss: 0.122018\n",
      "Train Epoch: 12 [23040/41964 (46%)]\tLoss: 0.236293\n",
      "Train Epoch: 12 [23680/41964 (47%)]\tLoss: 0.132184\n",
      "Train Epoch: 12 [24320/41964 (49%)]\tLoss: 0.168735\n",
      "Train Epoch: 12 [24960/41964 (50%)]\tLoss: 0.151769\n",
      "Train Epoch: 12 [25600/41964 (51%)]\tLoss: 0.144963\n",
      "Train Epoch: 12 [26240/41964 (52%)]\tLoss: 0.331119\n",
      "Train Epoch: 12 [26880/41964 (54%)]\tLoss: 0.281755\n",
      "Train Epoch: 12 [27520/41964 (55%)]\tLoss: 0.333052\n",
      "Train Epoch: 12 [28160/41964 (56%)]\tLoss: 0.433935\n",
      "Train Epoch: 12 [28800/41964 (58%)]\tLoss: 0.142293\n",
      "Train Epoch: 12 [29440/41964 (59%)]\tLoss: 0.168687\n",
      "Train Epoch: 12 [30080/41964 (60%)]\tLoss: 0.293856\n",
      "Train Epoch: 12 [30720/41964 (61%)]\tLoss: 0.069511\n",
      "Train Epoch: 12 [31360/41964 (63%)]\tLoss: 0.155943\n",
      "Train Epoch: 12 [32000/41964 (64%)]\tLoss: 0.191389\n",
      "Train Epoch: 12 [32640/41964 (65%)]\tLoss: 0.228762\n",
      "Train Epoch: 12 [33280/41964 (66%)]\tLoss: 0.061624\n",
      "Train Epoch: 12 [33920/41964 (68%)]\tLoss: 0.280495\n",
      "Train Epoch: 12 [34560/41964 (69%)]\tLoss: 0.138148\n",
      "Train Epoch: 12 [35200/41964 (70%)]\tLoss: 0.132241\n",
      "Train Epoch: 12 [35840/41964 (72%)]\tLoss: 0.147513\n",
      "Train Epoch: 12 [36480/41964 (73%)]\tLoss: 0.141346\n",
      "Train Epoch: 12 [37120/41964 (74%)]\tLoss: 0.139866\n",
      "Train Epoch: 12 [37760/41964 (75%)]\tLoss: 0.394207\n",
      "Train Epoch: 12 [38400/41964 (77%)]\tLoss: 0.118636\n",
      "Train Epoch: 12 [39040/41964 (78%)]\tLoss: 0.263827\n",
      "Train Epoch: 12 [39680/41964 (79%)]\tLoss: 0.102975\n",
      "Train Epoch: 12 [40320/41964 (81%)]\tLoss: 0.216574\n",
      "Train Epoch: 12 [40960/41964 (82%)]\tLoss: 0.333746\n",
      "Train Epoch: 12 [41600/41964 (83%)]\tLoss: 0.139055\n",
      "Train Epoch: 12 [42240/41964 (84%)]\tLoss: 0.141623\n",
      "Train Epoch: 12 [42880/41964 (86%)]\tLoss: 0.197277\n",
      "Train Epoch: 12 [43520/41964 (87%)]\tLoss: 0.105151\n",
      "Train Epoch: 12 [44160/41964 (88%)]\tLoss: 0.139580\n",
      "Train Epoch: 12 [44800/41964 (90%)]\tLoss: 0.217007\n",
      "Train Epoch: 12 [45440/41964 (91%)]\tLoss: 0.176651\n",
      "Train Epoch: 12 [46080/41964 (92%)]\tLoss: 0.130116\n",
      "Train Epoch: 12 [46720/41964 (93%)]\tLoss: 0.255647\n",
      "Train Epoch: 12 [47360/41964 (95%)]\tLoss: 0.155273\n",
      "Train Epoch: 12 [48000/41964 (96%)]\tLoss: 0.278785\n",
      "Train Epoch: 12 [48640/41964 (97%)]\tLoss: 0.303942\n",
      "Train Epoch: 12 [49280/41964 (98%)]\tLoss: 0.333505\n",
      "Train Epoch: 12 [49920/41964 (100%)]\tLoss: 0.189992\n",
      "\n",
      "Test set: Avg. loss: 0.0546, Accuracy: 9817/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/41964 (0%)]\tLoss: 0.107110\n",
      "Train Epoch: 13 [640/41964 (1%)]\tLoss: 0.183156\n",
      "Train Epoch: 13 [1280/41964 (3%)]\tLoss: 0.160084\n",
      "Train Epoch: 13 [1920/41964 (4%)]\tLoss: 0.164174\n",
      "Train Epoch: 13 [2560/41964 (5%)]\tLoss: 0.338179\n",
      "Train Epoch: 13 [3200/41964 (6%)]\tLoss: 0.145190\n",
      "Train Epoch: 13 [3840/41964 (8%)]\tLoss: 0.267469\n",
      "Train Epoch: 13 [4480/41964 (9%)]\tLoss: 0.208171\n",
      "Train Epoch: 13 [5120/41964 (10%)]\tLoss: 0.126482\n",
      "Train Epoch: 13 [5760/41964 (12%)]\tLoss: 0.256663\n",
      "Train Epoch: 13 [6400/41964 (13%)]\tLoss: 0.256515\n",
      "Train Epoch: 13 [7040/41964 (14%)]\tLoss: 0.056987\n",
      "Train Epoch: 13 [7680/41964 (15%)]\tLoss: 0.124064\n",
      "Train Epoch: 13 [8320/41964 (17%)]\tLoss: 0.152004\n",
      "Train Epoch: 13 [8960/41964 (18%)]\tLoss: 0.184117\n",
      "Train Epoch: 13 [9600/41964 (19%)]\tLoss: 0.196283\n",
      "Train Epoch: 13 [10240/41964 (20%)]\tLoss: 0.091210\n",
      "Train Epoch: 13 [10880/41964 (22%)]\tLoss: 0.114267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [11520/41964 (23%)]\tLoss: 0.247408\n",
      "Train Epoch: 13 [12160/41964 (24%)]\tLoss: 0.206007\n",
      "Train Epoch: 13 [12800/41964 (26%)]\tLoss: 0.213637\n",
      "Train Epoch: 13 [13440/41964 (27%)]\tLoss: 0.052805\n",
      "Train Epoch: 13 [14080/41964 (28%)]\tLoss: 0.307117\n",
      "Train Epoch: 13 [14720/41964 (29%)]\tLoss: 0.148826\n",
      "Train Epoch: 13 [15360/41964 (31%)]\tLoss: 0.111425\n",
      "Train Epoch: 13 [16000/41964 (32%)]\tLoss: 0.124199\n",
      "Train Epoch: 13 [16640/41964 (33%)]\tLoss: 0.367557\n",
      "Train Epoch: 13 [17280/41964 (35%)]\tLoss: 0.351469\n",
      "Train Epoch: 13 [17920/41964 (36%)]\tLoss: 0.136969\n",
      "Train Epoch: 13 [18560/41964 (37%)]\tLoss: 0.104374\n",
      "Train Epoch: 13 [19200/41964 (38%)]\tLoss: 0.276385\n",
      "Train Epoch: 13 [19840/41964 (40%)]\tLoss: 0.227876\n",
      "Train Epoch: 13 [20480/41964 (41%)]\tLoss: 0.222093\n",
      "Train Epoch: 13 [21120/41964 (42%)]\tLoss: 0.255505\n",
      "Train Epoch: 13 [21760/41964 (43%)]\tLoss: 0.190133\n",
      "Train Epoch: 13 [22400/41964 (45%)]\tLoss: 0.182015\n",
      "Train Epoch: 13 [23040/41964 (46%)]\tLoss: 0.183547\n",
      "Train Epoch: 13 [23680/41964 (47%)]\tLoss: 0.249526\n",
      "Train Epoch: 13 [24320/41964 (49%)]\tLoss: 0.269269\n",
      "Train Epoch: 13 [24960/41964 (50%)]\tLoss: 0.234237\n",
      "Train Epoch: 13 [25600/41964 (51%)]\tLoss: 0.108948\n",
      "Train Epoch: 13 [26240/41964 (52%)]\tLoss: 0.130955\n",
      "Train Epoch: 13 [26880/41964 (54%)]\tLoss: 0.111640\n",
      "Train Epoch: 13 [27520/41964 (55%)]\tLoss: 0.123556\n",
      "Train Epoch: 13 [28160/41964 (56%)]\tLoss: 0.119865\n",
      "Train Epoch: 13 [28800/41964 (58%)]\tLoss: 0.198330\n",
      "Train Epoch: 13 [29440/41964 (59%)]\tLoss: 0.124532\n",
      "Train Epoch: 13 [30080/41964 (60%)]\tLoss: 0.116718\n",
      "Train Epoch: 13 [30720/41964 (61%)]\tLoss: 0.183019\n",
      "Train Epoch: 13 [31360/41964 (63%)]\tLoss: 0.075239\n",
      "Train Epoch: 13 [32000/41964 (64%)]\tLoss: 0.196096\n",
      "Train Epoch: 13 [32640/41964 (65%)]\tLoss: 0.234909\n",
      "Train Epoch: 13 [33280/41964 (66%)]\tLoss: 0.132319\n",
      "Train Epoch: 13 [33920/41964 (68%)]\tLoss: 0.175601\n",
      "Train Epoch: 13 [34560/41964 (69%)]\tLoss: 0.121525\n",
      "Train Epoch: 13 [35200/41964 (70%)]\tLoss: 0.286706\n",
      "Train Epoch: 13 [35840/41964 (72%)]\tLoss: 0.170236\n",
      "Train Epoch: 13 [36480/41964 (73%)]\tLoss: 0.178975\n",
      "Train Epoch: 13 [37120/41964 (74%)]\tLoss: 0.227353\n",
      "Train Epoch: 13 [37760/41964 (75%)]\tLoss: 0.260079\n",
      "Train Epoch: 13 [38400/41964 (77%)]\tLoss: 0.128168\n",
      "Train Epoch: 13 [39040/41964 (78%)]\tLoss: 0.245503\n",
      "Train Epoch: 13 [39680/41964 (79%)]\tLoss: 0.441633\n",
      "Train Epoch: 13 [40320/41964 (81%)]\tLoss: 0.306177\n",
      "Train Epoch: 13 [40960/41964 (82%)]\tLoss: 0.215168\n",
      "Train Epoch: 13 [41600/41964 (83%)]\tLoss: 0.289033\n",
      "Train Epoch: 13 [42240/41964 (84%)]\tLoss: 0.272906\n",
      "Train Epoch: 13 [42880/41964 (86%)]\tLoss: 0.142652\n",
      "Train Epoch: 13 [43520/41964 (87%)]\tLoss: 0.138769\n",
      "Train Epoch: 13 [44160/41964 (88%)]\tLoss: 0.045188\n",
      "Train Epoch: 13 [44800/41964 (90%)]\tLoss: 0.130672\n",
      "Train Epoch: 13 [45440/41964 (91%)]\tLoss: 0.192924\n",
      "Train Epoch: 13 [46080/41964 (92%)]\tLoss: 0.166077\n",
      "Train Epoch: 13 [46720/41964 (93%)]\tLoss: 0.354077\n",
      "Train Epoch: 13 [47360/41964 (95%)]\tLoss: 0.161822\n",
      "Train Epoch: 13 [48000/41964 (96%)]\tLoss: 0.132446\n",
      "Train Epoch: 13 [48640/41964 (97%)]\tLoss: 0.252298\n",
      "Train Epoch: 13 [49280/41964 (98%)]\tLoss: 0.297797\n",
      "Train Epoch: 13 [49920/41964 (100%)]\tLoss: 0.070060\n",
      "\n",
      "Test set: Avg. loss: 0.0550, Accuracy: 9833/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/41964 (0%)]\tLoss: 0.277714\n",
      "Train Epoch: 14 [640/41964 (1%)]\tLoss: 0.138751\n",
      "Train Epoch: 14 [1280/41964 (3%)]\tLoss: 0.263691\n",
      "Train Epoch: 14 [1920/41964 (4%)]\tLoss: 0.133591\n",
      "Train Epoch: 14 [2560/41964 (5%)]\tLoss: 0.129888\n",
      "Train Epoch: 14 [3200/41964 (6%)]\tLoss: 0.152421\n",
      "Train Epoch: 14 [3840/41964 (8%)]\tLoss: 0.262763\n",
      "Train Epoch: 14 [4480/41964 (9%)]\tLoss: 0.152341\n",
      "Train Epoch: 14 [5120/41964 (10%)]\tLoss: 0.329271\n",
      "Train Epoch: 14 [5760/41964 (12%)]\tLoss: 0.160875\n",
      "Train Epoch: 14 [6400/41964 (13%)]\tLoss: 0.070878\n",
      "Train Epoch: 14 [7040/41964 (14%)]\tLoss: 0.161528\n",
      "Train Epoch: 14 [7680/41964 (15%)]\tLoss: 0.141080\n",
      "Train Epoch: 14 [8320/41964 (17%)]\tLoss: 0.207119\n",
      "Train Epoch: 14 [8960/41964 (18%)]\tLoss: 0.114479\n",
      "Train Epoch: 14 [9600/41964 (19%)]\tLoss: 0.266597\n",
      "Train Epoch: 14 [10240/41964 (20%)]\tLoss: 0.183316\n",
      "Train Epoch: 14 [10880/41964 (22%)]\tLoss: 0.166211\n",
      "Train Epoch: 14 [11520/41964 (23%)]\tLoss: 0.313500\n",
      "Train Epoch: 14 [12160/41964 (24%)]\tLoss: 0.390274\n",
      "Train Epoch: 14 [12800/41964 (26%)]\tLoss: 0.182559\n",
      "Train Epoch: 14 [13440/41964 (27%)]\tLoss: 0.231898\n",
      "Train Epoch: 14 [14080/41964 (28%)]\tLoss: 0.208413\n",
      "Train Epoch: 14 [14720/41964 (29%)]\tLoss: 0.114017\n",
      "Train Epoch: 14 [15360/41964 (31%)]\tLoss: 0.090660\n",
      "Train Epoch: 14 [16000/41964 (32%)]\tLoss: 0.215690\n",
      "Train Epoch: 14 [16640/41964 (33%)]\tLoss: 0.220056\n",
      "Train Epoch: 14 [17280/41964 (35%)]\tLoss: 0.290379\n",
      "Train Epoch: 14 [17920/41964 (36%)]\tLoss: 0.298538\n",
      "Train Epoch: 14 [18560/41964 (37%)]\tLoss: 0.133054\n",
      "Train Epoch: 14 [19200/41964 (38%)]\tLoss: 0.188042\n",
      "Train Epoch: 14 [19840/41964 (40%)]\tLoss: 0.117209\n",
      "Train Epoch: 14 [20480/41964 (41%)]\tLoss: 0.201103\n",
      "Train Epoch: 14 [21120/41964 (42%)]\tLoss: 0.279144\n",
      "Train Epoch: 14 [21760/41964 (43%)]\tLoss: 0.106781\n",
      "Train Epoch: 14 [22400/41964 (45%)]\tLoss: 0.214331\n",
      "Train Epoch: 14 [23040/41964 (46%)]\tLoss: 0.163026\n",
      "Train Epoch: 14 [23680/41964 (47%)]\tLoss: 0.123518\n",
      "Train Epoch: 14 [24320/41964 (49%)]\tLoss: 0.375918\n",
      "Train Epoch: 14 [24960/41964 (50%)]\tLoss: 0.123627\n",
      "Train Epoch: 14 [25600/41964 (51%)]\tLoss: 0.156906\n",
      "Train Epoch: 14 [26240/41964 (52%)]\tLoss: 0.227072\n",
      "Train Epoch: 14 [26880/41964 (54%)]\tLoss: 0.051508\n",
      "Train Epoch: 14 [27520/41964 (55%)]\tLoss: 0.310810\n",
      "Train Epoch: 14 [28160/41964 (56%)]\tLoss: 0.098062\n",
      "Train Epoch: 14 [28800/41964 (58%)]\tLoss: 0.261030\n",
      "Train Epoch: 14 [29440/41964 (59%)]\tLoss: 0.177715\n",
      "Train Epoch: 14 [30080/41964 (60%)]\tLoss: 0.182049\n",
      "Train Epoch: 14 [30720/41964 (61%)]\tLoss: 0.179689\n",
      "Train Epoch: 14 [31360/41964 (63%)]\tLoss: 0.247463\n",
      "Train Epoch: 14 [32000/41964 (64%)]\tLoss: 0.201173\n",
      "Train Epoch: 14 [32640/41964 (65%)]\tLoss: 0.269088\n",
      "Train Epoch: 14 [33280/41964 (66%)]\tLoss: 0.137274\n",
      "Train Epoch: 14 [33920/41964 (68%)]\tLoss: 0.160714\n",
      "Train Epoch: 14 [34560/41964 (69%)]\tLoss: 0.152864\n",
      "Train Epoch: 14 [35200/41964 (70%)]\tLoss: 0.149068\n",
      "Train Epoch: 14 [35840/41964 (72%)]\tLoss: 0.204031\n",
      "Train Epoch: 14 [36480/41964 (73%)]\tLoss: 0.088346\n",
      "Train Epoch: 14 [37120/41964 (74%)]\tLoss: 0.087450\n",
      "Train Epoch: 14 [37760/41964 (75%)]\tLoss: 0.318203\n",
      "Train Epoch: 14 [38400/41964 (77%)]\tLoss: 0.106387\n",
      "Train Epoch: 14 [39040/41964 (78%)]\tLoss: 0.290080\n",
      "Train Epoch: 14 [39680/41964 (79%)]\tLoss: 0.268817\n",
      "Train Epoch: 14 [40320/41964 (81%)]\tLoss: 0.202085\n",
      "Train Epoch: 14 [40960/41964 (82%)]\tLoss: 0.127628\n",
      "Train Epoch: 14 [41600/41964 (83%)]\tLoss: 0.099170\n",
      "Train Epoch: 14 [42240/41964 (84%)]\tLoss: 0.077684\n",
      "Train Epoch: 14 [42880/41964 (86%)]\tLoss: 0.141822\n",
      "Train Epoch: 14 [43520/41964 (87%)]\tLoss: 0.089588\n",
      "Train Epoch: 14 [44160/41964 (88%)]\tLoss: 0.171792\n",
      "Train Epoch: 14 [44800/41964 (90%)]\tLoss: 0.171693\n",
      "Train Epoch: 14 [45440/41964 (91%)]\tLoss: 0.405253\n",
      "Train Epoch: 14 [46080/41964 (92%)]\tLoss: 0.257396\n",
      "Train Epoch: 14 [46720/41964 (93%)]\tLoss: 0.208343\n",
      "Train Epoch: 14 [47360/41964 (95%)]\tLoss: 0.156518\n",
      "Train Epoch: 14 [48000/41964 (96%)]\tLoss: 0.115377\n",
      "Train Epoch: 14 [48640/41964 (97%)]\tLoss: 0.178013\n",
      "Train Epoch: 14 [49280/41964 (98%)]\tLoss: 0.172728\n",
      "Train Epoch: 14 [49920/41964 (100%)]\tLoss: 0.133014\n",
      "\n",
      "Test set: Avg. loss: 0.0499, Accuracy: 9842/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/41964 (0%)]\tLoss: 0.125728\n",
      "Train Epoch: 15 [640/41964 (1%)]\tLoss: 0.239505\n",
      "Train Epoch: 15 [1280/41964 (3%)]\tLoss: 0.138379\n",
      "Train Epoch: 15 [1920/41964 (4%)]\tLoss: 0.144516\n",
      "Train Epoch: 15 [2560/41964 (5%)]\tLoss: 0.197590\n",
      "Train Epoch: 15 [3200/41964 (6%)]\tLoss: 0.118871\n",
      "Train Epoch: 15 [3840/41964 (8%)]\tLoss: 0.237188\n",
      "Train Epoch: 15 [4480/41964 (9%)]\tLoss: 0.390859\n",
      "Train Epoch: 15 [5120/41964 (10%)]\tLoss: 0.068313\n",
      "Train Epoch: 15 [5760/41964 (12%)]\tLoss: 0.392494\n",
      "Train Epoch: 15 [6400/41964 (13%)]\tLoss: 0.327115\n",
      "Train Epoch: 15 [7040/41964 (14%)]\tLoss: 0.289407\n",
      "Train Epoch: 15 [7680/41964 (15%)]\tLoss: 0.250348\n",
      "Train Epoch: 15 [8320/41964 (17%)]\tLoss: 0.205049\n",
      "Train Epoch: 15 [8960/41964 (18%)]\tLoss: 0.175502\n",
      "Train Epoch: 15 [9600/41964 (19%)]\tLoss: 0.262841\n",
      "Train Epoch: 15 [10240/41964 (20%)]\tLoss: 0.236304\n",
      "Train Epoch: 15 [10880/41964 (22%)]\tLoss: 0.165099\n",
      "Train Epoch: 15 [11520/41964 (23%)]\tLoss: 0.257789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [12160/41964 (24%)]\tLoss: 0.505357\n",
      "Train Epoch: 15 [12800/41964 (26%)]\tLoss: 0.154870\n",
      "Train Epoch: 15 [13440/41964 (27%)]\tLoss: 0.209835\n",
      "Train Epoch: 15 [14080/41964 (28%)]\tLoss: 0.364838\n",
      "Train Epoch: 15 [14720/41964 (29%)]\tLoss: 0.288274\n",
      "Train Epoch: 15 [15360/41964 (31%)]\tLoss: 0.181242\n",
      "Train Epoch: 15 [16000/41964 (32%)]\tLoss: 0.175474\n",
      "Train Epoch: 15 [16640/41964 (33%)]\tLoss: 0.197019\n",
      "Train Epoch: 15 [17280/41964 (35%)]\tLoss: 0.135351\n",
      "Train Epoch: 15 [17920/41964 (36%)]\tLoss: 0.194462\n",
      "Train Epoch: 15 [18560/41964 (37%)]\tLoss: 0.241991\n",
      "Train Epoch: 15 [19200/41964 (38%)]\tLoss: 0.237923\n",
      "Train Epoch: 15 [19840/41964 (40%)]\tLoss: 0.130044\n",
      "Train Epoch: 15 [20480/41964 (41%)]\tLoss: 0.207063\n",
      "Train Epoch: 15 [21120/41964 (42%)]\tLoss: 0.197720\n",
      "Train Epoch: 15 [21760/41964 (43%)]\tLoss: 0.144837\n",
      "Train Epoch: 15 [22400/41964 (45%)]\tLoss: 0.122157\n",
      "Train Epoch: 15 [23040/41964 (46%)]\tLoss: 0.323513\n",
      "Train Epoch: 15 [23680/41964 (47%)]\tLoss: 0.167841\n",
      "Train Epoch: 15 [24320/41964 (49%)]\tLoss: 0.305183\n",
      "Train Epoch: 15 [24960/41964 (50%)]\tLoss: 0.183200\n",
      "Train Epoch: 15 [25600/41964 (51%)]\tLoss: 0.196917\n",
      "Train Epoch: 15 [26240/41964 (52%)]\tLoss: 0.104480\n",
      "Train Epoch: 15 [26880/41964 (54%)]\tLoss: 0.230367\n",
      "Train Epoch: 15 [27520/41964 (55%)]\tLoss: 0.360972\n",
      "Train Epoch: 15 [28160/41964 (56%)]\tLoss: 0.155172\n",
      "Train Epoch: 15 [28800/41964 (58%)]\tLoss: 0.156894\n",
      "Train Epoch: 15 [29440/41964 (59%)]\tLoss: 0.192797\n",
      "Train Epoch: 15 [30080/41964 (60%)]\tLoss: 0.211850\n",
      "Train Epoch: 15 [30720/41964 (61%)]\tLoss: 0.117001\n",
      "Train Epoch: 15 [31360/41964 (63%)]\tLoss: 0.367514\n",
      "Train Epoch: 15 [32000/41964 (64%)]\tLoss: 0.178360\n",
      "Train Epoch: 15 [32640/41964 (65%)]\tLoss: 0.110942\n",
      "Train Epoch: 15 [33280/41964 (66%)]\tLoss: 0.338033\n",
      "Train Epoch: 15 [33920/41964 (68%)]\tLoss: 0.312004\n",
      "Train Epoch: 15 [34560/41964 (69%)]\tLoss: 0.216466\n",
      "Train Epoch: 15 [35200/41964 (70%)]\tLoss: 0.289755\n",
      "Train Epoch: 15 [35840/41964 (72%)]\tLoss: 0.194645\n",
      "Train Epoch: 15 [36480/41964 (73%)]\tLoss: 0.213345\n",
      "Train Epoch: 15 [37120/41964 (74%)]\tLoss: 0.282643\n",
      "Train Epoch: 15 [37760/41964 (75%)]\tLoss: 0.220996\n",
      "Train Epoch: 15 [38400/41964 (77%)]\tLoss: 0.298958\n",
      "Train Epoch: 15 [39040/41964 (78%)]\tLoss: 0.142914\n",
      "Train Epoch: 15 [39680/41964 (79%)]\tLoss: 0.079940\n",
      "Train Epoch: 15 [40320/41964 (81%)]\tLoss: 0.110285\n",
      "Train Epoch: 15 [40960/41964 (82%)]\tLoss: 0.166421\n",
      "Train Epoch: 15 [41600/41964 (83%)]\tLoss: 0.266628\n",
      "Train Epoch: 15 [42240/41964 (84%)]\tLoss: 0.126206\n",
      "Train Epoch: 15 [42880/41964 (86%)]\tLoss: 0.183542\n",
      "Train Epoch: 15 [43520/41964 (87%)]\tLoss: 0.263674\n",
      "Train Epoch: 15 [44160/41964 (88%)]\tLoss: 0.205161\n",
      "Train Epoch: 15 [44800/41964 (90%)]\tLoss: 0.204997\n",
      "Train Epoch: 15 [45440/41964 (91%)]\tLoss: 0.346351\n",
      "Train Epoch: 15 [46080/41964 (92%)]\tLoss: 0.089424\n",
      "Train Epoch: 15 [46720/41964 (93%)]\tLoss: 0.215367\n",
      "Train Epoch: 15 [47360/41964 (95%)]\tLoss: 0.305422\n",
      "Train Epoch: 15 [48000/41964 (96%)]\tLoss: 0.063303\n",
      "Train Epoch: 15 [48640/41964 (97%)]\tLoss: 0.465973\n",
      "Train Epoch: 15 [49280/41964 (98%)]\tLoss: 0.129100\n",
      "Train Epoch: 15 [49920/41964 (100%)]\tLoss: 0.178102\n",
      "\n",
      "Test set: Avg. loss: 0.0484, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/41964 (0%)]\tLoss: 0.057143\n",
      "Train Epoch: 16 [640/41964 (1%)]\tLoss: 0.099986\n",
      "Train Epoch: 16 [1280/41964 (3%)]\tLoss: 0.427297\n",
      "Train Epoch: 16 [1920/41964 (4%)]\tLoss: 0.187102\n",
      "Train Epoch: 16 [2560/41964 (5%)]\tLoss: 0.102402\n",
      "Train Epoch: 16 [3200/41964 (6%)]\tLoss: 0.176033\n",
      "Train Epoch: 16 [3840/41964 (8%)]\tLoss: 0.262617\n",
      "Train Epoch: 16 [4480/41964 (9%)]\tLoss: 0.130079\n",
      "Train Epoch: 16 [5120/41964 (10%)]\tLoss: 0.163001\n",
      "Train Epoch: 16 [5760/41964 (12%)]\tLoss: 0.171237\n",
      "Train Epoch: 16 [6400/41964 (13%)]\tLoss: 0.087764\n",
      "Train Epoch: 16 [7040/41964 (14%)]\tLoss: 0.096359\n",
      "Train Epoch: 16 [7680/41964 (15%)]\tLoss: 0.441944\n",
      "Train Epoch: 16 [8320/41964 (17%)]\tLoss: 0.274244\n",
      "Train Epoch: 16 [8960/41964 (18%)]\tLoss: 0.130648\n",
      "Train Epoch: 16 [9600/41964 (19%)]\tLoss: 0.473352\n",
      "Train Epoch: 16 [10240/41964 (20%)]\tLoss: 0.271268\n",
      "Train Epoch: 16 [10880/41964 (22%)]\tLoss: 0.112513\n",
      "Train Epoch: 16 [11520/41964 (23%)]\tLoss: 0.356459\n",
      "Train Epoch: 16 [12160/41964 (24%)]\tLoss: 0.128553\n",
      "Train Epoch: 16 [12800/41964 (26%)]\tLoss: 0.196610\n",
      "Train Epoch: 16 [13440/41964 (27%)]\tLoss: 0.315874\n",
      "Train Epoch: 16 [14080/41964 (28%)]\tLoss: 0.108582\n",
      "Train Epoch: 16 [14720/41964 (29%)]\tLoss: 0.133347\n",
      "Train Epoch: 16 [15360/41964 (31%)]\tLoss: 0.258803\n",
      "Train Epoch: 16 [16000/41964 (32%)]\tLoss: 0.117762\n",
      "Train Epoch: 16 [16640/41964 (33%)]\tLoss: 0.310728\n",
      "Train Epoch: 16 [17280/41964 (35%)]\tLoss: 0.290837\n",
      "Train Epoch: 16 [17920/41964 (36%)]\tLoss: 0.109362\n",
      "Train Epoch: 16 [18560/41964 (37%)]\tLoss: 0.253787\n",
      "Train Epoch: 16 [19200/41964 (38%)]\tLoss: 0.293602\n",
      "Train Epoch: 16 [19840/41964 (40%)]\tLoss: 0.120944\n",
      "Train Epoch: 16 [20480/41964 (41%)]\tLoss: 0.146946\n",
      "Train Epoch: 16 [21120/41964 (42%)]\tLoss: 0.087941\n",
      "Train Epoch: 16 [21760/41964 (43%)]\tLoss: 0.097772\n",
      "Train Epoch: 16 [22400/41964 (45%)]\tLoss: 0.330936\n",
      "Train Epoch: 16 [23040/41964 (46%)]\tLoss: 0.308887\n",
      "Train Epoch: 16 [23680/41964 (47%)]\tLoss: 0.291046\n",
      "Train Epoch: 16 [24320/41964 (49%)]\tLoss: 0.183662\n",
      "Train Epoch: 16 [24960/41964 (50%)]\tLoss: 0.261910\n",
      "Train Epoch: 16 [25600/41964 (51%)]\tLoss: 0.081804\n",
      "Train Epoch: 16 [26240/41964 (52%)]\tLoss: 0.220857\n",
      "Train Epoch: 16 [26880/41964 (54%)]\tLoss: 0.081964\n",
      "Train Epoch: 16 [27520/41964 (55%)]\tLoss: 0.147537\n",
      "Train Epoch: 16 [28160/41964 (56%)]\tLoss: 0.125798\n",
      "Train Epoch: 16 [28800/41964 (58%)]\tLoss: 0.179621\n",
      "Train Epoch: 16 [29440/41964 (59%)]\tLoss: 0.170886\n",
      "Train Epoch: 16 [30080/41964 (60%)]\tLoss: 0.185242\n",
      "Train Epoch: 16 [30720/41964 (61%)]\tLoss: 0.400084\n",
      "Train Epoch: 16 [31360/41964 (63%)]\tLoss: 0.090225\n",
      "Train Epoch: 16 [32000/41964 (64%)]\tLoss: 0.142106\n",
      "Train Epoch: 16 [32640/41964 (65%)]\tLoss: 0.112489\n",
      "Train Epoch: 16 [33280/41964 (66%)]\tLoss: 0.224021\n",
      "Train Epoch: 16 [33920/41964 (68%)]\tLoss: 0.101065\n",
      "Train Epoch: 16 [34560/41964 (69%)]\tLoss: 0.122944\n",
      "Train Epoch: 16 [35200/41964 (70%)]\tLoss: 0.198838\n",
      "Train Epoch: 16 [35840/41964 (72%)]\tLoss: 0.336363\n",
      "Train Epoch: 16 [36480/41964 (73%)]\tLoss: 0.293974\n",
      "Train Epoch: 16 [37120/41964 (74%)]\tLoss: 0.174663\n",
      "Train Epoch: 16 [37760/41964 (75%)]\tLoss: 0.276370\n",
      "Train Epoch: 16 [38400/41964 (77%)]\tLoss: 0.227662\n",
      "Train Epoch: 16 [39040/41964 (78%)]\tLoss: 0.117638\n",
      "Train Epoch: 16 [39680/41964 (79%)]\tLoss: 0.163886\n",
      "Train Epoch: 16 [40320/41964 (81%)]\tLoss: 0.059273\n",
      "Train Epoch: 16 [40960/41964 (82%)]\tLoss: 0.083317\n",
      "Train Epoch: 16 [41600/41964 (83%)]\tLoss: 0.218031\n",
      "Train Epoch: 16 [42240/41964 (84%)]\tLoss: 0.157985\n",
      "Train Epoch: 16 [42880/41964 (86%)]\tLoss: 0.291390\n",
      "Train Epoch: 16 [43520/41964 (87%)]\tLoss: 0.204272\n",
      "Train Epoch: 16 [44160/41964 (88%)]\tLoss: 0.096704\n",
      "Train Epoch: 16 [44800/41964 (90%)]\tLoss: 0.062456\n",
      "Train Epoch: 16 [45440/41964 (91%)]\tLoss: 0.192894\n",
      "Train Epoch: 16 [46080/41964 (92%)]\tLoss: 0.096852\n",
      "Train Epoch: 16 [46720/41964 (93%)]\tLoss: 0.338457\n",
      "Train Epoch: 16 [47360/41964 (95%)]\tLoss: 0.249366\n",
      "Train Epoch: 16 [48000/41964 (96%)]\tLoss: 0.132958\n",
      "Train Epoch: 16 [48640/41964 (97%)]\tLoss: 0.153945\n",
      "Train Epoch: 16 [49280/41964 (98%)]\tLoss: 0.125456\n",
      "Train Epoch: 16 [49920/41964 (100%)]\tLoss: 0.117523\n",
      "\n",
      "Test set: Avg. loss: 0.0489, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/41964 (0%)]\tLoss: 0.378599\n",
      "Train Epoch: 17 [640/41964 (1%)]\tLoss: 0.179554\n",
      "Train Epoch: 17 [1280/41964 (3%)]\tLoss: 0.264900\n",
      "Train Epoch: 17 [1920/41964 (4%)]\tLoss: 0.185574\n",
      "Train Epoch: 17 [2560/41964 (5%)]\tLoss: 0.180719\n",
      "Train Epoch: 17 [3200/41964 (6%)]\tLoss: 0.256242\n",
      "Train Epoch: 17 [3840/41964 (8%)]\tLoss: 0.102362\n",
      "Train Epoch: 17 [4480/41964 (9%)]\tLoss: 0.108362\n",
      "Train Epoch: 17 [5120/41964 (10%)]\tLoss: 0.403397\n",
      "Train Epoch: 17 [5760/41964 (12%)]\tLoss: 0.260530\n",
      "Train Epoch: 17 [6400/41964 (13%)]\tLoss: 0.136096\n",
      "Train Epoch: 17 [7040/41964 (14%)]\tLoss: 0.170913\n",
      "Train Epoch: 17 [7680/41964 (15%)]\tLoss: 0.165123\n",
      "Train Epoch: 17 [8320/41964 (17%)]\tLoss: 0.134603\n",
      "Train Epoch: 17 [8960/41964 (18%)]\tLoss: 0.253132\n",
      "Train Epoch: 17 [9600/41964 (19%)]\tLoss: 0.090233\n",
      "Train Epoch: 17 [10240/41964 (20%)]\tLoss: 0.131346\n",
      "Train Epoch: 17 [10880/41964 (22%)]\tLoss: 0.103667\n",
      "Train Epoch: 17 [11520/41964 (23%)]\tLoss: 0.322752\n",
      "Train Epoch: 17 [12160/41964 (24%)]\tLoss: 0.312419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [12800/41964 (26%)]\tLoss: 0.119715\n",
      "Train Epoch: 17 [13440/41964 (27%)]\tLoss: 0.179626\n",
      "Train Epoch: 17 [14080/41964 (28%)]\tLoss: 0.069145\n",
      "Train Epoch: 17 [14720/41964 (29%)]\tLoss: 0.326959\n",
      "Train Epoch: 17 [15360/41964 (31%)]\tLoss: 0.094572\n",
      "Train Epoch: 17 [16000/41964 (32%)]\tLoss: 0.063248\n",
      "Train Epoch: 17 [16640/41964 (33%)]\tLoss: 0.153094\n",
      "Train Epoch: 17 [17280/41964 (35%)]\tLoss: 0.110892\n",
      "Train Epoch: 17 [17920/41964 (36%)]\tLoss: 0.049629\n",
      "Train Epoch: 17 [18560/41964 (37%)]\tLoss: 0.183856\n",
      "Train Epoch: 17 [19200/41964 (38%)]\tLoss: 0.303642\n",
      "Train Epoch: 17 [19840/41964 (40%)]\tLoss: 0.156667\n",
      "Train Epoch: 17 [20480/41964 (41%)]\tLoss: 0.442924\n",
      "Train Epoch: 17 [21120/41964 (42%)]\tLoss: 0.108853\n",
      "Train Epoch: 17 [21760/41964 (43%)]\tLoss: 0.092960\n",
      "Train Epoch: 17 [22400/41964 (45%)]\tLoss: 0.200974\n",
      "Train Epoch: 17 [23040/41964 (46%)]\tLoss: 0.023764\n",
      "Train Epoch: 17 [23680/41964 (47%)]\tLoss: 0.139563\n",
      "Train Epoch: 17 [24320/41964 (49%)]\tLoss: 0.279174\n",
      "Train Epoch: 17 [24960/41964 (50%)]\tLoss: 0.057291\n",
      "Train Epoch: 17 [25600/41964 (51%)]\tLoss: 0.244050\n",
      "Train Epoch: 17 [26240/41964 (52%)]\tLoss: 0.133224\n",
      "Train Epoch: 17 [26880/41964 (54%)]\tLoss: 0.221695\n",
      "Train Epoch: 17 [27520/41964 (55%)]\tLoss: 0.137549\n",
      "Train Epoch: 17 [28160/41964 (56%)]\tLoss: 0.094236\n",
      "Train Epoch: 17 [28800/41964 (58%)]\tLoss: 0.186770\n",
      "Train Epoch: 17 [29440/41964 (59%)]\tLoss: 0.210603\n",
      "Train Epoch: 17 [30080/41964 (60%)]\tLoss: 0.557124\n",
      "Train Epoch: 17 [30720/41964 (61%)]\tLoss: 0.114980\n",
      "Train Epoch: 17 [31360/41964 (63%)]\tLoss: 0.122658\n",
      "Train Epoch: 17 [32000/41964 (64%)]\tLoss: 0.225348\n",
      "Train Epoch: 17 [32640/41964 (65%)]\tLoss: 0.126016\n",
      "Train Epoch: 17 [33280/41964 (66%)]\tLoss: 0.176116\n",
      "Train Epoch: 17 [33920/41964 (68%)]\tLoss: 0.212808\n",
      "Train Epoch: 17 [34560/41964 (69%)]\tLoss: 0.106567\n",
      "Train Epoch: 17 [35200/41964 (70%)]\tLoss: 0.115261\n",
      "Train Epoch: 17 [35840/41964 (72%)]\tLoss: 0.178134\n",
      "Train Epoch: 17 [36480/41964 (73%)]\tLoss: 0.161382\n",
      "Train Epoch: 17 [37120/41964 (74%)]\tLoss: 0.279009\n",
      "Train Epoch: 17 [37760/41964 (75%)]\tLoss: 0.099768\n",
      "Train Epoch: 17 [38400/41964 (77%)]\tLoss: 0.150469\n",
      "Train Epoch: 17 [39040/41964 (78%)]\tLoss: 0.100211\n",
      "Train Epoch: 17 [39680/41964 (79%)]\tLoss: 0.478793\n",
      "Train Epoch: 17 [40320/41964 (81%)]\tLoss: 0.382968\n",
      "Train Epoch: 17 [40960/41964 (82%)]\tLoss: 0.066329\n",
      "Train Epoch: 17 [41600/41964 (83%)]\tLoss: 0.442988\n",
      "Train Epoch: 17 [42240/41964 (84%)]\tLoss: 0.097286\n",
      "Train Epoch: 17 [42880/41964 (86%)]\tLoss: 0.171944\n",
      "Train Epoch: 17 [43520/41964 (87%)]\tLoss: 0.199025\n",
      "Train Epoch: 17 [44160/41964 (88%)]\tLoss: 0.207911\n",
      "Train Epoch: 17 [44800/41964 (90%)]\tLoss: 0.123037\n",
      "Train Epoch: 17 [45440/41964 (91%)]\tLoss: 0.134038\n",
      "Train Epoch: 17 [46080/41964 (92%)]\tLoss: 0.202938\n",
      "Train Epoch: 17 [46720/41964 (93%)]\tLoss: 0.181975\n",
      "Train Epoch: 17 [47360/41964 (95%)]\tLoss: 0.248014\n",
      "Train Epoch: 17 [48000/41964 (96%)]\tLoss: 0.122241\n",
      "Train Epoch: 17 [48640/41964 (97%)]\tLoss: 0.198123\n",
      "Train Epoch: 17 [49280/41964 (98%)]\tLoss: 0.248943\n",
      "Train Epoch: 17 [49920/41964 (100%)]\tLoss: 0.105344\n",
      "\n",
      "Test set: Avg. loss: 0.0496, Accuracy: 9846/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/41964 (0%)]\tLoss: 0.266142\n",
      "Train Epoch: 18 [640/41964 (1%)]\tLoss: 0.258850\n",
      "Train Epoch: 18 [1280/41964 (3%)]\tLoss: 0.105822\n",
      "Train Epoch: 18 [1920/41964 (4%)]\tLoss: 0.112377\n",
      "Train Epoch: 18 [2560/41964 (5%)]\tLoss: 0.184085\n",
      "Train Epoch: 18 [3200/41964 (6%)]\tLoss: 0.116004\n",
      "Train Epoch: 18 [3840/41964 (8%)]\tLoss: 0.095019\n",
      "Train Epoch: 18 [4480/41964 (9%)]\tLoss: 0.329315\n",
      "Train Epoch: 18 [5120/41964 (10%)]\tLoss: 0.074335\n",
      "Train Epoch: 18 [5760/41964 (12%)]\tLoss: 0.263762\n",
      "Train Epoch: 18 [6400/41964 (13%)]\tLoss: 0.180394\n",
      "Train Epoch: 18 [7040/41964 (14%)]\tLoss: 0.241067\n",
      "Train Epoch: 18 [7680/41964 (15%)]\tLoss: 0.286462\n",
      "Train Epoch: 18 [8320/41964 (17%)]\tLoss: 0.178501\n",
      "Train Epoch: 18 [8960/41964 (18%)]\tLoss: 0.319174\n",
      "Train Epoch: 18 [9600/41964 (19%)]\tLoss: 0.174457\n",
      "Train Epoch: 18 [10240/41964 (20%)]\tLoss: 0.200142\n",
      "Train Epoch: 18 [10880/41964 (22%)]\tLoss: 0.254783\n",
      "Train Epoch: 18 [11520/41964 (23%)]\tLoss: 0.136551\n",
      "Train Epoch: 18 [12160/41964 (24%)]\tLoss: 0.094266\n",
      "Train Epoch: 18 [12800/41964 (26%)]\tLoss: 0.164978\n",
      "Train Epoch: 18 [13440/41964 (27%)]\tLoss: 0.187303\n",
      "Train Epoch: 18 [14080/41964 (28%)]\tLoss: 0.130813\n",
      "Train Epoch: 18 [14720/41964 (29%)]\tLoss: 0.231985\n",
      "Train Epoch: 18 [15360/41964 (31%)]\tLoss: 0.201292\n",
      "Train Epoch: 18 [16000/41964 (32%)]\tLoss: 0.085897\n",
      "Train Epoch: 18 [16640/41964 (33%)]\tLoss: 0.140380\n",
      "Train Epoch: 18 [17280/41964 (35%)]\tLoss: 0.309220\n",
      "Train Epoch: 18 [17920/41964 (36%)]\tLoss: 0.202987\n",
      "Train Epoch: 18 [18560/41964 (37%)]\tLoss: 0.216691\n",
      "Train Epoch: 18 [19200/41964 (38%)]\tLoss: 0.358864\n",
      "Train Epoch: 18 [19840/41964 (40%)]\tLoss: 0.099889\n",
      "Train Epoch: 18 [20480/41964 (41%)]\tLoss: 0.066724\n",
      "Train Epoch: 18 [21120/41964 (42%)]\tLoss: 0.123567\n",
      "Train Epoch: 18 [21760/41964 (43%)]\tLoss: 0.149276\n",
      "Train Epoch: 18 [22400/41964 (45%)]\tLoss: 0.206639\n",
      "Train Epoch: 18 [23040/41964 (46%)]\tLoss: 0.109914\n",
      "Train Epoch: 18 [23680/41964 (47%)]\tLoss: 0.151393\n",
      "Train Epoch: 18 [24320/41964 (49%)]\tLoss: 0.136861\n",
      "Train Epoch: 18 [24960/41964 (50%)]\tLoss: 0.128256\n",
      "Train Epoch: 18 [25600/41964 (51%)]\tLoss: 0.092527\n",
      "Train Epoch: 18 [26240/41964 (52%)]\tLoss: 0.146870\n",
      "Train Epoch: 18 [26880/41964 (54%)]\tLoss: 0.099551\n",
      "Train Epoch: 18 [27520/41964 (55%)]\tLoss: 0.162126\n",
      "Train Epoch: 18 [28160/41964 (56%)]\tLoss: 0.079544\n",
      "Train Epoch: 18 [28800/41964 (58%)]\tLoss: 0.116146\n",
      "Train Epoch: 18 [29440/41964 (59%)]\tLoss: 0.083825\n",
      "Train Epoch: 18 [30080/41964 (60%)]\tLoss: 0.098038\n",
      "Train Epoch: 18 [30720/41964 (61%)]\tLoss: 0.159712\n",
      "Train Epoch: 18 [31360/41964 (63%)]\tLoss: 0.080699\n",
      "Train Epoch: 18 [32000/41964 (64%)]\tLoss: 0.124622\n",
      "Train Epoch: 18 [32640/41964 (65%)]\tLoss: 0.136335\n",
      "Train Epoch: 18 [33280/41964 (66%)]\tLoss: 0.228937\n",
      "Train Epoch: 18 [33920/41964 (68%)]\tLoss: 0.161228\n",
      "Train Epoch: 18 [34560/41964 (69%)]\tLoss: 0.322005\n",
      "Train Epoch: 18 [35200/41964 (70%)]\tLoss: 0.096205\n",
      "Train Epoch: 18 [35840/41964 (72%)]\tLoss: 0.424074\n",
      "Train Epoch: 18 [36480/41964 (73%)]\tLoss: 0.202321\n",
      "Train Epoch: 18 [37120/41964 (74%)]\tLoss: 0.142708\n",
      "Train Epoch: 18 [37760/41964 (75%)]\tLoss: 0.136257\n",
      "Train Epoch: 18 [38400/41964 (77%)]\tLoss: 0.069136\n",
      "Train Epoch: 18 [39040/41964 (78%)]\tLoss: 0.194016\n",
      "Train Epoch: 18 [39680/41964 (79%)]\tLoss: 0.293722\n",
      "Train Epoch: 18 [40320/41964 (81%)]\tLoss: 0.153531\n",
      "Train Epoch: 18 [40960/41964 (82%)]\tLoss: 0.339521\n",
      "Train Epoch: 18 [41600/41964 (83%)]\tLoss: 0.028794\n",
      "Train Epoch: 18 [42240/41964 (84%)]\tLoss: 0.087448\n",
      "Train Epoch: 18 [42880/41964 (86%)]\tLoss: 0.194842\n",
      "Train Epoch: 18 [43520/41964 (87%)]\tLoss: 0.109664\n",
      "Train Epoch: 18 [44160/41964 (88%)]\tLoss: 0.176019\n",
      "Train Epoch: 18 [44800/41964 (90%)]\tLoss: 0.292554\n",
      "Train Epoch: 18 [45440/41964 (91%)]\tLoss: 0.059412\n",
      "Train Epoch: 18 [46080/41964 (92%)]\tLoss: 0.211686\n",
      "Train Epoch: 18 [46720/41964 (93%)]\tLoss: 0.207774\n",
      "Train Epoch: 18 [47360/41964 (95%)]\tLoss: 0.242911\n",
      "Train Epoch: 18 [48000/41964 (96%)]\tLoss: 0.235081\n",
      "Train Epoch: 18 [48640/41964 (97%)]\tLoss: 0.101556\n",
      "Train Epoch: 18 [49280/41964 (98%)]\tLoss: 0.107965\n",
      "Train Epoch: 18 [49920/41964 (100%)]\tLoss: 0.111624\n",
      "\n",
      "Test set: Avg. loss: 0.0462, Accuracy: 9860/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/41964 (0%)]\tLoss: 0.333668\n",
      "Train Epoch: 19 [640/41964 (1%)]\tLoss: 0.091243\n",
      "Train Epoch: 19 [1280/41964 (3%)]\tLoss: 0.283229\n",
      "Train Epoch: 19 [1920/41964 (4%)]\tLoss: 0.069901\n",
      "Train Epoch: 19 [2560/41964 (5%)]\tLoss: 0.406067\n",
      "Train Epoch: 19 [3200/41964 (6%)]\tLoss: 0.089327\n",
      "Train Epoch: 19 [3840/41964 (8%)]\tLoss: 0.174329\n",
      "Train Epoch: 19 [4480/41964 (9%)]\tLoss: 0.175810\n",
      "Train Epoch: 19 [5120/41964 (10%)]\tLoss: 0.077094\n",
      "Train Epoch: 19 [5760/41964 (12%)]\tLoss: 0.086675\n",
      "Train Epoch: 19 [6400/41964 (13%)]\tLoss: 0.175839\n",
      "Train Epoch: 19 [7040/41964 (14%)]\tLoss: 0.157218\n",
      "Train Epoch: 19 [7680/41964 (15%)]\tLoss: 0.069011\n",
      "Train Epoch: 19 [8320/41964 (17%)]\tLoss: 0.199664\n",
      "Train Epoch: 19 [8960/41964 (18%)]\tLoss: 0.230065\n",
      "Train Epoch: 19 [9600/41964 (19%)]\tLoss: 0.083114\n",
      "Train Epoch: 19 [10240/41964 (20%)]\tLoss: 0.112985\n",
      "Train Epoch: 19 [10880/41964 (22%)]\tLoss: 0.093610\n",
      "Train Epoch: 19 [11520/41964 (23%)]\tLoss: 0.149451\n",
      "Train Epoch: 19 [12160/41964 (24%)]\tLoss: 0.323186\n",
      "Train Epoch: 19 [12800/41964 (26%)]\tLoss: 0.058088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [13440/41964 (27%)]\tLoss: 0.298196\n",
      "Train Epoch: 19 [14080/41964 (28%)]\tLoss: 0.168867\n",
      "Train Epoch: 19 [14720/41964 (29%)]\tLoss: 0.258914\n",
      "Train Epoch: 19 [15360/41964 (31%)]\tLoss: 0.058899\n",
      "Train Epoch: 19 [16000/41964 (32%)]\tLoss: 0.236839\n",
      "Train Epoch: 19 [16640/41964 (33%)]\tLoss: 0.076050\n",
      "Train Epoch: 19 [17280/41964 (35%)]\tLoss: 0.252655\n",
      "Train Epoch: 19 [17920/41964 (36%)]\tLoss: 0.204394\n",
      "Train Epoch: 19 [18560/41964 (37%)]\tLoss: 0.377486\n",
      "Train Epoch: 19 [19200/41964 (38%)]\tLoss: 0.164465\n",
      "Train Epoch: 19 [19840/41964 (40%)]\tLoss: 0.100498\n",
      "Train Epoch: 19 [20480/41964 (41%)]\tLoss: 0.025380\n",
      "Train Epoch: 19 [21120/41964 (42%)]\tLoss: 0.092182\n",
      "Train Epoch: 19 [21760/41964 (43%)]\tLoss: 0.267773\n",
      "Train Epoch: 19 [22400/41964 (45%)]\tLoss: 0.182200\n",
      "Train Epoch: 19 [23040/41964 (46%)]\tLoss: 0.207862\n",
      "Train Epoch: 19 [23680/41964 (47%)]\tLoss: 0.170028\n",
      "Train Epoch: 19 [24320/41964 (49%)]\tLoss: 0.053351\n",
      "Train Epoch: 19 [24960/41964 (50%)]\tLoss: 0.223083\n",
      "Train Epoch: 19 [25600/41964 (51%)]\tLoss: 0.174600\n",
      "Train Epoch: 19 [26240/41964 (52%)]\tLoss: 0.134179\n",
      "Train Epoch: 19 [26880/41964 (54%)]\tLoss: 0.064125\n",
      "Train Epoch: 19 [27520/41964 (55%)]\tLoss: 0.212274\n",
      "Train Epoch: 19 [28160/41964 (56%)]\tLoss: 0.087807\n",
      "Train Epoch: 19 [28800/41964 (58%)]\tLoss: 0.118821\n",
      "Train Epoch: 19 [29440/41964 (59%)]\tLoss: 0.171469\n",
      "Train Epoch: 19 [30080/41964 (60%)]\tLoss: 0.071714\n",
      "Train Epoch: 19 [30720/41964 (61%)]\tLoss: 0.148345\n",
      "Train Epoch: 19 [31360/41964 (63%)]\tLoss: 0.188081\n",
      "Train Epoch: 19 [32000/41964 (64%)]\tLoss: 0.125785\n",
      "Train Epoch: 19 [32640/41964 (65%)]\tLoss: 0.157085\n",
      "Train Epoch: 19 [33280/41964 (66%)]\tLoss: 0.127301\n",
      "Train Epoch: 19 [33920/41964 (68%)]\tLoss: 0.142227\n",
      "Train Epoch: 19 [34560/41964 (69%)]\tLoss: 0.310581\n",
      "Train Epoch: 19 [35200/41964 (70%)]\tLoss: 0.152223\n",
      "Train Epoch: 19 [35840/41964 (72%)]\tLoss: 0.239047\n",
      "Train Epoch: 19 [36480/41964 (73%)]\tLoss: 0.042598\n",
      "Train Epoch: 19 [37120/41964 (74%)]\tLoss: 0.160661\n",
      "Train Epoch: 19 [37760/41964 (75%)]\tLoss: 0.120070\n",
      "Train Epoch: 19 [38400/41964 (77%)]\tLoss: 0.349618\n",
      "Train Epoch: 19 [39040/41964 (78%)]\tLoss: 0.013418\n",
      "Train Epoch: 19 [39680/41964 (79%)]\tLoss: 0.222749\n",
      "Train Epoch: 19 [40320/41964 (81%)]\tLoss: 0.223513\n",
      "Train Epoch: 19 [40960/41964 (82%)]\tLoss: 0.204871\n",
      "Train Epoch: 19 [41600/41964 (83%)]\tLoss: 0.220814\n",
      "Train Epoch: 19 [42240/41964 (84%)]\tLoss: 0.158708\n",
      "Train Epoch: 19 [42880/41964 (86%)]\tLoss: 0.144253\n",
      "Train Epoch: 19 [43520/41964 (87%)]\tLoss: 0.302923\n",
      "Train Epoch: 19 [44160/41964 (88%)]\tLoss: 0.062199\n",
      "Train Epoch: 19 [44800/41964 (90%)]\tLoss: 0.333539\n",
      "Train Epoch: 19 [45440/41964 (91%)]\tLoss: 0.397373\n",
      "Train Epoch: 19 [46080/41964 (92%)]\tLoss: 0.207133\n",
      "Train Epoch: 19 [46720/41964 (93%)]\tLoss: 0.173177\n",
      "Train Epoch: 19 [47360/41964 (95%)]\tLoss: 0.374181\n",
      "Train Epoch: 19 [48000/41964 (96%)]\tLoss: 0.175234\n",
      "Train Epoch: 19 [48640/41964 (97%)]\tLoss: 0.050429\n",
      "Train Epoch: 19 [49280/41964 (98%)]\tLoss: 0.146247\n",
      "Train Epoch: 19 [49920/41964 (100%)]\tLoss: 0.328869\n",
      "\n",
      "Test set: Avg. loss: 0.0452, Accuracy: 9854/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/41964 (0%)]\tLoss: 0.267343\n",
      "Train Epoch: 20 [640/41964 (1%)]\tLoss: 0.264360\n",
      "Train Epoch: 20 [1280/41964 (3%)]\tLoss: 0.367267\n",
      "Train Epoch: 20 [1920/41964 (4%)]\tLoss: 0.083517\n",
      "Train Epoch: 20 [2560/41964 (5%)]\tLoss: 0.262976\n",
      "Train Epoch: 20 [3200/41964 (6%)]\tLoss: 0.168241\n",
      "Train Epoch: 20 [3840/41964 (8%)]\tLoss: 0.100669\n",
      "Train Epoch: 20 [4480/41964 (9%)]\tLoss: 0.240961\n",
      "Train Epoch: 20 [5120/41964 (10%)]\tLoss: 0.134854\n",
      "Train Epoch: 20 [5760/41964 (12%)]\tLoss: 0.103663\n",
      "Train Epoch: 20 [6400/41964 (13%)]\tLoss: 0.092066\n",
      "Train Epoch: 20 [7040/41964 (14%)]\tLoss: 0.108923\n",
      "Train Epoch: 20 [7680/41964 (15%)]\tLoss: 0.118389\n",
      "Train Epoch: 20 [8320/41964 (17%)]\tLoss: 0.197277\n",
      "Train Epoch: 20 [8960/41964 (18%)]\tLoss: 0.104938\n",
      "Train Epoch: 20 [9600/41964 (19%)]\tLoss: 0.063355\n",
      "Train Epoch: 20 [10240/41964 (20%)]\tLoss: 0.211143\n",
      "Train Epoch: 20 [10880/41964 (22%)]\tLoss: 0.208841\n",
      "Train Epoch: 20 [11520/41964 (23%)]\tLoss: 0.069461\n",
      "Train Epoch: 20 [12160/41964 (24%)]\tLoss: 0.145729\n",
      "Train Epoch: 20 [12800/41964 (26%)]\tLoss: 0.269716\n",
      "Train Epoch: 20 [13440/41964 (27%)]\tLoss: 0.139883\n",
      "Train Epoch: 20 [14080/41964 (28%)]\tLoss: 0.122581\n",
      "Train Epoch: 20 [14720/41964 (29%)]\tLoss: 0.322454\n",
      "Train Epoch: 20 [15360/41964 (31%)]\tLoss: 0.174069\n",
      "Train Epoch: 20 [16000/41964 (32%)]\tLoss: 0.168077\n",
      "Train Epoch: 20 [16640/41964 (33%)]\tLoss: 0.437275\n",
      "Train Epoch: 20 [17280/41964 (35%)]\tLoss: 0.151047\n",
      "Train Epoch: 20 [17920/41964 (36%)]\tLoss: 0.131750\n",
      "Train Epoch: 20 [18560/41964 (37%)]\tLoss: 0.159058\n",
      "Train Epoch: 20 [19200/41964 (38%)]\tLoss: 0.157160\n",
      "Train Epoch: 20 [19840/41964 (40%)]\tLoss: 0.150727\n",
      "Train Epoch: 20 [20480/41964 (41%)]\tLoss: 0.161448\n",
      "Train Epoch: 20 [21120/41964 (42%)]\tLoss: 0.124835\n",
      "Train Epoch: 20 [21760/41964 (43%)]\tLoss: 0.369671\n",
      "Train Epoch: 20 [22400/41964 (45%)]\tLoss: 0.093368\n",
      "Train Epoch: 20 [23040/41964 (46%)]\tLoss: 0.170780\n",
      "Train Epoch: 20 [23680/41964 (47%)]\tLoss: 0.202457\n",
      "Train Epoch: 20 [24320/41964 (49%)]\tLoss: 0.113168\n",
      "Train Epoch: 20 [24960/41964 (50%)]\tLoss: 0.197143\n",
      "Train Epoch: 20 [25600/41964 (51%)]\tLoss: 0.436543\n",
      "Train Epoch: 20 [26240/41964 (52%)]\tLoss: 0.119687\n",
      "Train Epoch: 20 [26880/41964 (54%)]\tLoss: 0.151584\n",
      "Train Epoch: 20 [27520/41964 (55%)]\tLoss: 0.119808\n",
      "Train Epoch: 20 [28160/41964 (56%)]\tLoss: 0.255340\n",
      "Train Epoch: 20 [28800/41964 (58%)]\tLoss: 0.103255\n",
      "Train Epoch: 20 [29440/41964 (59%)]\tLoss: 0.109607\n",
      "Train Epoch: 20 [30080/41964 (60%)]\tLoss: 0.187727\n",
      "Train Epoch: 20 [30720/41964 (61%)]\tLoss: 0.056258\n",
      "Train Epoch: 20 [31360/41964 (63%)]\tLoss: 0.123796\n",
      "Train Epoch: 20 [32000/41964 (64%)]\tLoss: 0.253834\n",
      "Train Epoch: 20 [32640/41964 (65%)]\tLoss: 0.047687\n",
      "Train Epoch: 20 [33280/41964 (66%)]\tLoss: 0.177037\n",
      "Train Epoch: 20 [33920/41964 (68%)]\tLoss: 0.084344\n",
      "Train Epoch: 20 [34560/41964 (69%)]\tLoss: 0.293176\n",
      "Train Epoch: 20 [35200/41964 (70%)]\tLoss: 0.068072\n",
      "Train Epoch: 20 [35840/41964 (72%)]\tLoss: 0.266624\n",
      "Train Epoch: 20 [36480/41964 (73%)]\tLoss: 0.171795\n",
      "Train Epoch: 20 [37120/41964 (74%)]\tLoss: 0.180645\n",
      "Train Epoch: 20 [37760/41964 (75%)]\tLoss: 0.305869\n",
      "Train Epoch: 20 [38400/41964 (77%)]\tLoss: 0.300739\n",
      "Train Epoch: 20 [39040/41964 (78%)]\tLoss: 0.178577\n",
      "Train Epoch: 20 [39680/41964 (79%)]\tLoss: 0.062929\n",
      "Train Epoch: 20 [40320/41964 (81%)]\tLoss: 0.406521\n",
      "Train Epoch: 20 [40960/41964 (82%)]\tLoss: 0.111538\n",
      "Train Epoch: 20 [41600/41964 (83%)]\tLoss: 0.238743\n",
      "Train Epoch: 20 [42240/41964 (84%)]\tLoss: 0.159628\n",
      "Train Epoch: 20 [42880/41964 (86%)]\tLoss: 0.127300\n",
      "Train Epoch: 20 [43520/41964 (87%)]\tLoss: 0.255001\n",
      "Train Epoch: 20 [44160/41964 (88%)]\tLoss: 0.130007\n",
      "Train Epoch: 20 [44800/41964 (90%)]\tLoss: 0.144572\n",
      "Train Epoch: 20 [45440/41964 (91%)]\tLoss: 0.128693\n",
      "Train Epoch: 20 [46080/41964 (92%)]\tLoss: 0.284601\n",
      "Train Epoch: 20 [46720/41964 (93%)]\tLoss: 0.168249\n",
      "Train Epoch: 20 [47360/41964 (95%)]\tLoss: 0.085138\n",
      "Train Epoch: 20 [48000/41964 (96%)]\tLoss: 0.207328\n",
      "Train Epoch: 20 [48640/41964 (97%)]\tLoss: 0.164796\n",
      "Train Epoch: 20 [49280/41964 (98%)]\tLoss: 0.150644\n",
      "Train Epoch: 20 [49920/41964 (100%)]\tLoss: 0.136111\n",
      "\n",
      "Test set: Avg. loss: 0.0461, Accuracy: 9855/10000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/41964 (0%)]\tLoss: 0.101997\n",
      "Train Epoch: 21 [640/41964 (1%)]\tLoss: 0.256325\n",
      "Train Epoch: 21 [1280/41964 (3%)]\tLoss: 0.120266\n",
      "Train Epoch: 21 [1920/41964 (4%)]\tLoss: 0.333551\n",
      "Train Epoch: 21 [2560/41964 (5%)]\tLoss: 0.141815\n",
      "Train Epoch: 21 [3200/41964 (6%)]\tLoss: 0.193888\n",
      "Train Epoch: 21 [3840/41964 (8%)]\tLoss: 0.121546\n",
      "Train Epoch: 21 [4480/41964 (9%)]\tLoss: 0.186403\n",
      "Train Epoch: 21 [5120/41964 (10%)]\tLoss: 0.162565\n",
      "Train Epoch: 21 [5760/41964 (12%)]\tLoss: 0.297264\n",
      "Train Epoch: 21 [6400/41964 (13%)]\tLoss: 0.262184\n",
      "Train Epoch: 21 [7040/41964 (14%)]\tLoss: 0.152041\n",
      "Train Epoch: 21 [7680/41964 (15%)]\tLoss: 0.103301\n",
      "Train Epoch: 21 [8320/41964 (17%)]\tLoss: 0.191271\n",
      "Train Epoch: 21 [8960/41964 (18%)]\tLoss: 0.169423\n",
      "Train Epoch: 21 [9600/41964 (19%)]\tLoss: 0.132858\n",
      "Train Epoch: 21 [10240/41964 (20%)]\tLoss: 0.142590\n",
      "Train Epoch: 21 [10880/41964 (22%)]\tLoss: 0.411007\n",
      "Train Epoch: 21 [11520/41964 (23%)]\tLoss: 0.294168\n",
      "Train Epoch: 21 [12160/41964 (24%)]\tLoss: 0.085095\n",
      "Train Epoch: 21 [12800/41964 (26%)]\tLoss: 0.418073\n",
      "Train Epoch: 21 [13440/41964 (27%)]\tLoss: 0.103388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [14080/41964 (28%)]\tLoss: 0.149925\n",
      "Train Epoch: 21 [14720/41964 (29%)]\tLoss: 0.165342\n",
      "Train Epoch: 21 [15360/41964 (31%)]\tLoss: 0.173560\n",
      "Train Epoch: 21 [16000/41964 (32%)]\tLoss: 0.385318\n",
      "Train Epoch: 21 [16640/41964 (33%)]\tLoss: 0.244750\n",
      "Train Epoch: 21 [17280/41964 (35%)]\tLoss: 0.153508\n",
      "Train Epoch: 21 [17920/41964 (36%)]\tLoss: 0.410959\n",
      "Train Epoch: 21 [18560/41964 (37%)]\tLoss: 0.092847\n",
      "Train Epoch: 21 [19200/41964 (38%)]\tLoss: 0.198839\n",
      "Train Epoch: 21 [19840/41964 (40%)]\tLoss: 0.071854\n",
      "Train Epoch: 21 [20480/41964 (41%)]\tLoss: 0.252679\n",
      "Train Epoch: 21 [21120/41964 (42%)]\tLoss: 0.163222\n",
      "Train Epoch: 21 [21760/41964 (43%)]\tLoss: 0.108244\n",
      "Train Epoch: 21 [22400/41964 (45%)]\tLoss: 0.421481\n",
      "Train Epoch: 21 [23040/41964 (46%)]\tLoss: 0.117179\n",
      "Train Epoch: 21 [23680/41964 (47%)]\tLoss: 0.076674\n",
      "Train Epoch: 21 [24320/41964 (49%)]\tLoss: 0.159463\n",
      "Train Epoch: 21 [24960/41964 (50%)]\tLoss: 0.105575\n",
      "Train Epoch: 21 [25600/41964 (51%)]\tLoss: 0.090076\n",
      "Train Epoch: 21 [26240/41964 (52%)]\tLoss: 0.170883\n",
      "Train Epoch: 21 [26880/41964 (54%)]\tLoss: 0.044959\n",
      "Train Epoch: 21 [27520/41964 (55%)]\tLoss: 0.228110\n",
      "Train Epoch: 21 [28160/41964 (56%)]\tLoss: 0.170107\n",
      "Train Epoch: 21 [28800/41964 (58%)]\tLoss: 0.207068\n",
      "Train Epoch: 21 [29440/41964 (59%)]\tLoss: 0.084283\n",
      "Train Epoch: 21 [30080/41964 (60%)]\tLoss: 0.261126\n",
      "Train Epoch: 21 [30720/41964 (61%)]\tLoss: 0.165766\n",
      "Train Epoch: 21 [31360/41964 (63%)]\tLoss: 0.097737\n",
      "Train Epoch: 21 [32000/41964 (64%)]\tLoss: 0.195964\n",
      "Train Epoch: 21 [32640/41964 (65%)]\tLoss: 0.126953\n",
      "Train Epoch: 21 [33280/41964 (66%)]\tLoss: 0.159730\n",
      "Train Epoch: 21 [33920/41964 (68%)]\tLoss: 0.114711\n",
      "Train Epoch: 21 [34560/41964 (69%)]\tLoss: 0.317794\n",
      "Train Epoch: 21 [35200/41964 (70%)]\tLoss: 0.121307\n",
      "Train Epoch: 21 [35840/41964 (72%)]\tLoss: 0.264992\n",
      "Train Epoch: 21 [36480/41964 (73%)]\tLoss: 0.267775\n",
      "Train Epoch: 21 [37120/41964 (74%)]\tLoss: 0.266097\n",
      "Train Epoch: 21 [37760/41964 (75%)]\tLoss: 0.174907\n",
      "Train Epoch: 21 [38400/41964 (77%)]\tLoss: 0.171831\n",
      "Train Epoch: 21 [39040/41964 (78%)]\tLoss: 0.107394\n",
      "Train Epoch: 21 [39680/41964 (79%)]\tLoss: 0.166720\n",
      "Train Epoch: 21 [40320/41964 (81%)]\tLoss: 0.192495\n",
      "Train Epoch: 21 [40960/41964 (82%)]\tLoss: 0.125048\n",
      "Train Epoch: 21 [41600/41964 (83%)]\tLoss: 0.318673\n",
      "Train Epoch: 21 [42240/41964 (84%)]\tLoss: 0.194515\n",
      "Train Epoch: 21 [42880/41964 (86%)]\tLoss: 0.158013\n",
      "Train Epoch: 21 [43520/41964 (87%)]\tLoss: 0.315199\n",
      "Train Epoch: 21 [44160/41964 (88%)]\tLoss: 0.306951\n",
      "Train Epoch: 21 [44800/41964 (90%)]\tLoss: 0.098808\n",
      "Train Epoch: 21 [45440/41964 (91%)]\tLoss: 0.381094\n",
      "Train Epoch: 21 [46080/41964 (92%)]\tLoss: 0.188026\n",
      "Train Epoch: 21 [46720/41964 (93%)]\tLoss: 0.371659\n",
      "Train Epoch: 21 [47360/41964 (95%)]\tLoss: 0.277162\n",
      "Train Epoch: 21 [48000/41964 (96%)]\tLoss: 0.241434\n",
      "Train Epoch: 21 [48640/41964 (97%)]\tLoss: 0.247803\n",
      "Train Epoch: 21 [49280/41964 (98%)]\tLoss: 0.304669\n",
      "Train Epoch: 21 [49920/41964 (100%)]\tLoss: 0.215141\n",
      "\n",
      "Test set: Avg. loss: 0.0481, Accuracy: 9853/10000 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/41964 (0%)]\tLoss: 0.095353\n",
      "Train Epoch: 22 [640/41964 (1%)]\tLoss: 0.226651\n",
      "Train Epoch: 22 [1280/41964 (3%)]\tLoss: 0.205361\n",
      "Train Epoch: 22 [1920/41964 (4%)]\tLoss: 0.202850\n",
      "Train Epoch: 22 [2560/41964 (5%)]\tLoss: 0.270246\n",
      "Train Epoch: 22 [3200/41964 (6%)]\tLoss: 0.179920\n",
      "Train Epoch: 22 [3840/41964 (8%)]\tLoss: 0.145887\n",
      "Train Epoch: 22 [4480/41964 (9%)]\tLoss: 0.232117\n",
      "Train Epoch: 22 [5120/41964 (10%)]\tLoss: 0.149318\n",
      "Train Epoch: 22 [5760/41964 (12%)]\tLoss: 0.240494\n",
      "Train Epoch: 22 [6400/41964 (13%)]\tLoss: 0.085858\n",
      "Train Epoch: 22 [7040/41964 (14%)]\tLoss: 0.117973\n",
      "Train Epoch: 22 [7680/41964 (15%)]\tLoss: 0.151659\n",
      "Train Epoch: 22 [8320/41964 (17%)]\tLoss: 0.074558\n",
      "Train Epoch: 22 [8960/41964 (18%)]\tLoss: 0.268999\n",
      "Train Epoch: 22 [9600/41964 (19%)]\tLoss: 0.282433\n",
      "Train Epoch: 22 [10240/41964 (20%)]\tLoss: 0.164942\n",
      "Train Epoch: 22 [10880/41964 (22%)]\tLoss: 0.181400\n",
      "Train Epoch: 22 [11520/41964 (23%)]\tLoss: 0.114059\n",
      "Train Epoch: 22 [12160/41964 (24%)]\tLoss: 0.240904\n",
      "Train Epoch: 22 [12800/41964 (26%)]\tLoss: 0.166750\n",
      "Train Epoch: 22 [13440/41964 (27%)]\tLoss: 0.139436\n",
      "Train Epoch: 22 [14080/41964 (28%)]\tLoss: 0.231736\n",
      "Train Epoch: 22 [14720/41964 (29%)]\tLoss: 0.073710\n",
      "Train Epoch: 22 [15360/41964 (31%)]\tLoss: 0.492835\n",
      "Train Epoch: 22 [16000/41964 (32%)]\tLoss: 0.131023\n",
      "Train Epoch: 22 [16640/41964 (33%)]\tLoss: 0.168082\n",
      "Train Epoch: 22 [17280/41964 (35%)]\tLoss: 0.229639\n",
      "Train Epoch: 22 [17920/41964 (36%)]\tLoss: 0.251427\n",
      "Train Epoch: 22 [18560/41964 (37%)]\tLoss: 0.215797\n",
      "Train Epoch: 22 [19200/41964 (38%)]\tLoss: 0.230353\n",
      "Train Epoch: 22 [19840/41964 (40%)]\tLoss: 0.089180\n",
      "Train Epoch: 22 [20480/41964 (41%)]\tLoss: 0.138661\n",
      "Train Epoch: 22 [21120/41964 (42%)]\tLoss: 0.247363\n",
      "Train Epoch: 22 [21760/41964 (43%)]\tLoss: 0.128849\n",
      "Train Epoch: 22 [22400/41964 (45%)]\tLoss: 0.135513\n",
      "Train Epoch: 22 [23040/41964 (46%)]\tLoss: 0.116367\n",
      "Train Epoch: 22 [23680/41964 (47%)]\tLoss: 0.193263\n",
      "Train Epoch: 22 [24320/41964 (49%)]\tLoss: 0.218508\n",
      "Train Epoch: 22 [24960/41964 (50%)]\tLoss: 0.154264\n",
      "Train Epoch: 22 [25600/41964 (51%)]\tLoss: 0.146172\n",
      "Train Epoch: 22 [26240/41964 (52%)]\tLoss: 0.157141\n",
      "Train Epoch: 22 [26880/41964 (54%)]\tLoss: 0.240174\n",
      "Train Epoch: 22 [27520/41964 (55%)]\tLoss: 0.160511\n",
      "Train Epoch: 22 [28160/41964 (56%)]\tLoss: 0.092826\n",
      "Train Epoch: 22 [28800/41964 (58%)]\tLoss: 0.175197\n",
      "Train Epoch: 22 [29440/41964 (59%)]\tLoss: 0.108677\n",
      "Train Epoch: 22 [30080/41964 (60%)]\tLoss: 0.175990\n",
      "Train Epoch: 22 [30720/41964 (61%)]\tLoss: 0.221452\n",
      "Train Epoch: 22 [31360/41964 (63%)]\tLoss: 0.183430\n",
      "Train Epoch: 22 [32000/41964 (64%)]\tLoss: 0.370839\n",
      "Train Epoch: 22 [32640/41964 (65%)]\tLoss: 0.211730\n",
      "Train Epoch: 22 [33280/41964 (66%)]\tLoss: 0.141510\n",
      "Train Epoch: 22 [33920/41964 (68%)]\tLoss: 0.303968\n",
      "Train Epoch: 22 [34560/41964 (69%)]\tLoss: 0.152183\n",
      "Train Epoch: 22 [35200/41964 (70%)]\tLoss: 0.127674\n",
      "Train Epoch: 22 [35840/41964 (72%)]\tLoss: 0.151232\n",
      "Train Epoch: 22 [36480/41964 (73%)]\tLoss: 0.180375\n",
      "Train Epoch: 22 [37120/41964 (74%)]\tLoss: 0.121316\n",
      "Train Epoch: 22 [37760/41964 (75%)]\tLoss: 0.095093\n",
      "Train Epoch: 22 [38400/41964 (77%)]\tLoss: 0.279966\n",
      "Train Epoch: 22 [39040/41964 (78%)]\tLoss: 0.169385\n",
      "Train Epoch: 22 [39680/41964 (79%)]\tLoss: 0.199091\n",
      "Train Epoch: 22 [40320/41964 (81%)]\tLoss: 0.263714\n",
      "Train Epoch: 22 [40960/41964 (82%)]\tLoss: 0.154743\n",
      "Train Epoch: 22 [41600/41964 (83%)]\tLoss: 0.099450\n",
      "Train Epoch: 22 [42240/41964 (84%)]\tLoss: 0.435830\n",
      "Train Epoch: 22 [42880/41964 (86%)]\tLoss: 0.179834\n",
      "Train Epoch: 22 [43520/41964 (87%)]\tLoss: 0.059304\n",
      "Train Epoch: 22 [44160/41964 (88%)]\tLoss: 0.191654\n",
      "Train Epoch: 22 [44800/41964 (90%)]\tLoss: 0.066560\n",
      "Train Epoch: 22 [45440/41964 (91%)]\tLoss: 0.165343\n",
      "Train Epoch: 22 [46080/41964 (92%)]\tLoss: 0.173967\n",
      "Train Epoch: 22 [46720/41964 (93%)]\tLoss: 0.083890\n",
      "Train Epoch: 22 [47360/41964 (95%)]\tLoss: 0.143733\n",
      "Train Epoch: 22 [48000/41964 (96%)]\tLoss: 0.155620\n",
      "Train Epoch: 22 [48640/41964 (97%)]\tLoss: 0.066571\n",
      "Train Epoch: 22 [49280/41964 (98%)]\tLoss: 0.085449\n",
      "Train Epoch: 22 [49920/41964 (100%)]\tLoss: 0.230614\n",
      "\n",
      "Test set: Avg. loss: 0.0432, Accuracy: 9860/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/41964 (0%)]\tLoss: 0.112651\n",
      "Train Epoch: 23 [640/41964 (1%)]\tLoss: 0.123648\n",
      "Train Epoch: 23 [1280/41964 (3%)]\tLoss: 0.153240\n",
      "Train Epoch: 23 [1920/41964 (4%)]\tLoss: 0.163004\n",
      "Train Epoch: 23 [2560/41964 (5%)]\tLoss: 0.184622\n",
      "Train Epoch: 23 [3200/41964 (6%)]\tLoss: 0.181825\n",
      "Train Epoch: 23 [3840/41964 (8%)]\tLoss: 0.055370\n",
      "Train Epoch: 23 [4480/41964 (9%)]\tLoss: 0.102233\n",
      "Train Epoch: 23 [5120/41964 (10%)]\tLoss: 0.059342\n",
      "Train Epoch: 23 [5760/41964 (12%)]\tLoss: 0.181916\n",
      "Train Epoch: 23 [6400/41964 (13%)]\tLoss: 0.248059\n",
      "Train Epoch: 23 [7040/41964 (14%)]\tLoss: 0.137733\n",
      "Train Epoch: 23 [7680/41964 (15%)]\tLoss: 0.076937\n",
      "Train Epoch: 23 [8320/41964 (17%)]\tLoss: 0.055714\n",
      "Train Epoch: 23 [8960/41964 (18%)]\tLoss: 0.109913\n",
      "Train Epoch: 23 [9600/41964 (19%)]\tLoss: 0.051844\n",
      "Train Epoch: 23 [10240/41964 (20%)]\tLoss: 0.206700\n",
      "Train Epoch: 23 [10880/41964 (22%)]\tLoss: 0.314881\n",
      "Train Epoch: 23 [11520/41964 (23%)]\tLoss: 0.128031\n",
      "Train Epoch: 23 [12160/41964 (24%)]\tLoss: 0.207712\n",
      "Train Epoch: 23 [12800/41964 (26%)]\tLoss: 0.249648\n",
      "Train Epoch: 23 [13440/41964 (27%)]\tLoss: 0.050821\n",
      "Train Epoch: 23 [14080/41964 (28%)]\tLoss: 0.244683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [14720/41964 (29%)]\tLoss: 0.232219\n",
      "Train Epoch: 23 [15360/41964 (31%)]\tLoss: 0.081944\n",
      "Train Epoch: 23 [16000/41964 (32%)]\tLoss: 0.079600\n",
      "Train Epoch: 23 [16640/41964 (33%)]\tLoss: 0.089650\n",
      "Train Epoch: 23 [17280/41964 (35%)]\tLoss: 0.208742\n",
      "Train Epoch: 23 [17920/41964 (36%)]\tLoss: 0.114454\n",
      "Train Epoch: 23 [18560/41964 (37%)]\tLoss: 0.075856\n",
      "Train Epoch: 23 [19200/41964 (38%)]\tLoss: 0.124880\n",
      "Train Epoch: 23 [19840/41964 (40%)]\tLoss: 0.138530\n",
      "Train Epoch: 23 [20480/41964 (41%)]\tLoss: 0.145242\n",
      "Train Epoch: 23 [21120/41964 (42%)]\tLoss: 0.114759\n",
      "Train Epoch: 23 [21760/41964 (43%)]\tLoss: 0.102587\n",
      "Train Epoch: 23 [22400/41964 (45%)]\tLoss: 0.156277\n",
      "Train Epoch: 23 [23040/41964 (46%)]\tLoss: 0.079493\n",
      "Train Epoch: 23 [23680/41964 (47%)]\tLoss: 0.158650\n",
      "Train Epoch: 23 [24320/41964 (49%)]\tLoss: 0.182598\n",
      "Train Epoch: 23 [24960/41964 (50%)]\tLoss: 0.245213\n",
      "Train Epoch: 23 [25600/41964 (51%)]\tLoss: 0.179109\n",
      "Train Epoch: 23 [26240/41964 (52%)]\tLoss: 0.168805\n",
      "Train Epoch: 23 [26880/41964 (54%)]\tLoss: 0.112172\n",
      "Train Epoch: 23 [27520/41964 (55%)]\tLoss: 0.140805\n",
      "Train Epoch: 23 [28160/41964 (56%)]\tLoss: 0.073721\n",
      "Train Epoch: 23 [28800/41964 (58%)]\tLoss: 0.203550\n",
      "Train Epoch: 23 [29440/41964 (59%)]\tLoss: 0.200410\n",
      "Train Epoch: 23 [30080/41964 (60%)]\tLoss: 0.220300\n",
      "Train Epoch: 23 [30720/41964 (61%)]\tLoss: 0.085781\n",
      "Train Epoch: 23 [31360/41964 (63%)]\tLoss: 0.241679\n",
      "Train Epoch: 23 [32000/41964 (64%)]\tLoss: 0.185107\n",
      "Train Epoch: 23 [32640/41964 (65%)]\tLoss: 0.085269\n",
      "Train Epoch: 23 [33280/41964 (66%)]\tLoss: 0.130344\n",
      "Train Epoch: 23 [33920/41964 (68%)]\tLoss: 0.295295\n",
      "Train Epoch: 23 [34560/41964 (69%)]\tLoss: 0.114539\n",
      "Train Epoch: 23 [35200/41964 (70%)]\tLoss: 0.573781\n",
      "Train Epoch: 23 [35840/41964 (72%)]\tLoss: 0.120459\n",
      "Train Epoch: 23 [36480/41964 (73%)]\tLoss: 0.135429\n",
      "Train Epoch: 23 [37120/41964 (74%)]\tLoss: 0.137885\n",
      "Train Epoch: 23 [37760/41964 (75%)]\tLoss: 0.219465\n",
      "Train Epoch: 23 [38400/41964 (77%)]\tLoss: 0.060150\n",
      "Train Epoch: 23 [39040/41964 (78%)]\tLoss: 0.078807\n",
      "Train Epoch: 23 [39680/41964 (79%)]\tLoss: 0.267314\n",
      "Train Epoch: 23 [40320/41964 (81%)]\tLoss: 0.130442\n",
      "Train Epoch: 23 [40960/41964 (82%)]\tLoss: 0.092772\n",
      "Train Epoch: 23 [41600/41964 (83%)]\tLoss: 0.140733\n",
      "Train Epoch: 23 [42240/41964 (84%)]\tLoss: 0.085911\n",
      "Train Epoch: 23 [42880/41964 (86%)]\tLoss: 0.176372\n",
      "Train Epoch: 23 [43520/41964 (87%)]\tLoss: 0.091459\n",
      "Train Epoch: 23 [44160/41964 (88%)]\tLoss: 0.137976\n",
      "Train Epoch: 23 [44800/41964 (90%)]\tLoss: 0.143021\n",
      "Train Epoch: 23 [45440/41964 (91%)]\tLoss: 0.269515\n",
      "Train Epoch: 23 [46080/41964 (92%)]\tLoss: 0.145960\n",
      "Train Epoch: 23 [46720/41964 (93%)]\tLoss: 0.210498\n",
      "Train Epoch: 23 [47360/41964 (95%)]\tLoss: 0.143775\n",
      "Train Epoch: 23 [48000/41964 (96%)]\tLoss: 0.105987\n",
      "Train Epoch: 23 [48640/41964 (97%)]\tLoss: 0.230851\n",
      "Train Epoch: 23 [49280/41964 (98%)]\tLoss: 0.249500\n",
      "Train Epoch: 23 [49920/41964 (100%)]\tLoss: 0.428283\n",
      "\n",
      "Test set: Avg. loss: 0.0418, Accuracy: 9862/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/41964 (0%)]\tLoss: 0.135044\n",
      "Train Epoch: 24 [640/41964 (1%)]\tLoss: 0.084302\n",
      "Train Epoch: 24 [1280/41964 (3%)]\tLoss: 0.113702\n",
      "Train Epoch: 24 [1920/41964 (4%)]\tLoss: 0.040249\n",
      "Train Epoch: 24 [2560/41964 (5%)]\tLoss: 0.230702\n",
      "Train Epoch: 24 [3200/41964 (6%)]\tLoss: 0.156251\n",
      "Train Epoch: 24 [3840/41964 (8%)]\tLoss: 0.170856\n",
      "Train Epoch: 24 [4480/41964 (9%)]\tLoss: 0.152545\n",
      "Train Epoch: 24 [5120/41964 (10%)]\tLoss: 0.305299\n",
      "Train Epoch: 24 [5760/41964 (12%)]\tLoss: 0.233347\n",
      "Train Epoch: 24 [6400/41964 (13%)]\tLoss: 0.110653\n",
      "Train Epoch: 24 [7040/41964 (14%)]\tLoss: 0.122391\n",
      "Train Epoch: 24 [7680/41964 (15%)]\tLoss: 0.096816\n",
      "Train Epoch: 24 [8320/41964 (17%)]\tLoss: 0.089804\n",
      "Train Epoch: 24 [8960/41964 (18%)]\tLoss: 0.184457\n",
      "Train Epoch: 24 [9600/41964 (19%)]\tLoss: 0.090328\n",
      "Train Epoch: 24 [10240/41964 (20%)]\tLoss: 0.076873\n",
      "Train Epoch: 24 [10880/41964 (22%)]\tLoss: 0.244459\n",
      "Train Epoch: 24 [11520/41964 (23%)]\tLoss: 0.200016\n",
      "Train Epoch: 24 [12160/41964 (24%)]\tLoss: 0.105937\n",
      "Train Epoch: 24 [12800/41964 (26%)]\tLoss: 0.218706\n",
      "Train Epoch: 24 [13440/41964 (27%)]\tLoss: 0.153904\n",
      "Train Epoch: 24 [14080/41964 (28%)]\tLoss: 0.089346\n",
      "Train Epoch: 24 [14720/41964 (29%)]\tLoss: 0.220224\n",
      "Train Epoch: 24 [15360/41964 (31%)]\tLoss: 0.169960\n",
      "Train Epoch: 24 [16000/41964 (32%)]\tLoss: 0.285871\n",
      "Train Epoch: 24 [16640/41964 (33%)]\tLoss: 0.179876\n",
      "Train Epoch: 24 [17280/41964 (35%)]\tLoss: 0.103532\n",
      "Train Epoch: 24 [17920/41964 (36%)]\tLoss: 0.437957\n",
      "Train Epoch: 24 [18560/41964 (37%)]\tLoss: 0.192234\n",
      "Train Epoch: 24 [19200/41964 (38%)]\tLoss: 0.066435\n",
      "Train Epoch: 24 [19840/41964 (40%)]\tLoss: 0.033506\n",
      "Train Epoch: 24 [20480/41964 (41%)]\tLoss: 0.167126\n",
      "Train Epoch: 24 [21120/41964 (42%)]\tLoss: 0.215649\n",
      "Train Epoch: 24 [21760/41964 (43%)]\tLoss: 0.288288\n",
      "Train Epoch: 24 [22400/41964 (45%)]\tLoss: 0.051578\n",
      "Train Epoch: 24 [23040/41964 (46%)]\tLoss: 0.058029\n",
      "Train Epoch: 24 [23680/41964 (47%)]\tLoss: 0.162705\n",
      "Train Epoch: 24 [24320/41964 (49%)]\tLoss: 0.108854\n",
      "Train Epoch: 24 [24960/41964 (50%)]\tLoss: 0.133014\n",
      "Train Epoch: 24 [25600/41964 (51%)]\tLoss: 0.162740\n",
      "Train Epoch: 24 [26240/41964 (52%)]\tLoss: 0.221029\n",
      "Train Epoch: 24 [26880/41964 (54%)]\tLoss: 0.056685\n",
      "Train Epoch: 24 [27520/41964 (55%)]\tLoss: 0.157904\n",
      "Train Epoch: 24 [28160/41964 (56%)]\tLoss: 0.125007\n",
      "Train Epoch: 24 [28800/41964 (58%)]\tLoss: 0.177987\n",
      "Train Epoch: 24 [29440/41964 (59%)]\tLoss: 0.178010\n",
      "Train Epoch: 24 [30080/41964 (60%)]\tLoss: 0.151753\n",
      "Train Epoch: 24 [30720/41964 (61%)]\tLoss: 0.190021\n",
      "Train Epoch: 24 [31360/41964 (63%)]\tLoss: 0.169733\n",
      "Train Epoch: 24 [32000/41964 (64%)]\tLoss: 0.077213\n",
      "Train Epoch: 24 [32640/41964 (65%)]\tLoss: 0.149466\n",
      "Train Epoch: 24 [33280/41964 (66%)]\tLoss: 0.126931\n",
      "Train Epoch: 24 [33920/41964 (68%)]\tLoss: 0.070219\n",
      "Train Epoch: 24 [34560/41964 (69%)]\tLoss: 0.261401\n",
      "Train Epoch: 24 [35200/41964 (70%)]\tLoss: 0.043381\n",
      "Train Epoch: 24 [35840/41964 (72%)]\tLoss: 0.239742\n",
      "Train Epoch: 24 [36480/41964 (73%)]\tLoss: 0.089025\n",
      "Train Epoch: 24 [37120/41964 (74%)]\tLoss: 0.186546\n",
      "Train Epoch: 24 [37760/41964 (75%)]\tLoss: 0.143398\n",
      "Train Epoch: 24 [38400/41964 (77%)]\tLoss: 0.055760\n",
      "Train Epoch: 24 [39040/41964 (78%)]\tLoss: 0.210139\n",
      "Train Epoch: 24 [39680/41964 (79%)]\tLoss: 0.293800\n",
      "Train Epoch: 24 [40320/41964 (81%)]\tLoss: 0.191200\n",
      "Train Epoch: 24 [40960/41964 (82%)]\tLoss: 0.039979\n",
      "Train Epoch: 24 [41600/41964 (83%)]\tLoss: 0.204948\n",
      "Train Epoch: 24 [42240/41964 (84%)]\tLoss: 0.240579\n",
      "Train Epoch: 24 [42880/41964 (86%)]\tLoss: 0.235522\n",
      "Train Epoch: 24 [43520/41964 (87%)]\tLoss: 0.122309\n",
      "Train Epoch: 24 [44160/41964 (88%)]\tLoss: 0.464001\n",
      "Train Epoch: 24 [44800/41964 (90%)]\tLoss: 0.129993\n",
      "Train Epoch: 24 [45440/41964 (91%)]\tLoss: 0.275582\n",
      "Train Epoch: 24 [46080/41964 (92%)]\tLoss: 0.203572\n",
      "Train Epoch: 24 [46720/41964 (93%)]\tLoss: 0.348937\n",
      "Train Epoch: 24 [47360/41964 (95%)]\tLoss: 0.205625\n",
      "Train Epoch: 24 [48000/41964 (96%)]\tLoss: 0.139275\n",
      "Train Epoch: 24 [48640/41964 (97%)]\tLoss: 0.067888\n",
      "Train Epoch: 24 [49280/41964 (98%)]\tLoss: 0.318271\n",
      "Train Epoch: 24 [49920/41964 (100%)]\tLoss: 0.281367\n",
      "\n",
      "Test set: Avg. loss: 0.0406, Accuracy: 9874/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/41964 (0%)]\tLoss: 0.116554\n",
      "Train Epoch: 25 [640/41964 (1%)]\tLoss: 0.275310\n",
      "Train Epoch: 25 [1280/41964 (3%)]\tLoss: 0.215039\n",
      "Train Epoch: 25 [1920/41964 (4%)]\tLoss: 0.231263\n",
      "Train Epoch: 25 [2560/41964 (5%)]\tLoss: 0.143475\n",
      "Train Epoch: 25 [3200/41964 (6%)]\tLoss: 0.163061\n",
      "Train Epoch: 25 [3840/41964 (8%)]\tLoss: 0.172313\n",
      "Train Epoch: 25 [4480/41964 (9%)]\tLoss: 0.171890\n",
      "Train Epoch: 25 [5120/41964 (10%)]\tLoss: 0.147719\n",
      "Train Epoch: 25 [5760/41964 (12%)]\tLoss: 0.082351\n",
      "Train Epoch: 25 [6400/41964 (13%)]\tLoss: 0.247561\n",
      "Train Epoch: 25 [7040/41964 (14%)]\tLoss: 0.082011\n",
      "Train Epoch: 25 [7680/41964 (15%)]\tLoss: 0.108466\n",
      "Train Epoch: 25 [8320/41964 (17%)]\tLoss: 0.078082\n",
      "Train Epoch: 25 [8960/41964 (18%)]\tLoss: 0.126188\n",
      "Train Epoch: 25 [9600/41964 (19%)]\tLoss: 0.090402\n",
      "Train Epoch: 25 [10240/41964 (20%)]\tLoss: 0.094028\n",
      "Train Epoch: 25 [10880/41964 (22%)]\tLoss: 0.205060\n",
      "Train Epoch: 25 [11520/41964 (23%)]\tLoss: 0.170272\n",
      "Train Epoch: 25 [12160/41964 (24%)]\tLoss: 0.018232\n",
      "Train Epoch: 25 [12800/41964 (26%)]\tLoss: 0.176865\n",
      "Train Epoch: 25 [13440/41964 (27%)]\tLoss: 0.374059\n",
      "Train Epoch: 25 [14080/41964 (28%)]\tLoss: 0.178711\n",
      "Train Epoch: 25 [14720/41964 (29%)]\tLoss: 0.091771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [15360/41964 (31%)]\tLoss: 0.142579\n",
      "Train Epoch: 25 [16000/41964 (32%)]\tLoss: 0.054809\n",
      "Train Epoch: 25 [16640/41964 (33%)]\tLoss: 0.164821\n",
      "Train Epoch: 25 [17280/41964 (35%)]\tLoss: 0.199131\n",
      "Train Epoch: 25 [17920/41964 (36%)]\tLoss: 0.264575\n",
      "Train Epoch: 25 [18560/41964 (37%)]\tLoss: 0.154265\n",
      "Train Epoch: 25 [19200/41964 (38%)]\tLoss: 0.229391\n",
      "Train Epoch: 25 [19840/41964 (40%)]\tLoss: 0.321151\n",
      "Train Epoch: 25 [20480/41964 (41%)]\tLoss: 0.288243\n",
      "Train Epoch: 25 [21120/41964 (42%)]\tLoss: 0.232035\n",
      "Train Epoch: 25 [21760/41964 (43%)]\tLoss: 0.195856\n",
      "Train Epoch: 25 [22400/41964 (45%)]\tLoss: 0.178693\n",
      "Train Epoch: 25 [23040/41964 (46%)]\tLoss: 0.215259\n",
      "Train Epoch: 25 [23680/41964 (47%)]\tLoss: 0.244081\n",
      "Train Epoch: 25 [24320/41964 (49%)]\tLoss: 0.145073\n",
      "Train Epoch: 25 [24960/41964 (50%)]\tLoss: 0.135641\n",
      "Train Epoch: 25 [25600/41964 (51%)]\tLoss: 0.270778\n",
      "Train Epoch: 25 [26240/41964 (52%)]\tLoss: 0.244619\n",
      "Train Epoch: 25 [26880/41964 (54%)]\tLoss: 0.244276\n",
      "Train Epoch: 25 [27520/41964 (55%)]\tLoss: 0.151926\n",
      "Train Epoch: 25 [28160/41964 (56%)]\tLoss: 0.100900\n",
      "Train Epoch: 25 [28800/41964 (58%)]\tLoss: 0.089163\n",
      "Train Epoch: 25 [29440/41964 (59%)]\tLoss: 0.067944\n",
      "Train Epoch: 25 [30080/41964 (60%)]\tLoss: 0.110221\n",
      "Train Epoch: 25 [30720/41964 (61%)]\tLoss: 0.258226\n",
      "Train Epoch: 25 [31360/41964 (63%)]\tLoss: 0.070863\n",
      "Train Epoch: 25 [32000/41964 (64%)]\tLoss: 0.160142\n",
      "Train Epoch: 25 [32640/41964 (65%)]\tLoss: 0.193691\n",
      "Train Epoch: 25 [33280/41964 (66%)]\tLoss: 0.045541\n",
      "Train Epoch: 25 [33920/41964 (68%)]\tLoss: 0.289855\n",
      "Train Epoch: 25 [34560/41964 (69%)]\tLoss: 0.165557\n",
      "Train Epoch: 25 [35200/41964 (70%)]\tLoss: 0.180894\n",
      "Train Epoch: 25 [35840/41964 (72%)]\tLoss: 0.067776\n",
      "Train Epoch: 25 [36480/41964 (73%)]\tLoss: 0.133835\n",
      "Train Epoch: 25 [37120/41964 (74%)]\tLoss: 0.110312\n",
      "Train Epoch: 25 [37760/41964 (75%)]\tLoss: 0.115451\n",
      "Train Epoch: 25 [38400/41964 (77%)]\tLoss: 0.083267\n",
      "Train Epoch: 25 [39040/41964 (78%)]\tLoss: 0.109034\n",
      "Train Epoch: 25 [39680/41964 (79%)]\tLoss: 0.178096\n",
      "Train Epoch: 25 [40320/41964 (81%)]\tLoss: 0.105429\n",
      "Train Epoch: 25 [40960/41964 (82%)]\tLoss: 0.098123\n",
      "Train Epoch: 25 [41600/41964 (83%)]\tLoss: 0.058673\n",
      "Train Epoch: 25 [42240/41964 (84%)]\tLoss: 0.247922\n",
      "Train Epoch: 25 [42880/41964 (86%)]\tLoss: 0.125011\n",
      "Train Epoch: 25 [43520/41964 (87%)]\tLoss: 0.104433\n",
      "Train Epoch: 25 [44160/41964 (88%)]\tLoss: 0.211811\n",
      "Train Epoch: 25 [44800/41964 (90%)]\tLoss: 0.160787\n",
      "Train Epoch: 25 [45440/41964 (91%)]\tLoss: 0.300367\n",
      "Train Epoch: 25 [46080/41964 (92%)]\tLoss: 0.192247\n",
      "Train Epoch: 25 [46720/41964 (93%)]\tLoss: 0.311564\n",
      "Train Epoch: 25 [47360/41964 (95%)]\tLoss: 0.130661\n",
      "Train Epoch: 25 [48000/41964 (96%)]\tLoss: 0.053991\n",
      "Train Epoch: 25 [48640/41964 (97%)]\tLoss: 0.464297\n",
      "Train Epoch: 25 [49280/41964 (98%)]\tLoss: 0.133943\n",
      "Train Epoch: 25 [49920/41964 (100%)]\tLoss: 0.177424\n",
      "\n",
      "Test set: Avg. loss: 0.0406, Accuracy: 9879/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network_balanced_step = CNN()\n",
    "optimizer_balanced_step = optim.SGD(network_balanced_step.parameters(), lr=args.learning_rate, momentum=args.momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i * len(balanced_step_loader) for i in range(args.n_epochs + 1)]\n",
    "\n",
    "test(network_balanced_step)\n",
    "for epoch in range(1, args.n_epochs + 1):\n",
    "    train(epoch, balanced_step_loader, network_balanced_step, optimizer_balanced_step)\n",
    "    test(network_balanced_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_CNN_linear = []\n",
    "val_CNN_linear = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = network(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        for i in range(len(np.array(pred).T[0])):\n",
    "            pred_CNN_linear.append(np.array(pred).T[0][i])\n",
    "            val_CNN_linear.append(np.array(target)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_CNN_step = []\n",
    "val_CNN_step = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = network_step(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        for i in range(len(np.array(pred).T[0])):\n",
    "            pred_CNN_step.append(np.array(pred).T[0][i])\n",
    "            val_CNN_step.append(np.array(target)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_CNN_linear_res = []\n",
    "val_CNN_linear_res = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = network_balanced_linear(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        for i in range(len(np.array(pred).T[0])):\n",
    "            pred_CNN_linear_res.append(np.array(pred).T[0][i])\n",
    "            val_CNN_linear_res.append(np.array(target)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_CNN_step_res = []\n",
    "val_CNN_step_res = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = network_balanced_step(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        for i in range(len(np.array(pred).T[0])):\n",
    "            pred_CNN_step_res.append(np.array(pred).T[0][i])\n",
    "            val_CNN_step_res.append(np.array(target)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for CNN Linear: 0.9903142056796252\n",
      "ROC AUC Score for CNN Step: 0.9916839024140162\n",
      "ROC AUC Score for CNN Linear Res: 0.9929575635381556\n",
      "ROC AUC Score for CNN Step Res: 0.9932338120210634\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC Score for CNN Linear: ' + str(roc_auc_score_multiclass(val_CNN_linear, pred_CNN_linear)))\n",
    "print('ROC AUC Score for CNN Step: ' + str(roc_auc_score_multiclass(val_CNN_step, pred_CNN_step)))\n",
    "print('ROC AUC Score for CNN Linear Res: ' + str(roc_auc_score_multiclass(val_CNN_linear_res, pred_CNN_linear_res)))\n",
    "print('ROC AUC Score for CNN Step Res: ' + str(roc_auc_score_multiclass(val_CNN_step_res, pred_CNN_step_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Convolutional Neural Network does a pretty good job as it can classify digits with around a 99% accuracy and has a 99.2% AUC ROC score for the step CNN model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "\n",
    "Now we need to save our models in python object files. We can perform this task by using the *pickle* module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(log_model_linear, open(\"./Models/log_model_linear.p\", \"wb\"))\n",
    "pickle.dump(log_model_linear_res, open(\"./Models/log_model_linear_res.p\", \"wb\"))\n",
    "pickle.dump(log_model_step, open(\"./Models/log_model_step.p\", \"wb\"))\n",
    "pickle.dump(log_model_step_res, open(\"./Models/log_model_step_res.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(RF_model, open(\"./Models/RF_model_linear.p\", \"wb\"))\n",
    "pickle.dump(RF_model_res, open(\"./Models/RF_model_linear_res.p\", \"wb\"))\n",
    "pickle.dump(RF_model_step, open(\"./Models/RF_model_step.p\", \"wb\"))\n",
    "pickle.dump(RF_model_step_res, open(\"./Models/RF_model_step_res.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(network, open(\"./Models/CNN_model_linear.p\", \"wb\"))\n",
    "pickle.dump(network_step, open(\"./Models/CNN_model_step.p\", \"wb\"))\n",
    "pickle.dump(network_balanced_linear, open(\"./Models/CNN_model_linear_res.p\", \"wb\"))\n",
    "pickle.dump(network_balanced_step, open(\"./Models/CNN_model_step_res.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
